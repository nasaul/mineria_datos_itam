# Regresi√≥n lineal

## Regresi√≥n Lineal Simple

Comenzaremos con el caso m√°s sencillo: predecir una variable de resultado `Y` a partir de una √∫nica variable predictora `X`.

El modelo matem√°tico que queremos ajustar es una l√≠nea recta:

$$Y = \beta_0 + \beta_1 X + \epsilon$$

Donde:

- **$Y$**: La variable dependiente (lo que queremos predecir).
- **$X$**: La variable independiente (nuestro predictor).
- **$\beta_0$**: El intercepto (el valor de $Y$ cuando $X=0$).
- **$\beta_1$**: La pendiente (cu√°nto cambia $Y$ por cada unidad que aumenta $X$).
- **$\epsilon$**: El t√©rmino de error (la parte de $Y$ que nuestro modelo no puede explicar).

Nuestro objetivo üéØ es encontrar los **mejores valores posibles** para los coeficientes $\beta_0$ y $\beta_1$ usando los datos que tenemos.



### ¬øC√≥mo estimamos los coeficientes $\beta_0$ y $\beta_1$?

"Mejor" para nosotros significa encontrar la l√≠nea que minimice la distancia vertical entre cada punto de dato y la propia l√≠nea. Espec√≠ficamente, minimizamos la **Suma de los Errores al Cuadrado** (SEC o *Sum of Squared Errors*, SSE).

La funci√≥n de costo (o p√©rdida) que queremos minimizar es:

$$J(\beta_0, \beta_1) = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2$$

Tenemos dos m√©todos principales para encontrar los $\beta$ que minimizan esta funci√≥n:

#### M√©todo 1: Las Ecuaciones Normales (La soluci√≥n anal√≠tica üß†)

Este m√©todo utiliza c√°lculo para encontrar el m√≠nimo exacto de la funci√≥n de costo. Para ello, tomamos las derivadas parciales de $J$ con respecto a $\beta_0$ y $\beta_1$, las igualamos a cero y resolvemos para los coeficientes.

::: {.callout-note collapse="true"}
## **Derivada parcial con respecto a $\beta_0$**:
$$\frac{\partial J}{\partial \beta_0} = \sum_{i=1}^{n} -2(y_i - \beta_0 - \beta_1 x_i) = 0$$
$$\sum y_i - n\beta_0 - \beta_1 \sum x_i = 0$$
$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$$
::: 

::: {.callout-note collapse="true"}
## **Derivada parcial con respecto a $\beta_1$**
$$\frac{\partial J}{\partial \beta_1} = \sum_{i=1}^{n} -2x_i(y_i - \beta_0 - \beta_1 x_i) = 0$$
Sustituyendo $\beta_0$ de la primera ecuaci√≥n y resolviendo, llegamos a:
$$\hat{\beta}_1 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}$$
::: 

Estas f√≥rmulas nos dan los valores √≥ptimos y exactos de los coeficientes directamente a partir de los datos.

#### M√©todo 2: Descenso en Gradiente (La soluci√≥n iterativa ‚öôÔ∏è)

Este es un m√©todo computacional que nos "acerca" progresivamente a la soluci√≥n. Es especialmente √∫til cuando tenemos una cantidad masiva de datos y calcular la soluci√≥n anal√≠tica es muy costoso.

**La intuici√≥n:** Imagina que est√°s en una monta√±a (la funci√≥n de costo) y quieres llegar al valle (el costo m√≠nimo). El Descenso en Gradiente te dice que mires a tu alrededor y des un paso en la direcci√≥n m√°s inclinada hacia abajo. Repites esto hasta llegar al fondo.



El algoritmo funciona as√≠:

1.  **Inicializa** los coeficientes $\beta_0$ y $\beta_1$ con valores aleatorios (o en ceros).
2.  **Calcula el gradiente** de la funci√≥n de costo. El gradiente es un vector que apunta en la direcci√≥n del m√°ximo ascenso. Nosotros iremos en la direcci√≥n opuesta.
    -   $\frac{\partial J}{\partial \beta_0} = -2 \sum (y_i - (\beta_0 + \beta_1 x_i))$
    -   $\frac{\partial J}{\partial \beta_1} = -2 \sum x_i(y_i - (\beta_0 + \beta_1 x_i))$
3.  **Actualiza** los coeficientes usando una **tasa de aprendizaje** ($\alpha$), que controla el tama√±o del paso que damos.
    -   $\beta_0 := \beta_0 - \alpha \frac{\partial J}{\partial \beta_0}$
    -   $\beta_1 := \beta_1 - \alpha \frac{\partial J}{\partial \beta_1}$
4.  **Repite** los pasos 2 y 3 durante un n√∫mero determinado de iteraciones o hasta que el cambio en el costo sea muy peque√±o (convergencia).

::: {.callout-note collapse="true"}
#### Explicacion visual
![](imgs/gradient_descent.gif)
:::

## ¬øCu√°les son los supuestos de la regresi√≥n? üßê

Para que nuestro modelo sea confiable (es decir, para que los coeficientes y las predicciones tengan sentido), debemos cumplir con ciertos supuestos.

1.  **Linealidad:** La relaci√≥n entre $\beta$ y $Y$ debe ser lineal.
    -   **¬øPara qu√© sirve?** Si la relaci√≥n no es lineal, nuestro modelo de l√≠nea recta ser√° intr√≠nsecamente incorrecto.

2.  **Independencia de los errores:** Los errores (residuos) no deben estar correlacionados entre s√≠.
    -   **¬øPara qu√© sirve?** Es crucial para datos de series temporales. Si los errores est√°n correlacionados, la informaci√≥n de un error nos da pistas sobre el siguiente, lo cual viola la idea de que cada observaci√≥n es independiente.

3.  **Homocedasticidad (Varianza constante de los errores):** La varianza de los errores debe ser constante para todos los niveles de $X$.
    -   **¬øPara qu√© sirve?** Si la varianza cambia (heterocedasticidad), nuestras predicciones ser√°n mejores para algunas partes de los datos que para otras, y los intervalos de confianza para los coeficientes ser√°n poco fiables. Visualmente, en un gr√°fico de residuos vs. valores predichos, no queremos ver una forma de cono o embudo.

4.  **Normalidad de los errores:** Los errores deben seguir una distribuci√≥n normal con media cero.
    -   **¬øPara qu√© sirve?** Este supuesto es fundamental para poder realizar pruebas de hip√≥tesis sobre los coeficientes (como los p-values) y construir intervalos de confianza. Podemos verificarlo con un histograma de los residuos o un gr√°fico Q-Q.

---

## ¬øC√≥mo evaluar la precisi√≥n del modelo? üìà

Una vez que hemos ajustado el modelo, ¬øc√≥mo sabemos si es bueno?

### Coeficiente de Determinaci√≥n ($R^2$)

El **$R^2$** mide la proporci√≥n de la varianza total en la variable dependiente ($Y$) que es explicada por nuestro modelo.

$$R^2 = 1 - \frac{\text{Suma de Errores al Cuadrado (SEC)}}{\text{Suma Total de Cuadrados (STC)}} = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}$$

-   $R^2$ var√≠a entre 0 y 1 (o 0% y 100%).
-   Un $R^2$ de 0.85 significa que el 85% de la variabilidad en $Y$ puede ser explicada por $X$.
-   Un $R^2$ m√°s alto generalmente indica un mejor ajuste del modelo.

### p-values (Valores p)

El **p-value** nos ayuda a determinar si nuestra variable predictora $X$ es **estad√≠sticamente significativa**. Responde a la pregunta: ¬øEs probable que la relaci√≥n que observamos entre $X$ y $Y$ haya ocurrido por puro azar?

-   **Hip√≥tesis Nula ($H_0$):** No hay relaci√≥n entre $X$ y $Y$ (es decir, $\beta_1 = 0$).
-   **Hip√≥tesis Alternativa ($H_a$):** S√≠ hay una relaci√≥n entre $X$ y $Y$ (es decir, $\beta_1 \neq 0$).

Un **p-value peque√±o** (t√≠picamente < 0.05) nos da evidencia para rechazar la hip√≥tesis nula. Esto sugiere que nuestra variable $X$ es un predictor √∫til para $Y$.

## M√©tricas de Error de Predicci√≥n

Adem√°s del $R^2$, existen m√∫ltiples m√©tricas para evaluar qu√© tan bien predice nuestro modelo. Cada una tiene sus ventajas y casos de uso espec√≠ficos:

### Error Cuadr√°tico Medio (MSE)

El **MSE** mide el promedio de los errores al cuadrado:

$$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

- **Ventajas:** Penaliza fuertemente errores grandes, diferenciable (√∫til para optimizaci√≥n)
- **Desventajas:** Sensible a valores at√≠picos, dif√≠cil de interpretar (unidades al cuadrado)
- **Cu√°ndo usar:** Cuando errores grandes son especialmente costosos

### Ra√≠z del Error Cuadr√°tico Medio (RMSE)

El **RMSE** es la ra√≠z cuadrada del MSE:

$$RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

- **Ventajas:** Mismas unidades que la variable objetivo, interpretable
- **Desventajas:** A√∫n sensible a valores at√≠picos
- **Interpretaci√≥n:** "En promedio, nuestras predicciones se desv√≠an X unidades del valor real"

### Error Absoluto Medio (MAE)

El **MAE** mide el promedio de los errores absolutos:

$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

- **Ventajas:** Robusto a valores at√≠picos, f√°cil de interpretar
- **Desventajas:** No diferenciable en cero, trata todos los errores por igual
- **Cu√°ndo usar:** Cuando hay valores at√≠picos o todos los errores tienen igual importancia

### Error Porcentual Absoluto Medio (MAPE)

El **MAPE** expresa el error como porcentaje del valor real:

$$MAPE = \frac{100}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

- **Ventajas:** Interpretable (% de error), adimensional, √∫til para comparar modelos en diferentes escalas
- **Desventajas:** Indefinido cuando $y_i = 0$, asim√©trico (penaliza m√°s las sobreestimaciones)
- **Interpretaci√≥n:** "Nuestras predicciones se desv√≠an en promedio X% del valor real"
- **Cu√°ndo usar:** Para comparar precisi√≥n entre diferentes productos, regiones, o escalas

### Error Porcentual Absoluto Medio Sim√©trico (SMAPE)

El **SMAPE** es una versi√≥n sim√©trica del MAPE:

$$SMAPE = \frac{100}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}$$

- **Ventajas:** Sim√©trico, acotado entre 0% y 200%
- **Desventajas:** Puede ser contraintuitivo, no tan est√°ndar como MAPE
- **Cu√°ndo usar:** Cuando queremos evitar el sesgo del MAPE hacia sobreestimaciones

### Error Logar√≠tmico Cuadr√°tico Medio (MSLE)

El **MSLE** usa transformaci√≥n logar√≠tmica:

$$MSLE = \frac{1}{n} \sum_{i=1}^{n} (\log(1 + y_i) - \log(1 + \hat{y}_i))^2$$

- **Ventajas:** Penaliza m√°s las subestimaciones que las sobreestimaciones
- **Desventajas:** Solo para valores positivos, menos interpretable
- **Cu√°ndo usar:** Cuando subestimar es m√°s costoso que sobreestimar (ej: demanda de inventario)

### $R^2$ Ajustado

El **$R^2$ ajustado** penaliza por el n√∫mero de variables en el modelo:

$$R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-p-1}$$

Donde $p$ es el n√∫mero de predictores.

- **Ventajas:** No aumenta autom√°ticamente al a√±adir variables
- **Cu√°ndo usar:** Para comparar modelos con diferente n√∫mero de variables
- **Interpretaci√≥n:** Similar a $R^2$ pero m√°s conservador

#### ¬øCu√°l m√©trica elegir?

La elecci√≥n de m√©trica depende del contexto del problema:

| **M√©trica** | **Mejor para** | **Evitar cuando** |
|-------------|----------------|-------------------|
| **RMSE** | Errores grandes son costosos | Hay muchos valores at√≠picos |
| **MAE** | Errores tienen igual importancia | Necesitas diferenciabilidad |
| **MAPE** | Comparar diferentes escalas | Hay valores cercanos a cero |
| **SMAPE** | Comparar con simetr√≠a | Interpretaci√≥n debe ser simple |
| **R¬≤** | Explicar variabilidad | Solo importa precisi√≥n de predicci√≥n |

::: {.callout-tip}
## **Recomendaci√≥n pr√°ctica**
Usa **m√∫ltiples m√©tricas** para evaluar tu modelo. Una combinaci√≥n t√≠pica ser√≠a:
- **RMSE** para precisi√≥n general
- **MAPE** para interpretabilidad de negocio  
- **R¬≤** para explicaci√≥n de variabilidad
:::

---

## Regresi√≥n Lineal M√∫ltiple

Ahora, ¬øqu√© pasa si tenemos m√∫ltiples predictores ($X_1, X_2, ..., X_p$)? El modelo se expande:

$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p + \epsilon$$

La intuici√≥n es la misma, pero en lugar de ajustar una l√≠nea, estamos ajustando un **hiperplano** en un espacio multidimensional.

Para manejar esto de forma elegante, usamos notaci√≥n matricial:

$$\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$$

Donde:
- $\mathbf{y}$ es el vector de observaciones.
- $\mathbf{X}$ es la matriz de dise√±o (con una primera columna de unos para el intercepto).
- $\boldsymbol{\beta}$ es el vector de coeficientes.
- $\boldsymbol{\epsilon}$ es el vector de errores.

La funci√≥n de costo en forma matricial es:
$$J(\boldsymbol{\beta}) = (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})^T (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})$$

---

## Transformaciones Comunes en Modelos Lineales

A veces, la relaci√≥n entre X e Y no es estrictamente lineal. Las transformaciones logar√≠tmicas nos permiten modelar relaciones no lineales y, adem√°s, ofrecen interpretaciones muy √∫tiles en t√©rminos de cambios porcentuales.

### Modelo Log-Nivel (Transformaci√≥n en Y)

Este modelo se usa cuando el efecto de X sobre Y no es absoluto, sino porcentual. Por ejemplo, c√≥mo un a√±o m√°s de educaci√≥n afecta el *porcentaje* de aumento salarial.

-   **Ecuaci√≥n:** $\ln(Y) = \beta_0 + \beta_1 X + \epsilon$
-   **Interpretaci√≥n:** Un **incremento de una unidad** en $X$ est√° asociado con un cambio de $(100 \cdot \beta_1)\%$ en $Y$.



::: {.callout-note collapse="true"}
#### Explicaci√≥n Matem√°tica de la Aproximaci√≥n
La clave est√° en la propiedad del logaritmo y el c√°lculo. La derivada de $\ln(Y)$ con respecto a $X$ es $\beta_1$:
$$\frac{d(\ln(Y))}{dX} = \beta_1$$
Sabemos que $d(\ln(Y)) = \frac{dY}{Y}$. Por tanto:
$$\frac{dY/Y}{dX} = \beta_1$$
Para cambios peque√±os (o discretos, $\Delta$), podemos aproximar los diferenciales:
$$\beta_1 \approx \frac{\Delta Y / Y}{\Delta X}$$
Si consideramos un cambio unitario en X, $\Delta X = 1$, entonces:
$$\beta_1 \approx \frac{\Delta Y}{Y}$$
Esto significa que $\beta_1$ es la aproximaci√≥n del cambio porcentual en $Y$ ante un cambio de una unidad en $X$.
:::

### Modelo Nivel-Log (Transformaci√≥n en X)

Este modelo es √∫til cuando el efecto de X sobre Y se reduce a medida que X aumenta (rendimientos decrecientes). Por ejemplo, el efecto de a√±adir presupuesto de marketing sobre las ventas.

-   **Ecuaci√≥n:** $Y = \beta_0 + \beta_1 \ln(X) + \epsilon$
-   **Interpretaci√≥n:** Un **incremento del 1%** en $X$ est√° asociado con un cambio de $(\beta_1 / 100)$ **unidades** en $Y$.

::: {.callout-note collapse="true"}
#### Explicaci√≥n Matem√°tica de la Aproximaci√≥n
Tomamos la derivada de $Y$ con respecto a $\ln(X)$:
$$\frac{dY}{d(\ln(X))} = \beta_1$$
Usando la regla de la cadena, sabemos que $d(\ln(X)) = \frac{dX}{X}$. Sustituyendo:
$$\frac{dY}{dX/X} = \beta_1 \implies dY = \beta_1 \frac{dX}{X}$$
Para cambios discretos, aproximamos:
$$\Delta Y \approx \beta_1 \frac{\Delta X}{X}$$
Si consideramos un cambio del 1% en X, entonces $\frac{\Delta X}{X} = 0.01$. La ecuaci√≥n se convierte en:
$$\Delta Y \approx \beta_1 (0.01) = \frac{\beta_1}{100}$$
Esto significa que un cambio del 1% en $X$ provoca un cambio de $\beta_1/100$ unidades en $Y$.
:::

### Modelo Log-Log (Transformaci√≥n en X e Y)

Este modelo es muy com√∫n en econom√≠a y modela la **elasticidad** constante entre dos variables.

-   **Ecuaci√≥n:** $\ln(Y) = \beta_0 + \beta_1 \ln(X) + \epsilon$
-   **Interpretaci√≥n:** Un **incremento del 1%** en $X$ est√° asociado con un cambio del $\beta_1\%$ en $Y$.



::: {.callout-note collapse="true"}
#### Explicaci√≥n Matem√°tica de la Aproximaci√≥n
Este caso combina los dos anteriores. $\beta_1$ es la derivada de $\ln(Y)$ con respecto a $\ln(X)$, que es la definici√≥n de elasticidad.
$$\beta_1 = \frac{d(\ln(Y))}{d(\ln(X))}$$
Usando las propiedades del c√°lculo que vimos antes:
$$\beta_1 = \frac{dY/Y}{dX/X}$$
Aproximando para cambios discretos:
$$\beta_1 \approx \frac{\Delta Y / Y}{\Delta X / X}$$
Esta es la definici√≥n de elasticidad: el cambio porcentual en $Y$ dividido por el cambio porcentual en $X$. Por lo tanto, si $X$ cambia en un 1% ($\Delta X / X = 0.01$), el cambio porcentual en $Y$ ($\Delta Y / Y$) ser√° aproximadamente $\beta_1 \times 0.01$, es decir, un $\beta_1\%$.
:::

---

## Regresi√≥n Regularizada (Penalizada) üéØ

Hasta ahora hemos visto la regresi√≥n lineal cl√°sica, pero ¬øqu√© pasa cuando tenemos **muchas variables** o cuando nuestro modelo sufre de **sobreajuste**? Aqu√≠ es donde entran las t√©cnicas de **regularizaci√≥n**.

### ¬øPor qu√© necesitamos regularizaci√≥n?

La regresi√≥n lineal ordinaria (OLS) puede presentar varios problemas:

1. **Sobreajuste**: Cuando tenemos muchas variables relativas al n√∫mero de observaciones
2. **Multicolinealidad**: Variables predictoras altamente correlacionadas
3. **Inestabilidad**: Peque√±os cambios en los datos causan grandes cambios en los coeficientes
4. **Interpretabilidad**: Demasiadas variables hacen dif√≠cil entender el modelo

La **regularizaci√≥n** a√±ade una **penalizaci√≥n** a la funci√≥n de costo para controlar la complejidad del modelo.

---

### Ridge Regression (Regresi√≥n Ridge) üèîÔ∏è

La **regresi√≥n Ridge** a√±ade una penalizaci√≥n **L2** (suma de cuadrados) a los coeficientes:

$$J_{Ridge}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} \beta_j^2$$

Donde:
- $\lambda > 0$ es el **par√°metro de regularizaci√≥n**
- $\sum_{j=1}^{p} \beta_j^2$ es la **penalizaci√≥n L2**

#### Caracter√≠sticas de Ridge:

‚úÖ **Ventajas:**
- Reduce el sobreajuste
- Maneja bien la multicolinealidad
- Siempre tiene soluci√≥n √∫nica
- Estabiliza los coeficientes

‚ùå **Desventajas:**
- **NO** elimina variables (coeficientes nunca son exactamente cero)
- Dificulta la interpretabilidad
- Requiere estandarizar las variables

#### Soluci√≥n Anal√≠tica:

$$\hat{\boldsymbol{\beta}}_{Ridge} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}$$

El t√©rmino $\lambda\mathbf{I}$ hace que la matriz sea invertible incluso con multicolinealidad.

#### ¬øC√≥mo elegir Œª?

- **Œª = 0**: Regresi√≥n ordinaria (sin penalizaci√≥n)
- **Œª ‚Üí ‚àû**: Todos los coeficientes ‚Üí 0
- **Œª √≥ptimo**: Se encuentra usando **validaci√≥n cruzada**

---

### Lasso Regression (Least Absolute Shrinkage and Selection Operator) ‚úÇÔ∏è

La **regresi√≥n Lasso** usa penalizaci√≥n **L1** (suma de valores absolutos):

$$J_{Lasso}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} |\beta_j|$$

#### Caracter√≠sticas de Lasso:

‚úÖ **Ventajas:**
- **Selecci√≥n autom√°tica de variables** (coeficientes = 0)
- Modelos m√°s interpretables y simples
- √ötil cuando muchas variables son irrelevantes

‚ùå **Desventajas:**
- Puede ser inestable con grupos de variables correlacionadas
- Selecciona arbitrariamente entre variables correlacionadas
- No tiene soluci√≥n anal√≠tica cerrada

#### La "Magia" de L1: ¬øPor qu√© produce ceros exactos?

La penalizaci√≥n L1 crea una regi√≥n factible con **esquinas puntiagudas**. La soluci√≥n √≥ptima tiende a ocurrir en estas esquinas, donde algunos coeficientes son exactamente cero.

::: {.callout-note collapse="true"}
## Intuici√≥n Geom√©trica
Imagina que est√°s minimizando una funci√≥n bajo la restricci√≥n de que $|\beta_1| + |\beta_2| \leq t$. Esta restricci√≥n forma un **diamante** en 2D. La funci√≥n objetivo forma **elipses**. La soluci√≥n est√° donde la elipse m√°s peque√±a toca el diamante, y esto frecuentemente ocurre en los v√©rtices (donde $\beta_1 = 0$ o $\beta_2 = 0$).
:::

---

### Elastic Net: Lo Mejor de Ambos Mundos üï∏Ô∏è

**Elastic Net** combina las penalizaciones L1 y L2:

$$J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2$$

O equivalentemente, con un par√°metro de mezcla $\alpha$:

$$J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \left[ \alpha \sum_{j=1}^{p} |\beta_j| + (1-\alpha) \sum_{j=1}^{p} \beta_j^2 \right]$$

Donde:
- $\alpha \in [0,1]$ controla la mezcla entre L1 y L2
- $\alpha = 0$: Pure Ridge
- $\alpha = 1$: Pure Lasso
- $\alpha = 0.5$: Igual peso a ambas penalizaciones

#### Caracter√≠sticas de Elastic Net:

‚úÖ **Ventajas:**
- **Selecci√≥n de variables** como Lasso
- **Estabilidad** como Ridge
- Maneja bien **grupos de variables correlacionadas**
- M√°s flexible que Ridge o Lasso por separado

‚ùå **Desventajas:**
- Dos hiperpar√°metros para ajustar ($\lambda$ y $\alpha$)
- M√°s complejo computacionalmente

---

### Comparaci√≥n Visual: Ridge vs Lasso vs Elastic Net

| **Aspecto** | **Ridge** | **Lasso** | **Elastic Net** |
|-------------|-----------|-----------|-----------------|
| **Penalizaci√≥n** | L2: $\sum \beta_j^2$ | L1: $\sum |\beta_j|$ | L1 + L2 combinadas |
| **Selecci√≥n de variables** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **Coeficientes exactamente cero** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **Manejo de multicolinealidad** | ‚úÖ Excelente | ‚ö†Ô∏è Problem√°tico | ‚úÖ Muy bueno |
| **Estabilidad** | ‚úÖ Alta | ‚ö†Ô∏è Media | ‚úÖ Alta |
| **Interpretabilidad** | ‚ö†Ô∏è Media | ‚úÖ Alta | ‚úÖ Alta |
| **Cuando usar** | Todas las variables importan | Pocas variables importantes | Situaciones mixtas |

### ¬øCu√°ndo usar cada m√©todo?

#### Usa **Ridge** cuando:
- Crees que **todas las variables** contribuyen al modelo
- Tienes **multicolinealidad** severa
- Quieres **estabilizar** coeficientes sin eliminar variables
- El n√∫mero de observaciones es **peque√±o** relativo a variables

#### Usa **Lasso** cuando:
- Crees que **pocas variables** son realmente importantes
- Quieres un modelo **simple e interpretable**
- Necesitas **selecci√≥n autom√°tica** de variables
- Tienes muchas variables **irrelevantes**

#### Usa **Elastic Net** cuando:
- No est√°s seguro de cu√°ntas variables son importantes
- Tienes **grupos de variables correlacionadas**
- Quieres balancear **selecci√≥n** y **estabilidad**
- Es tu **primera opci√≥n** cuando no conoces la estructura de los datos

---

### Validaci√≥n de Modelos y Selecci√≥n de Hiperpar√°metros

#### ¬øPor qu√© necesitamos dividir nuestros datos?

Cuando construimos modelos de machine learning, enfrentamos un dilema fundamental: **¬øc√≥mo sabemos si nuestro modelo funcionar√° bien con datos nuevos?**

##### El Problema del Sobreajuste

Imagina que est√°s prepar√°ndote para un examen. Si solo estudias las preguntas exactas que aparecer√°n en el examen, podr√≠as obtener una calificaci√≥n perfecta. Pero si las preguntas cambian ligeramente, tu rendimiento se desplomar√≠a. Esto es **sobreajuste**: el modelo memoriza los datos de entrenamiento pero no generaliza.

#### Divisi√≥n T√≠pica de Datos: Entrenamiento/Validaci√≥n/Prueba

La estrategia est√°ndar es dividir nuestros datos en **tres conjuntos**:

```
üìä Dataset Completo (100%)
‚îú‚îÄ‚îÄ üèãÔ∏è Entrenamiento (60%) - Para ajustar coeficientes
‚îú‚îÄ‚îÄ üéØ Validaci√≥n (20%)     - Para seleccionar hiperpar√°metros  
‚îî‚îÄ‚îÄ üß™ Prueba (20%)         - Para evaluaci√≥n final
```

##### Conjunto de Entrenamiento (60%)
- **Prop√≥sito**: Ajustar los coeficientes $\beta$ del modelo
- **Analog√≠a**: Los ejercicios que haces para aprender

##### Conjunto de Validaci√≥n (20%)
- **Prop√≥sito**: Comparar diferentes hiperpar√°metros (como $\lambda$ en Ridge/Lasso)
- **Analog√≠a**: Ex√°menes de pr√°ctica para decidir qu√© estrategia de estudio funciona mejor

##### Conjunto de Prueba (20%)
- **Prop√≥sito**: Evaluaci√≥n final y honesta del modelo
- **Analog√≠a**: El examen final real
- **‚ö†Ô∏è Regla de Oro**: ¬°Solo se usa UNA vez al final!

#### ¬øQu√© pasa si tenemos pocos datos?

Cuando nuestro dataset es peque√±o (< 1000 observaciones), dividir en tres partes puede ser problem√°tico:

‚ùå **Problemas con datasets peque√±os:**
- Conjunto de entrenamiento muy peque√±o ‚Üí modelo pobre
- Conjunto de validaci√≥n peque√±o ‚Üí selecci√≥n inestable de hiperpar√°metros
- Conjunto de prueba peque√±o ‚Üí evaluaci√≥n poco confiable

**Soluci√≥n**: ¬°Validaci√≥n Cruzada!

---

#### Validaci√≥n Cruzada (Cross-Validation)

La **validaci√≥n cruzada** es una t√©cnica que maximiza el uso de nuestros datos limitados. En lugar de usar una sola divisi√≥n, usamos **m√∫ltiples divisiones**.

##### Validaci√≥n Cruzada k-fold

El m√©todo m√°s com√∫n es **k-fold cross-validation**:

1. **Dividir** el dataset en $k$ "pliegues" (folds) de igual tama√±o
2. **Repetir** $k$ veces:
   - Usar $k-1$ pliegues para entrenamiento
   - Usar 1 pliegue para validaci√≥n
3. **Promediar** los resultados de las $k$ evaluaciones

```{python}
#| label: cv-visualization
#| fig-cap: "Visualizaci√≥n de 5-Fold Cross Validation mostrando c√≥mo se dividen los datos en cada iteraci√≥n"
#| fig-width: 12
#| fig-height: 8
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib
matplotlib.rcParams['figure.dpi'] = 150  # Higher DPI for better quality

# Visualizaci√≥n de 5-Fold Cross Validation
fig, axes = plt.subplots(5, 1, figsize=(12, 8))
fig.suptitle('Validaci√≥n Cruzada 5-Fold: Divisi√≥n de Datos', fontsize=16, fontweight='bold')

k = 5
colors = ['lightblue', 'lightcoral']

for fold in range(k):
    ax = axes[fold]
    
    # Crear rect√°ngulos para cada fold
    for i in range(k):
        if i == fold:
            # Este es el fold de validaci√≥n
            rect = patches.Rectangle((i, 0), 1, 1, linewidth=2, 
                                   edgecolor='red', facecolor=colors[1])
            ax.add_patch(rect)
        else:
            # Estos son los folds de entrenamiento
            rect = patches.Rectangle((i, 0), 1, 1, linewidth=2, 
                                   edgecolor='blue', facecolor=colors[0])
            ax.add_patch(rect)
    
    # Configurar ejes
    ax.set_xlim(0, k)
    ax.set_ylim(0, 1)
    ax.set_xticks(np.arange(k) + 0.5)
    ax.set_xticklabels([f'Fold {i+1}' for i in range(k)])
    ax.set_yticks([])
    ax.set_ylabel(f'Iteraci√≥n {fold+1}', rotation=0, ha='right', va='center')
    
    # A√±adir t√≠tulo para la primera iteraci√≥n
    if fold == 0:
        ax.text(k/2, 1.3, 'Divisi√≥n de Datos en Cada Iteraci√≥n', 
                ha='center', va='center', fontsize=12, fontweight='bold')

# A√±adir leyenda
legend_elements = [patches.Patch(facecolor=colors[0], edgecolor='blue', label='Entrenamiento'),
                  patches.Patch(facecolor=colors[1], edgecolor='red', label='Validaci√≥n')]
fig.legend(handles=legend_elements, loc='center right', bbox_to_anchor=(0.95, 0.5))

plt.tight_layout()
plt.show()
```

##### Ventajas de la Validaci√≥n Cruzada

‚úÖ **Maximiza el uso de datos**: Cada observaci√≥n se usa tanto para entrenamiento como validaci√≥n

‚úÖ **Estimaci√≥n m√°s robusta**: Promedia m√∫ltiples evaluaciones independientes

‚úÖ **Reduce la varianza**: Menos dependiente de una divisi√≥n particular

‚úÖ **Detecta inestabilidad**: Si los resultados var√≠an mucho entre folds, el modelo es inestable

#### Validaci√≥n Cruzada para Selecci√≥n de Hiperpar√°metros

En regresi√≥n regularizada, usamos CV para encontrar el mejor $\lambda$:

```{python}
#| label: validation-curve
#| fig-cap: "Curva de validaci√≥n mostrando c√≥mo seleccionar el hiperpar√°metro √≥ptimo Œª usando validaci√≥n cruzada"
#| fig-width: 12
#| fig-height: 6
#| echo: false

# Ejemplo conceptual de selecci√≥n de hiperpar√°metros
alphas = np.logspace(-3, 2, 20)  # Valores de lambda a probar
cv_scores = []

print("üéØ SELECCI√ìN DE HIPERPAR√ÅMETROS CON VALIDACI√ìN CRUZADA")
print("=" * 60)
print("Para cada valor de Œª:")
print("  1. Aplicar 5-fold CV")
print("  2. Calcular error promedio")
print("  3. Seleccionar Œª con menor error")

# Simular scores para visualizaci√≥n
np.random.seed(42)
true_minimum = 0.1
cv_scores = []

for alpha in alphas:
    # Simular error de CV (menor cerca del √≥ptimo)
    distance = abs(np.log10(alpha) - np.log10(true_minimum))
    base_error = 0.5 + distance**2 * 0.1
    noise = np.random.normal(0, 0.05)
    cv_scores.append(base_error + noise)

cv_scores = np.array(cv_scores)

# Encontrar el mejor alpha
best_idx = np.argmin(cv_scores)
best_alpha = alphas[best_idx]

# Graficar curva de validaci√≥n
plt.figure(figsize=(12, 6))
plt.plot(alphas, cv_scores, 'bo-', alpha=0.7, label='Error de Validaci√≥n Cruzada')
plt.axvline(x=best_alpha, color='red', linestyle='--', 
           label=f'Œª √≥ptimo = {best_alpha:.3f}')
plt.scatter([best_alpha], [cv_scores[best_idx]], color='red', s=100, zorder=5)

plt.xscale('log')
plt.xlabel('Œª (Par√°metro de Regularizaci√≥n)')
plt.ylabel('Error de Validaci√≥n Cruzada')
plt.title('Curva de Validaci√≥n: Selecci√≥n de Hiperpar√°metros')
plt.legend()
plt.grid(True, alpha=0.3)

# A√±adir anotaciones
plt.annotate('Infraajuste\n(Œª muy alto)', 
            xy=(10, 0.7), xytext=(50, 0.8),
            arrowprops=dict(arrowstyle='->', color='orange', alpha=0.7),
            fontsize=10, ha='center', color='orange')

plt.annotate('Sobreajuste\n(Œª muy bajo)', 
            xy=(0.01, 0.6), xytext=(0.003, 0.9),
            arrowprops=dict(arrowstyle='->', color='purple', alpha=0.7),
            fontsize=10, ha='center', color='purple')

plt.tight_layout()
plt.show()

print(f"\nüìà Resultado: Œª √≥ptimo = {best_alpha:.4f}")
print(f"üìâ Error de CV m√≠nimo = {cv_scores[best_idx]:.4f}")
```

#### Proceso Completo de Validaci√≥n

El flujo completo para modelos regularizados es:

```
1. üìä Dividir datos originales
   ‚îî‚îÄ‚îÄ 80% para desarrollo (entrenamiento + validaci√≥n)
   ‚îî‚îÄ‚îÄ 20% para prueba final (¬°NO TOCAR hasta el final!)

2. üîÑ En el conjunto de desarrollo:
   ‚îî‚îÄ‚îÄ Para cada Œª candidato:
       ‚îú‚îÄ‚îÄ Aplicar k-fold CV
       ‚îú‚îÄ‚îÄ Calcular error promedio
       ‚îî‚îÄ‚îÄ Guardar resultado

3. üéØ Seleccionar Œª con menor error de CV

4. üèóÔ∏è Entrenar modelo final con Œª √≥ptimo en TODO el conjunto de desarrollo

5. üß™ Evaluaci√≥n final en conjunto de prueba
```

#### Variantes de Validaci√≥n Cruzada

##### Leave-One-Out CV (LOOCV)
- **k = n** (n√∫mero de observaciones)
- **Ventaja**: M√°ximo uso de datos para entrenamiento
- **Desventaja**: Computacionalmente costoso, alta varianza

##### Stratified CV
- **Para problemas de clasificaci√≥n**
- Mantiene la proporci√≥n de clases en cada fold

##### Time Series CV
- **Para datos temporales**
- Respeta el orden temporal (no mezcla futuro con pasado)

::: {.callout-important}
## **‚ö†Ô∏è Errores Comunes**

1. **Data Leakage**: Usar informaci√≥n del conjunto de prueba durante el desarrollo
2. **M√∫ltiples evaluaciones**: Evaluar repetidamente en el conjunto de prueba
3. **Selecci√≥n de modelo sesgada**: Elegir el modelo bas√°ndose en el conjunto de prueba
4. **CV incorrecto**: Aplicar transformaciones antes de la divisi√≥n de CV
:::

#### ¬øCu√°ndo usar cada enfoque?

| **Tama√±o del Dataset** | **Enfoque Recomendado** | **Raz√≥n** |
|------------------------|------------------------|-----------|
| **Grande (>10,000)** | Train/Validation/Test | Suficientes datos para divisi√≥n estable |
| **Mediano (1,000-10,000)** | Train/Test + CV | CV para hiperpar√°metros, test para evaluaci√≥n final |
| **Peque√±o (<1,000)** | Solo CV (sin test separado) | Maximizar datos disponibles |
| **Muy peque√±o (<100)** | LOOCV o Bootstrap | Cada observaci√≥n es valiosa |

::: {.callout-tip}
## **Consejo Pr√°ctico**
Empieza siempre con **Elastic Net** con $\alpha = 0.5$. Si el modelo selecciona muchas variables, prueba valores de $\alpha$ m√°s cercanos a 1 (m√°s Lasso). Si elimina variables importantes, prueba valores cercanos a 0 (m√°s Ridge).
:::

---

### Ejercicio Pr√°ctico: Comparando los Tres M√©todos

En el notebook correspondiente, implementaremos:

1. **Generaci√≥n de datos** con diferentes estructuras de correlaci√≥n
2. **Comparaci√≥n visual** de los caminos de regularizaci√≥n
3. **Validaci√≥n cruzada** para selecci√≥n de hiperpar√°metros
4. **Evaluaci√≥n** del rendimiento en datos de prueba
5. **Interpretaci√≥n** de los coeficientes seleccionados

**Pregunta de reflexi√≥n:** ¬øEn qu√© situaciones esperar√≠as que Ridge supere a Lasso, y viceversa?

---
