# RegresiÃ³n lineal

## RegresiÃ³n Lineal Simple

Comenzaremos con el caso mÃ¡s sencillo: predecir una variable de resultado `Y` a partir de una Ãºnica variable predictora `X`.

El modelo matemÃ¡tico que queremos ajustar es una lÃ­nea recta:

$$Y = \beta_0 + \beta_1 X + \epsilon$$

Donde:

- **$Y$**: La variable dependiente (lo que queremos predecir).
- **$X$**: La variable independiente (nuestro predictor).
- **$\beta_0$**: El intercepto (el valor de $Y$ cuando $X=0$).
- **$\beta_1$**: La pendiente (cuÃ¡nto cambia $Y$ por cada unidad que aumenta $X$).
- **$\epsilon$**: El tÃ©rmino de error (la parte de $Y$ que nuestro modelo no puede explicar).

Nuestro objetivo ğŸ¯ es encontrar los **mejores valores posibles** para los coeficientes $\beta_0$ y $\beta_1$ usando los datos que tenemos.



### Â¿CÃ³mo estimamos los coeficientes $\beta_0$ y $\beta_1$?

"Mejor" para nosotros significa encontrar la lÃ­nea que minimice la distancia vertical entre cada punto de dato y la propia lÃ­nea. EspecÃ­ficamente, minimizamos la **Suma de los Errores al Cuadrado** (SEC o *Sum of Squared Errors*, SSE).

La funciÃ³n de costo (o pÃ©rdida) que queremos minimizar es:

$$J(\beta_0, \beta_1) = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2$$

Tenemos dos mÃ©todos principales para encontrar los $\beta$ que minimizan esta funciÃ³n:

#### MÃ©todo 1: Las Ecuaciones Normales (La soluciÃ³n analÃ­tica ğŸ§ )

Este mÃ©todo utiliza cÃ¡lculo para encontrar el mÃ­nimo exacto de la funciÃ³n de costo. Para ello, tomamos las derivadas parciales de $J$ con respecto a $\beta_0$ y $\beta_1$, las igualamos a cero y resolvemos para los coeficientes.

::: {.callout-note collapse="true"}
## **Derivada parcial con respecto a $\beta_0$**:
$$\frac{\partial J}{\partial \beta_0} = \sum_{i=1}^{n} -2(y_i - \beta_0 - \beta_1 x_i) = 0$$
$$\sum y_i - n\beta_0 - \beta_1 \sum x_i = 0$$
$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$$
::: 

::: {.callout-note collapse="true"}
## **Derivada parcial con respecto a $\beta_1$**
$$\frac{\partial J}{\partial \beta_1} = \sum_{i=1}^{n} -2x_i(y_i - \beta_0 - \beta_1 x_i) = 0$$
Sustituyendo $\beta_0$ de la primera ecuaciÃ³n y resolviendo, llegamos a:
$$\hat{\beta}_1 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}$$
::: 

Estas fÃ³rmulas nos dan los valores Ã³ptimos y exactos de los coeficientes directamente a partir de los datos.

#### MÃ©todo 2: Descenso en Gradiente (La soluciÃ³n iterativa âš™ï¸)

Este es un mÃ©todo computacional que nos "acerca" progresivamente a la soluciÃ³n. Es especialmente Ãºtil cuando tenemos una cantidad masiva de datos y calcular la soluciÃ³n analÃ­tica es muy costoso.

**La intuiciÃ³n:** Imagina que estÃ¡s en una montaÃ±a (la funciÃ³n de costo) y quieres llegar al valle (el costo mÃ­nimo). El Descenso en Gradiente te dice que mires a tu alrededor y des un paso en la direcciÃ³n mÃ¡s inclinada hacia abajo. Repites esto hasta llegar al fondo.



El algoritmo funciona asÃ­:

1.  **Inicializa** los coeficientes $\beta_0$ y $\beta_1$ con valores aleatorios (o en ceros).
2.  **Calcula el gradiente** de la funciÃ³n de costo. El gradiente es un vector que apunta en la direcciÃ³n del mÃ¡ximo ascenso. Nosotros iremos en la direcciÃ³n opuesta.
    -   $\frac{\partial J}{\partial \beta_0} = -2 \sum (y_i - (\beta_0 + \beta_1 x_i))$
    -   $\frac{\partial J}{\partial \beta_1} = -2 \sum x_i(y_i - (\beta_0 + \beta_1 x_i))$
3.  **Actualiza** los coeficientes usando una **tasa de aprendizaje** ($\alpha$), que controla el tamaÃ±o del paso que damos.
    -   $\beta_0 := \beta_0 - \alpha \frac{\partial J}{\partial \beta_0}$
    -   $\beta_1 := \beta_1 - \alpha \frac{\partial J}{\partial \beta_1}$
4.  **Repite** los pasos 2 y 3 durante un nÃºmero determinado de iteraciones o hasta que el cambio en el costo sea muy pequeÃ±o (convergencia).

::: {.callout-note collapse="true"}
#### Explicacion visual
![](imgs/gradient_descent.gif)
:::

## Â¿CuÃ¡les son los supuestos de la regresiÃ³n? ğŸ§

Para que nuestro modelo sea confiable (es decir, para que los coeficientes y las predicciones tengan sentido), debemos cumplir con ciertos supuestos.

1.  **Linealidad:** La relaciÃ³n entre $\beta$ y $Y$ debe ser lineal.
    -   **Â¿Para quÃ© sirve?** Si la relaciÃ³n no es lineal, nuestro modelo de lÃ­nea recta serÃ¡ intrÃ­nsecamente incorrecto.

2.  **Independencia de los errores:** Los errores (residuos) no deben estar correlacionados entre sÃ­.
    -   **Â¿Para quÃ© sirve?** Es crucial para datos de series temporales. Si los errores estÃ¡n correlacionados, la informaciÃ³n de un error nos da pistas sobre el siguiente, lo cual viola la idea de que cada observaciÃ³n es independiente.

3.  **Homocedasticidad (Varianza constante de los errores):** La varianza de los errores debe ser constante para todos los niveles de $X$.
    -   **Â¿Para quÃ© sirve?** Si la varianza cambia (heterocedasticidad), nuestras predicciones serÃ¡n mejores para algunas partes de los datos que para otras, y los intervalos de confianza para los coeficientes serÃ¡n poco fiables. Visualmente, en un grÃ¡fico de residuos vs. valores predichos, no queremos ver una forma de cono o embudo.

4.  **Normalidad de los errores:** Los errores deben seguir una distribuciÃ³n normal con media cero.
    -   **Â¿Para quÃ© sirve?** Este supuesto es fundamental para poder realizar pruebas de hipÃ³tesis sobre los coeficientes (como los p-values) y construir intervalos de confianza. Podemos verificarlo con un histograma de los residuos o un grÃ¡fico Q-Q.

---

## Â¿CÃ³mo evaluar la precisiÃ³n del modelo? ğŸ“ˆ

Una vez que hemos ajustado el modelo, Â¿cÃ³mo sabemos si es bueno?

### Coeficiente de DeterminaciÃ³n ($R^2$)

El **$R^2$** mide la proporciÃ³n de la varianza total en la variable dependiente ($Y$) que es explicada por nuestro modelo.

$$R^2 = 1 - \frac{\text{Suma de Errores al Cuadrado (SEC)}}{\text{Suma Total de Cuadrados (STC)}} = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}$$

-   $R^2$ varÃ­a entre 0 y 1 (o 0% y 100%).
-   Un $R^2$ de 0.85 significa que el 85% de la variabilidad en $Y$ puede ser explicada por $X$.
-   Un $R^2$ mÃ¡s alto generalmente indica un mejor ajuste del modelo.

### p-values (Valores p)

El **p-value** nos ayuda a determinar si nuestra variable predictora $X$ es **estadÃ­sticamente significativa**. Responde a la pregunta: Â¿Es probable que la relaciÃ³n que observamos entre $X$ y $Y$ haya ocurrido por puro azar?

-   **HipÃ³tesis Nula ($H_0$):** No hay relaciÃ³n entre $X$ y $Y$ (es decir, $\beta_1 = 0$).
-   **HipÃ³tesis Alternativa ($H_a$):** SÃ­ hay una relaciÃ³n entre $X$ y $Y$ (es decir, $\beta_1 \neq 0$).

Un **p-value pequeÃ±o** (tÃ­picamente < 0.05) nos da evidencia para rechazar la hipÃ³tesis nula. Esto sugiere que nuestra variable $X$ es un predictor Ãºtil para $Y$.

## MÃ©tricas de Error de PredicciÃ³n

AdemÃ¡s del $R^2$, existen mÃºltiples mÃ©tricas para evaluar quÃ© tan bien predice nuestro modelo. Cada una tiene sus ventajas y casos de uso especÃ­ficos:

### Error CuadrÃ¡tico Medio (MSE)

El **MSE** mide el promedio de los errores al cuadrado:

$$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

- **Ventajas:** Penaliza fuertemente errores grandes, diferenciable (Ãºtil para optimizaciÃ³n)
- **Desventajas:** Sensible a valores atÃ­picos, difÃ­cil de interpretar (unidades al cuadrado)
- **CuÃ¡ndo usar:** Cuando errores grandes son especialmente costosos

### RaÃ­z del Error CuadrÃ¡tico Medio (RMSE)

El **RMSE** es la raÃ­z cuadrada del MSE:

$$RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

- **Ventajas:** Mismas unidades que la variable objetivo, interpretable
- **Desventajas:** AÃºn sensible a valores atÃ­picos
- **InterpretaciÃ³n:** "En promedio, nuestras predicciones se desvÃ­an X unidades del valor real"

### Error Absoluto Medio (MAE)

El **MAE** mide el promedio de los errores absolutos:

$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

- **Ventajas:** Robusto a valores atÃ­picos, fÃ¡cil de interpretar
- **Desventajas:** No diferenciable en cero, trata todos los errores por igual
- **CuÃ¡ndo usar:** Cuando hay valores atÃ­picos o todos los errores tienen igual importancia

### Error Porcentual Absoluto Medio (MAPE)

El **MAPE** expresa el error como porcentaje del valor real:

$$MAPE = \frac{100}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

- **Ventajas:** Interpretable (% de error), adimensional, Ãºtil para comparar modelos en diferentes escalas
- **Desventajas:** Indefinido cuando $y_i = 0$, asimÃ©trico (penaliza mÃ¡s las sobreestimaciones)
- **InterpretaciÃ³n:** "Nuestras predicciones se desvÃ­an en promedio X% del valor real"
- **CuÃ¡ndo usar:** Para comparar precisiÃ³n entre diferentes productos, regiones, o escalas

### Error Porcentual Absoluto Medio SimÃ©trico (SMAPE)

El **SMAPE** es una versiÃ³n simÃ©trica del MAPE:

$$SMAPE = \frac{100}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}$$

- **Ventajas:** SimÃ©trico, acotado entre 0% y 200%
- **Desventajas:** Puede ser contraintuitivo, no tan estÃ¡ndar como MAPE
- **CuÃ¡ndo usar:** Cuando queremos evitar el sesgo del MAPE hacia sobreestimaciones

### Error LogarÃ­tmico CuadrÃ¡tico Medio (MSLE)

El **MSLE** usa transformaciÃ³n logarÃ­tmica:

$$MSLE = \frac{1}{n} \sum_{i=1}^{n} (\log(1 + y_i) - \log(1 + \hat{y}_i))^2$$

- **Ventajas:** Penaliza mÃ¡s las subestimaciones que las sobreestimaciones
- **Desventajas:** Solo para valores positivos, menos interpretable
- **CuÃ¡ndo usar:** Cuando subestimar es mÃ¡s costoso que sobreestimar (ej: demanda de inventario)

### $R^2$ Ajustado

El **$R^2$ ajustado** penaliza por el nÃºmero de variables en el modelo:

$$R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-p-1}$$

Donde $p$ es el nÃºmero de predictores.

- **Ventajas:** No aumenta automÃ¡ticamente al aÃ±adir variables
- **CuÃ¡ndo usar:** Para comparar modelos con diferente nÃºmero de variables
- **InterpretaciÃ³n:** Similar a $R^2$ pero mÃ¡s conservador

#### Â¿CuÃ¡l mÃ©trica elegir?

La elecciÃ³n de mÃ©trica depende del contexto del problema:

| **MÃ©trica** | **Mejor para** | **Evitar cuando** |
|-------------|----------------|-------------------|
| **RMSE** | Errores grandes son costosos | Hay muchos valores atÃ­picos |
| **MAE** | Errores tienen igual importancia | Necesitas diferenciabilidad |
| **MAPE** | Comparar diferentes escalas | Hay valores cercanos a cero |
| **SMAPE** | Comparar con simetrÃ­a | InterpretaciÃ³n debe ser simple |
| **RÂ²** | Explicar variabilidad | Solo importa precisiÃ³n de predicciÃ³n |

::: {.callout-tip}
## **RecomendaciÃ³n prÃ¡ctica**
Usa **mÃºltiples mÃ©tricas** para evaluar tu modelo. Una combinaciÃ³n tÃ­pica serÃ­a:
- **RMSE** para precisiÃ³n general
- **MAPE** para interpretabilidad de negocio  
- **RÂ²** para explicaciÃ³n de variabilidad
:::

---

## RegresiÃ³n Lineal MÃºltiple

Ahora, Â¿quÃ© pasa si tenemos mÃºltiples predictores ($X_1, X_2, ..., X_p$)? El modelo se expande:

$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p + \epsilon$$

La intuiciÃ³n es la misma, pero en lugar de ajustar una lÃ­nea, estamos ajustando un **hiperplano** en un espacio multidimensional.

Para manejar esto de forma elegante, usamos notaciÃ³n matricial:

$$\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$$

Donde:
- $\mathbf{y}$ es el vector de observaciones.
- $\mathbf{X}$ es la matriz de diseÃ±o (con una primera columna de unos para el intercepto).
- $\boldsymbol{\beta}$ es el vector de coeficientes.
- $\boldsymbol{\epsilon}$ es el vector de errores.

La funciÃ³n de costo en forma matricial es:
$$J(\boldsymbol{\beta}) = (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})^T (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})$$

---

## Transformaciones Comunes en Modelos Lineales

A veces, la relaciÃ³n entre X e Y no es estrictamente lineal. Las transformaciones logarÃ­tmicas nos permiten modelar relaciones no lineales y, ademÃ¡s, ofrecen interpretaciones muy Ãºtiles en tÃ©rminos de cambios porcentuales.

### Modelo Log-Nivel (TransformaciÃ³n en Y)

Este modelo se usa cuando el efecto de X sobre Y no es absoluto, sino porcentual. Por ejemplo, cÃ³mo un aÃ±o mÃ¡s de educaciÃ³n afecta el *porcentaje* de aumento salarial.

-   **EcuaciÃ³n:** $\ln(Y) = \beta_0 + \beta_1 X + \epsilon$
-   **InterpretaciÃ³n:** Un **incremento de una unidad** en $X$ estÃ¡ asociado con un cambio de $(100 \cdot \beta_1)\%$ en $Y$.



::: {.callout-note collapse="true"}
#### ExplicaciÃ³n MatemÃ¡tica de la AproximaciÃ³n
La clave estÃ¡ en la propiedad del logaritmo y el cÃ¡lculo. La derivada de $\ln(Y)$ con respecto a $X$ es $\beta_1$:
$$\frac{d(\ln(Y))}{dX} = \beta_1$$
Sabemos que $d(\ln(Y)) = \frac{dY}{Y}$. Por tanto:
$$\frac{dY/Y}{dX} = \beta_1$$
Para cambios pequeÃ±os (o discretos, $\Delta$), podemos aproximar los diferenciales:
$$\beta_1 \approx \frac{\Delta Y / Y}{\Delta X}$$
Si consideramos un cambio unitario en X, $\Delta X = 1$, entonces:
$$\beta_1 \approx \frac{\Delta Y}{Y}$$
Esto significa que $\beta_1$ es la aproximaciÃ³n del cambio porcentual en $Y$ ante un cambio de una unidad en $X$.
:::

### Modelo Nivel-Log (TransformaciÃ³n en X)

Este modelo es Ãºtil cuando el efecto de X sobre Y se reduce a medida que X aumenta (rendimientos decrecientes). Por ejemplo, el efecto de aÃ±adir presupuesto de marketing sobre las ventas.

-   **EcuaciÃ³n:** $Y = \beta_0 + \beta_1 \ln(X) + \epsilon$
-   **InterpretaciÃ³n:** Un **incremento del 1%** en $X$ estÃ¡ asociado con un cambio de $(\beta_1 / 100)$ **unidades** en $Y$.

::: {.callout-note collapse="true"}
#### ExplicaciÃ³n MatemÃ¡tica de la AproximaciÃ³n
Tomamos la derivada de $Y$ con respecto a $\ln(X)$:
$$\frac{dY}{d(\ln(X))} = \beta_1$$
Usando la regla de la cadena, sabemos que $d(\ln(X)) = \frac{dX}{X}$. Sustituyendo:
$$\frac{dY}{dX/X} = \beta_1 \implies dY = \beta_1 \frac{dX}{X}$$
Para cambios discretos, aproximamos:
$$\Delta Y \approx \beta_1 \frac{\Delta X}{X}$$
Si consideramos un cambio del 1% en X, entonces $\frac{\Delta X}{X} = 0.01$. La ecuaciÃ³n se convierte en:
$$\Delta Y \approx \beta_1 (0.01) = \frac{\beta_1}{100}$$
Esto significa que un cambio del 1% en $X$ provoca un cambio de $\beta_1/100$ unidades en $Y$.
:::

### Modelo Log-Log (TransformaciÃ³n en X e Y)

Este modelo es muy comÃºn en economÃ­a y modela la **elasticidad** constante entre dos variables.

-   **EcuaciÃ³n:** $\ln(Y) = \beta_0 + \beta_1 \ln(X) + \epsilon$
-   **InterpretaciÃ³n:** Un **incremento del 1%** en $X$ estÃ¡ asociado con un cambio del $\beta_1\%$ en $Y$.



::: {.callout-note collapse="true"}
#### ExplicaciÃ³n MatemÃ¡tica de la AproximaciÃ³n
Este caso combina los dos anteriores. $\beta_1$ es la derivada de $\ln(Y)$ con respecto a $\ln(X)$, que es la definiciÃ³n de elasticidad.
$$\beta_1 = \frac{d(\ln(Y))}{d(\ln(X))}$$
Usando las propiedades del cÃ¡lculo que vimos antes:
$$\beta_1 = \frac{dY/Y}{dX/X}$$
Aproximando para cambios discretos:
$$\beta_1 \approx \frac{\Delta Y / Y}{\Delta X / X}$$
Esta es la definiciÃ³n de elasticidad: el cambio porcentual en $Y$ dividido por el cambio porcentual en $X$. Por lo tanto, si $X$ cambia en un 1% ($\Delta X / X = 0.01$), el cambio porcentual en $Y$ ($\Delta Y / Y$) serÃ¡ aproximadamente $\beta_1 \times 0.01$, es decir, un $\beta_1\%$.
:::

---

## RegresiÃ³n Regularizada (Penalizada) ğŸ¯

Hasta ahora hemos visto la regresiÃ³n lineal clÃ¡sica, pero Â¿quÃ© pasa cuando tenemos **muchas variables** o cuando nuestro modelo sufre de **sobreajuste**? AquÃ­ es donde entran las tÃ©cnicas de **regularizaciÃ³n**.

### Â¿Por quÃ© necesitamos regularizaciÃ³n?

La regresiÃ³n lineal ordinaria (OLS) puede presentar varios problemas:

1. **Sobreajuste**: Cuando tenemos muchas variables relativas al nÃºmero de observaciones
2. **Multicolinealidad**: Variables predictoras altamente correlacionadas
3. **Inestabilidad**: PequeÃ±os cambios en los datos causan grandes cambios en los coeficientes
4. **Interpretabilidad**: Demasiadas variables hacen difÃ­cil entender el modelo

La **regularizaciÃ³n** aÃ±ade una **penalizaciÃ³n** a la funciÃ³n de costo para controlar la complejidad del modelo.

---

### Ridge Regression (RegresiÃ³n Ridge) ğŸ”ï¸

La **regresiÃ³n Ridge** aÃ±ade una penalizaciÃ³n **L2** (suma de cuadrados) a los coeficientes:

$$J_{Ridge}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} \beta_j^2$$

Donde:
- $\lambda > 0$ es el **parÃ¡metro de regularizaciÃ³n**
- $\sum_{j=1}^{p} \beta_j^2$ es la **penalizaciÃ³n L2**

#### CaracterÃ­sticas de Ridge:

âœ… **Ventajas:**
- Reduce el sobreajuste
- Maneja bien la multicolinealidad
- Siempre tiene soluciÃ³n Ãºnica
- Estabiliza los coeficientes

âŒ **Desventajas:**
- **NO** elimina variables (coeficientes nunca son exactamente cero)
- Dificulta la interpretabilidad
- Requiere estandarizar las variables

#### SoluciÃ³n AnalÃ­tica:

$$\hat{\boldsymbol{\beta}}_{Ridge} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}$$

El tÃ©rmino $\lambda\mathbf{I}$ hace que la matriz sea invertible incluso con multicolinealidad.

#### Â¿CÃ³mo elegir Î»?

- **Î» = 0**: RegresiÃ³n ordinaria (sin penalizaciÃ³n)
- **Î» â†’ âˆ**: Todos los coeficientes â†’ 0
- **Î» Ã³ptimo**: Se encuentra usando **validaciÃ³n cruzada**

---

### Lasso Regression (Least Absolute Shrinkage and Selection Operator) âœ‚ï¸

La **regresiÃ³n Lasso** usa penalizaciÃ³n **L1** (suma de valores absolutos):

$$J_{Lasso}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} |\beta_j|$$

#### CaracterÃ­sticas de Lasso:

âœ… **Ventajas:**
- **SelecciÃ³n automÃ¡tica de variables** (coeficientes = 0)
- Modelos mÃ¡s interpretables y simples
- Ãštil cuando muchas variables son irrelevantes

âŒ **Desventajas:**
- Puede ser inestable con grupos de variables correlacionadas
- Selecciona arbitrariamente entre variables correlacionadas
- No tiene soluciÃ³n analÃ­tica cerrada

#### La "Magia" de L1: Â¿Por quÃ© produce ceros exactos?

La penalizaciÃ³n L1 crea una regiÃ³n factible con **esquinas puntiagudas**. La soluciÃ³n Ã³ptima tiende a ocurrir en estas esquinas, donde algunos coeficientes son exactamente cero.

::: {.callout-note collapse="true"}
## IntuiciÃ³n GeomÃ©trica
Imagina que estÃ¡s minimizando una funciÃ³n bajo la restricciÃ³n de que $|\beta_1| + |\beta_2| \leq t$. Esta restricciÃ³n forma un **diamante** en 2D. La funciÃ³n objetivo forma **elipses**. La soluciÃ³n estÃ¡ donde la elipse mÃ¡s pequeÃ±a toca el diamante, y esto frecuentemente ocurre en los vÃ©rtices (donde $\beta_1 = 0$ o $\beta_2 = 0$).
:::

---

### Elastic Net: Lo Mejor de Ambos Mundos ğŸ•¸ï¸

**Elastic Net** combina las penalizaciones L1 y L2:

$$J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2$$

O equivalentemente, con un parÃ¡metro de mezcla $\alpha$:

$$J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \left[ \alpha \sum_{j=1}^{p} |\beta_j| + (1-\alpha) \sum_{j=1}^{p} \beta_j^2 \right]$$

Donde:
- $\alpha \in [0,1]$ controla la mezcla entre L1 y L2
- $\alpha = 0$: Pure Ridge
- $\alpha = 1$: Pure Lasso
- $\alpha = 0.5$: Igual peso a ambas penalizaciones

#### CaracterÃ­sticas de Elastic Net:

âœ… **Ventajas:**
- **SelecciÃ³n de variables** como Lasso
- **Estabilidad** como Ridge
- Maneja bien **grupos de variables correlacionadas**
- MÃ¡s flexible que Ridge o Lasso por separado

âŒ **Desventajas:**
- Dos hiperparÃ¡metros para ajustar ($\lambda$ y $\alpha$)
- MÃ¡s complejo computacionalmente

---

### ComparaciÃ³n Visual: Ridge vs Lasso vs Elastic Net

| **Aspecto** | **Ridge** | **Lasso** | **Elastic Net** |
|-------------|-----------|-----------|-----------------|
| **PenalizaciÃ³n** | L2: $\sum \beta_j^2$ | L1: $\sum |\beta_j|$ | L1 + L2 combinadas |
| **SelecciÃ³n de variables** | âŒ No | âœ… SÃ­ | âœ… SÃ­ |
| **Coeficientes exactamente cero** | âŒ No | âœ… SÃ­ | âœ… SÃ­ |
| **Manejo de multicolinealidad** | âœ… Excelente | âš ï¸ ProblemÃ¡tico | âœ… Muy bueno |
| **Estabilidad** | âœ… Alta | âš ï¸ Media | âœ… Alta |
| **Interpretabilidad** | âš ï¸ Media | âœ… Alta | âœ… Alta |
| **Cuando usar** | Todas las variables importan | Pocas variables importantes | Situaciones mixtas |

### Â¿CuÃ¡ndo usar cada mÃ©todo?

#### Usa **Ridge** cuando:
- Crees que **todas las variables** contribuyen al modelo
- Tienes **multicolinealidad** severa
- Quieres **estabilizar** coeficientes sin eliminar variables
- El nÃºmero de observaciones es **pequeÃ±o** relativo a variables

#### Usa **Lasso** cuando:
- Crees que **pocas variables** son realmente importantes
- Quieres un modelo **simple e interpretable**
- Necesitas **selecciÃ³n automÃ¡tica** de variables
- Tienes muchas variables **irrelevantes**

#### Usa **Elastic Net** cuando:
- No estÃ¡s seguro de cuÃ¡ntas variables son importantes
- Tienes **grupos de variables correlacionadas**
- Quieres balancear **selecciÃ³n** y **estabilidad**
- Es tu **primera opciÃ³n** cuando no conoces la estructura de los datos

---

### ValidaciÃ³n de Modelos y SelecciÃ³n de HiperparÃ¡metros

#### Â¿Por quÃ© necesitamos dividir nuestros datos?

Cuando construimos modelos de machine learning, enfrentamos un dilema fundamental: **Â¿cÃ³mo sabemos si nuestro modelo funcionarÃ¡ bien con datos nuevos?**

##### El Problema del Sobreajuste

Imagina que estÃ¡s preparÃ¡ndote para un examen. Si solo estudias las preguntas exactas que aparecerÃ¡n en el examen, podrÃ­as obtener una calificaciÃ³n perfecta. Pero si las preguntas cambian ligeramente, tu rendimiento se desplomarÃ­a. Esto es **sobreajuste**: el modelo memoriza los datos de entrenamiento pero no generaliza.

#### DivisiÃ³n TÃ­pica de Datos: Entrenamiento/ValidaciÃ³n/Prueba

La estrategia estÃ¡ndar es dividir nuestros datos en **tres conjuntos**:

```
ğŸ“Š Dataset Completo (100%)
â”œâ”€â”€ ğŸ‹ï¸ Entrenamiento (60%) - Para ajustar coeficientes
â”œâ”€â”€ ğŸ¯ ValidaciÃ³n (20%)     - Para seleccionar hiperparÃ¡metros  
â””â”€â”€ ğŸ§ª Prueba (20%)         - Para evaluaciÃ³n final
```

##### Conjunto de Entrenamiento (60%)
- **PropÃ³sito**: Ajustar los coeficientes $\beta$ del modelo
- **AnalogÃ­a**: Los ejercicios que haces para aprender

##### Conjunto de ValidaciÃ³n (20%)
- **PropÃ³sito**: Comparar diferentes hiperparÃ¡metros (como $\lambda$ en Ridge/Lasso)
- **AnalogÃ­a**: ExÃ¡menes de prÃ¡ctica para decidir quÃ© estrategia de estudio funciona mejor

##### Conjunto de Prueba (20%)
- **PropÃ³sito**: EvaluaciÃ³n final y honesta del modelo
- **AnalogÃ­a**: El examen final real
- **âš ï¸ Regla de Oro**: Â¡Solo se usa UNA vez al final!

#### Â¿QuÃ© pasa si tenemos pocos datos?

Cuando nuestro dataset es pequeÃ±o (< 1000 observaciones), dividir en tres partes puede ser problemÃ¡tico:

âŒ **Problemas con datasets pequeÃ±os:**
- Conjunto de entrenamiento muy pequeÃ±o â†’ modelo pobre
- Conjunto de validaciÃ³n pequeÃ±o â†’ selecciÃ³n inestable de hiperparÃ¡metros
- Conjunto de prueba pequeÃ±o â†’ evaluaciÃ³n poco confiable

**SoluciÃ³n**: Â¡ValidaciÃ³n Cruzada!

---

#### ValidaciÃ³n Cruzada (Cross-Validation)

La **validaciÃ³n cruzada** es una tÃ©cnica que maximiza el uso de nuestros datos limitados. En lugar de usar una sola divisiÃ³n, usamos **mÃºltiples divisiones**.

##### ValidaciÃ³n Cruzada k-fold

El mÃ©todo mÃ¡s comÃºn es **k-fold cross-validation**:

1. **Dividir** el dataset en $k$ "pliegues" (folds) de igual tamaÃ±o
2. **Repetir** $k$ veces:
   - Usar $k-1$ pliegues para entrenamiento
   - Usar 1 pliegue para validaciÃ³n
3. **Promediar** los resultados de las $k$ evaluaciones

```{python}
#| label: cv-visualization
#| fig-cap: "VisualizaciÃ³n de 5-Fold Cross Validation mostrando cÃ³mo se dividen los datos en cada iteraciÃ³n"
#| fig-width: 12
#| fig-height: 8
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib
matplotlib.rcParams['figure.dpi'] = 150  # Higher DPI for better quality

# VisualizaciÃ³n de 5-Fold Cross Validation
fig, axes = plt.subplots(5, 1, figsize=(12, 8))
fig.suptitle('ValidaciÃ³n Cruzada 5-Fold: DivisiÃ³n de Datos', fontsize=16, fontweight='bold')

k = 5
colors = ['lightblue', 'lightcoral']

for fold in range(k):
    ax = axes[fold]
    
    # Crear rectÃ¡ngulos para cada fold
    for i in range(k):
        if i == fold:
            # Este es el fold de validaciÃ³n
            rect = patches.Rectangle((i, 0), 1, 1, linewidth=2, 
                                   edgecolor='red', facecolor=colors[1])
            ax.add_patch(rect)
        else:
            # Estos son los folds de entrenamiento
            rect = patches.Rectangle((i, 0), 1, 1, linewidth=2, 
                                   edgecolor='blue', facecolor=colors[0])
            ax.add_patch(rect)
    
    # Configurar ejes
    ax.set_xlim(0, k)
    ax.set_ylim(0, 1)
    ax.set_xticks(np.arange(k) + 0.5)
    ax.set_xticklabels([f'Fold {i+1}' for i in range(k)])
    ax.set_yticks([])
    ax.set_ylabel(f'IteraciÃ³n {fold+1}', rotation=0, ha='right', va='center')
    
    # AÃ±adir tÃ­tulo para la primera iteraciÃ³n
    if fold == 0:
        ax.text(k/2, 1.3, 'DivisiÃ³n de Datos en Cada IteraciÃ³n', 
                ha='center', va='center', fontsize=12, fontweight='bold')

# AÃ±adir leyenda
legend_elements = [patches.Patch(facecolor=colors[0], edgecolor='blue', label='Entrenamiento'),
                  patches.Patch(facecolor=colors[1], edgecolor='red', label='ValidaciÃ³n')]
fig.legend(handles=legend_elements, loc='center right', bbox_to_anchor=(0.95, 0.5))

plt.tight_layout()
plt.show()
```

##### Ventajas de la ValidaciÃ³n Cruzada

âœ… **Maximiza el uso de datos**: Cada observaciÃ³n se usa tanto para entrenamiento como validaciÃ³n

âœ… **EstimaciÃ³n mÃ¡s robusta**: Promedia mÃºltiples evaluaciones independientes

âœ… **Reduce la varianza**: Menos dependiente de una divisiÃ³n particular

âœ… **Detecta inestabilidad**: Si los resultados varÃ­an mucho entre folds, el modelo es inestable

#### ValidaciÃ³n Cruzada para SelecciÃ³n de HiperparÃ¡metros

En regresiÃ³n regularizada, usamos CV para encontrar el mejor $\lambda$:

```{python}
#| label: validation-curve
#| fig-cap: "Curva de validaciÃ³n mostrando cÃ³mo seleccionar el hiperparÃ¡metro Ã³ptimo Î» usando validaciÃ³n cruzada"
#| fig-width: 12
#| fig-height: 6
#| echo: false

# Ejemplo conceptual de selecciÃ³n de hiperparÃ¡metros
alphas = np.logspace(-3, 2, 20)  # Valores de lambda a probar
cv_scores = []

print("ğŸ¯ SELECCIÃ“N DE HIPERPARÃMETROS CON VALIDACIÃ“N CRUZADA")
print("=" * 60)
print("Para cada valor de Î»:")
print("  1. Aplicar 5-fold CV")
print("  2. Calcular error promedio")
print("  3. Seleccionar Î» con menor error")

# Simular scores para visualizaciÃ³n
np.random.seed(42)
true_minimum = 0.1
cv_scores = []

for alpha in alphas:
    # Simular error de CV (menor cerca del Ã³ptimo)
    distance = abs(np.log10(alpha) - np.log10(true_minimum))
    base_error = 0.5 + distance**2 * 0.1
    noise = np.random.normal(0, 0.05)
    cv_scores.append(base_error + noise)

cv_scores = np.array(cv_scores)

# Encontrar el mejor alpha
best_idx = np.argmin(cv_scores)
best_alpha = alphas[best_idx]

# Graficar curva de validaciÃ³n
plt.figure(figsize=(12, 6))
plt.plot(alphas, cv_scores, 'bo-', alpha=0.7, label='Error de ValidaciÃ³n Cruzada')
plt.axvline(x=best_alpha, color='red', linestyle='--', 
           label=f'Î» Ã³ptimo = {best_alpha:.3f}')
plt.scatter([best_alpha], [cv_scores[best_idx]], color='red', s=100, zorder=5)

plt.xscale('log')
plt.xlabel('Î» (ParÃ¡metro de RegularizaciÃ³n)')
plt.ylabel('Error de ValidaciÃ³n Cruzada')
plt.title('Curva de ValidaciÃ³n: SelecciÃ³n de HiperparÃ¡metros')
plt.legend()
plt.grid(True, alpha=0.3)

# AÃ±adir anotaciones
plt.annotate('Infraajuste\n(Î» muy alto)', 
            xy=(10, 0.7), xytext=(50, 0.8),
            arrowprops=dict(arrowstyle='->', color='orange', alpha=0.7),
            fontsize=10, ha='center', color='orange')

plt.annotate('Sobreajuste\n(Î» muy bajo)', 
            xy=(0.01, 0.6), xytext=(0.003, 0.9),
            arrowprops=dict(arrowstyle='->', color='purple', alpha=0.7),
            fontsize=10, ha='center', color='purple')

plt.tight_layout()
plt.show()

print(f"\nğŸ“ˆ Resultado: Î» Ã³ptimo = {best_alpha:.4f}")
print(f"ğŸ“‰ Error de CV mÃ­nimo = {cv_scores[best_idx]:.4f}")
```

#### Proceso Completo de ValidaciÃ³n

El flujo completo para modelos regularizados es:

```
1. ğŸ“Š Dividir datos originales
   â””â”€â”€ 80% para desarrollo (entrenamiento + validaciÃ³n)
   â””â”€â”€ 20% para prueba final (Â¡NO TOCAR hasta el final!)

2. ğŸ”„ En el conjunto de desarrollo:
   â””â”€â”€ Para cada Î» candidato:
       â”œâ”€â”€ Aplicar k-fold CV
       â”œâ”€â”€ Calcular error promedio
       â””â”€â”€ Guardar resultado

3. ğŸ¯ Seleccionar Î» con menor error de CV

4. ğŸ—ï¸ Entrenar modelo final con Î» Ã³ptimo en TODO el conjunto de desarrollo

5. ğŸ§ª EvaluaciÃ³n final en conjunto de prueba
```

#### Variantes de ValidaciÃ³n Cruzada

##### Leave-One-Out CV (LOOCV)
- **k = n** (nÃºmero de observaciones)
- **Ventaja**: MÃ¡ximo uso de datos para entrenamiento
- **Desventaja**: Computacionalmente costoso, alta varianza

##### Stratified CV
- **Para problemas de clasificaciÃ³n**
- Mantiene la proporciÃ³n de clases en cada fold

##### Time Series CV
- **Para datos temporales**
- Respeta el orden temporal (no mezcla futuro con pasado)