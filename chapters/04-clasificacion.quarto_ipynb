{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clasificación\n",
        "\n",
        "## Introducción al Problema de Clasificación\n",
        "\n",
        "En los capítulos anteriores hemos trabajado con problemas de regresión, donde la variable respuesta $Y$ es cuantitativa (continua). En este capítulo estudiaremos los **problemas de clasificación**, donde la variakbble respuesta $Y$ es **cualitativa** (categórica o discreta).\n",
        "\n",
        "### Definición Formal\n",
        "\n",
        "Un problema de clasificación consiste en asignar una observación $\\mathbf{x} = (x_1, x_2, ..., x_p)$ a una de $K$ clases o categorías posibles. Formalmente:\n",
        "\n",
        "- **Entrada**: Un vector de características $\\mathbf{x} \\in \\mathbb{R}^p$\n",
        "- **Salida**: Una etiqueta de clase $y \\in \\mathcal{C} = \\{C_1, C_2, ..., C_K\\}$\n",
        "\n",
        "Donde $\\mathcal{C}$ es el conjunto finito de clases posibles.\n",
        "\n",
        "### Ejemplos de Problemas de Clasificación\n",
        "\n",
        "1. **Clasificación binaria** ($K=2$):\n",
        "   - Detección de spam en correos electrónicos (spam/no spam)\n",
        "   - Diagnóstico médico (enfermo/sano)\n",
        "   - Aprobación de crédito (aprobado/rechazado)\n",
        "\n",
        "2. **Clasificación multiclase** ($K>2$):\n",
        "   - Reconocimiento de dígitos escritos a mano (0-9)\n",
        "   - Clasificación de tipos de flores (setosa/versicolor/virginica)\n",
        "   - Categorización de noticias (deportes/política/tecnología/etc.)\n",
        "\n",
        "### Objetivo del Aprendizaje\n",
        "\n",
        "El objetivo es aprender una función de clasificación $f: \\mathbb{R}^p \\rightarrow \\mathcal{C}$ que minimice el error de clasificación esperado:\n",
        "\n",
        "$$\\mathbb{E}[L(Y, f(\\mathbf{X}))]$$\n",
        "\n",
        "Donde $L$ es una función de pérdida. La función de pérdida más común es la **pérdida 0-1**:\n",
        "\n",
        "$$L_{0-1}(y, \\hat{y}) = \\begin{cases}\n",
        "0 & \\text{si } y = \\hat{y} \\\\\n",
        "1 & \\text{si } y \\neq \\hat{y}\n",
        "\\end{cases}$$\n",
        "\n",
        "## Funciones de Pérdida en Clasificación\n",
        "\n",
        "Aunque la pérdida 0-1 es intuitiva y directamente relacionada con la tasa de error, presenta limitaciones importantes: no es diferenciable y no proporciona información sobre la **confianza** de las predicciones. Por esto, en la práctica se utilizan funciones de pérdida alternativas que trabajan con probabilidades.\n",
        "\n",
        "### Clasificación Binaria: Pérdidas Probabilísticas\n",
        "\n",
        "Para clasificación binaria, donde $y \\in \\{0, 1\\}$, consideramos predicciones probabilísticas $\\hat{p} = P(\\hat{Y} = 1 | \\mathbf{x})$. Las funciones de pérdida más importantes son:\n",
        "\n",
        "#### Pérdida de Brier (Brier Score)\n",
        "\n",
        "La **pérdida de Brier** o pérdida cuadrática mide el error cuadrático medio entre las probabilidades predichas y los valores reales:\n",
        "\n",
        "$$L_{\\text{Brier}}(y, \\hat{p}) = (y - \\hat{p})^2$$\n",
        "\n",
        "Para un conjunto de $n$ observaciones:\n",
        "\n",
        "$$\\text{Brier Score} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{p}_i)^2$$\n",
        "\n",
        "**Propiedades:**\n",
        "\n",
        "- Rango: $[0, 1]$ (menor es mejor)\n",
        "- Es una regla de puntuación **propia** (proper scoring rule)\n",
        "- Penaliza fuertemente predicciones confiadas pero incorrectas\n",
        "- Se puede descomponer en: calibración + refinamiento\n",
        "\n",
        "#### Pérdida Logarítmica (Log Loss o Entropía Cruzada Binaria)\n",
        "\n",
        "La **pérdida logarítmica** mide la distancia entre la distribución verdadera y la predicha usando la divergencia de Kullback-Leibler:\n",
        "\n",
        "$$L_{\\text{log}}(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})]$$\n",
        "\n",
        "Equivalentemente:\n",
        "$$L_{\\text{log}}(y, \\hat{p}) = \\begin{cases}\n",
        "-\\log(\\hat{p}) & \\text{si } y = 1 \\\\\n",
        "-\\log(1-\\hat{p}) & \\text{si } y = 0\n",
        "\\end{cases}$$\n",
        "\n",
        "Para un conjunto de observaciones:\n",
        "\n",
        "$$\\text{Log Loss} = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(\\hat{p}_i) + (1-y_i) \\log(1-\\hat{p}_i)]$$\n",
        "\n",
        "**Propiedades:**\n",
        "\n",
        "- Rango: $[0, \\infty)$ (menor es mejor)\n",
        "- También es una regla de puntuación propia\n",
        "- Penaliza infinitamente predicciones completamente incorrectas ($\\hat{p} = 0$ cuando $y = 1$)\n",
        "- Es la función objetivo en regresión logística\n",
        "\n",
        "### Comparación de Funciones de Pérdida"
      ],
      "id": "0ae73804"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 6
      },
      "source": [
        "#| label: classification-loss-functions\n",
        "#| fig-cap: Funciones de perdidas para clasificación\n",
        "#| echo: false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Rango de probabilidades predichas\n",
        "p_hat = np.linspace(0.001, 0.999, 1000)\n",
        "\n",
        "# Pérdidas cuando y = 1\n",
        "brier_y1 = (1 - p_hat)**2\n",
        "log_y1 = -np.log(p_hat)\n",
        "zero_one_y1 = (p_hat < 0.5).astype(float)\n",
        "\n",
        "# Pérdidas cuando y = 0\n",
        "brier_y0 = p_hat**2\n",
        "log_y0 = -np.log(1 - p_hat)\n",
        "zero_one_y0 = (p_hat >= 0.5).astype(float)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Gráfica cuando y = 1\n",
        "axes[0].plot(p_hat, brier_y1, label='Brier', linewidth=2)\n",
        "axes[0].plot(p_hat, log_y1, label='Log Loss', linewidth=2)\n",
        "axes[0].plot(p_hat, zero_one_y1, label='0-1', linewidth=2, linestyle='--')\n",
        "axes[0].set_xlabel('Probabilidad predicha $\\hat{p}$')\n",
        "axes[0].set_ylabel('Pérdida')\n",
        "axes[0].set_title('Pérdida cuando $y = 1$')\n",
        "axes[0].set_ylim([0, 5])\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfica cuando y = 0\n",
        "axes[1].plot(p_hat, brier_y0, label='Brier', linewidth=2)\n",
        "axes[1].plot(p_hat, log_y0, label='Log Loss', linewidth=2)\n",
        "axes[1].plot(p_hat, zero_one_y0, label='0-1', linewidth=2, linestyle='--')\n",
        "axes[1].set_xlabel('Probabilidad predicha $\\hat{p}$')\n",
        "axes[1].set_ylabel('Pérdida')\n",
        "axes[1].set_title('Pérdida cuando $y = 0$')\n",
        "axes[1].set_ylim([0, 5])\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "classification-loss-functions",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reglas de Puntuación Propias\n",
        "\n",
        "Una **regla de puntuación propia** (proper scoring rule) es una función de pérdida que incentiva al modelo a reportar sus verdaderas probabilidades. Formalmente, una función $S(p, y)$ es propia si:\n",
        "\n",
        "$$\\mathbb{E}_{Y \\sim p^*}[S(p^*, Y)] \\leq \\mathbb{E}_{Y \\sim p^*}[S(p, Y)]$$\n",
        "\n",
        "Donde $p^*$ es la distribución verdadera. Tanto la pérdida de Brier como la log loss son propias, mientras que la pérdida 0-1 no lo es.\n",
        "\n",
        "### Ventajas y Desventajas\n",
        "\n",
        "**Pérdida de Brier:**\n",
        "\n",
        "- ✓ Interpretación directa como MSE de probabilidades\n",
        "- ✓ Acotada en $[0,1]$\n",
        "- ✓ Menos sensible a predicciones extremas incorrectas\n",
        "- ✗ Menos utilizada en optimización de modelos\n",
        "\n",
        "**Pérdida Logarítmica:**\n",
        "\n",
        "- ✓ Base teórica sólida (teoría de información)\n",
        "- ✓ Función objetivo natural para muchos modelos (logística, redes neuronales)\n",
        "- ✓ Diferenciable y convexa\n",
        "- ✗ No acotada superiormente\n",
        "- ✗ Muy sensible a predicciones extremas incorrectas\n",
        "\n",
        "## Modelos para Clasificación Binaria\n",
        "\n",
        "### Clasificador de Bayes para el Caso Binario\n",
        "\n",
        "El **clasificador de Bayes** es el clasificador óptimo teórico que minimiza el error de clasificación. Para el caso binario con clases $\\{0, 1\\}$, clasifica según:\n",
        "\n",
        "$$\\hat{y}(\\mathbf{x}) = \\begin{cases}\n",
        "1 & \\text{si } P(Y = 1 | \\mathbf{X} = \\mathbf{x}) > 0.5 \\\\\n",
        "0 & \\text{si } P(Y = 1 | \\mathbf{X} = \\mathbf{x}) \\leq 0.5\n",
        "\\end{cases}$$\n",
        "\n",
        "O más generalmente, con un umbral $\\tau$:\n",
        "\n",
        "$$\\hat{y}(\\mathbf{x}) = \\mathbb{1}[P(Y = 1 | \\mathbf{X} = \\mathbf{x}) > \\tau]$$\n",
        "\n",
        "#### Estimación mediante el Teorema de Bayes\n",
        "\n",
        "Usando el teorema de Bayes:\n",
        "\n",
        "$$P(Y = k | \\mathbf{X} = \\mathbf{x}) = \\frac{P(\\mathbf{X} = \\mathbf{x} | Y = k) \\cdot P(Y = k)}{P(\\mathbf{X} = \\mathbf{x})}$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "- $P(Y = k)$ es la **probabilidad a priori** de la clase $k$\n",
        "- $P(\\mathbf{X} = \\mathbf{x} | Y = k)$ es la **verosimilitud** de observar $\\mathbf{x}$ dado que pertenece a la clase $k$\n",
        "- $P(\\mathbf{X} = \\mathbf{x})$ es la **evidencia** (constante de normalización)\n",
        "\n",
        "Como $P(\\mathbf{X} = \\mathbf{x})$ es igual para todas las clases, la decisión se basa en:\n",
        "\n",
        "$$\\hat{y} = \\arg\\max_k P(\\mathbf{X} = \\mathbf{x} | Y = k) \\cdot P(Y = k)$$\n",
        "\n",
        "#### Naive Bayes: Simplificando el Problema\n",
        "\n",
        "El problema principal del clasificador de Bayes es estimar $P(\\mathbf{X} = \\mathbf{x} | Y = k)$ en alta dimensión. Con $p$ características, necesitamos estimar la distribución conjunta de todas las variables, lo cual es computacionalmente intratable cuando $p$ es grande.\n",
        "\n",
        "El clasificador **Naive Bayes** resuelve este problema mediante una **asunción de independencia condicional**: asume que las características son condicionalmente independientes dada la clase:\n",
        "\n",
        "$$P(\\mathbf{X} = \\mathbf{x} | Y = k) = P(x_1, x_2, ..., x_p | Y = k) = \\prod_{j=1}^{p} P(x_j | Y = k)$$\n",
        "\n",
        "Esta asunción, aunque \"ingenua\" (naive), simplifica enormemente el cálculo y funciona sorprendentemente bien en la práctica.\n",
        "\n",
        "#### Tipos de Naive Bayes\n",
        "\n",
        "Dependiendo del tipo de características, existen diferentes variantes:\n",
        "\n",
        "##### 1. **Gaussian Naive Bayes** (características continuas)\n",
        "\n",
        "Asume que las características siguen una distribución normal dentro de cada clase:\n",
        "\n",
        "$$P(x_j | Y = k) = \\frac{1}{\\sqrt{2\\pi\\sigma_{jk}^2}} \\exp\\left(-\\frac{(x_j - \\mu_{jk})^2}{2\\sigma_{jk}^2}\\right)$$\n",
        "\n",
        "Donde $\\mu_{jk}$ y $\\sigma_{jk}^2$ son la media y varianza de la característica $j$ en la clase $k$.\n",
        "\n",
        "##### 2. **Multinomial Naive Bayes** (características discretas/conteos)\n",
        "\n",
        "Utilizado para datos de conteo (ej. frecuencia de palabras en clasificación de texto):\n",
        "\n",
        "$$P(\\mathbf{x} | Y = k) = \\frac{N_k!}{\\prod_j x_j!} \\prod_{j=1}^{p} \\theta_{jk}^{x_j}$$\n",
        "\n",
        "Donde $\\theta_{jk}$ es la probabilidad de la característica $j$ en la clase $k$.\n",
        "\n",
        "##### 3. **Bernoulli Naive Bayes** (características binarias)\n",
        "\n",
        "Para características binarias (presencia/ausencia):\n",
        "\n",
        "$$P(\\mathbf{x} | Y = k) = \\prod_{j=1}^{p} \\theta_{jk}^{x_j} (1-\\theta_{jk})^{1-x_j}$$\n",
        "\n",
        "#### Ventajas y Desventajas de Naive Bayes\n",
        "\n",
        "**Ventajas:**\n",
        "\n",
        "- ✓ Rápido de entrenar y predecir\n",
        "- ✓ Funciona bien con pocos datos de entrenamiento\n",
        "- ✓ Maneja naturalmente múltiples clases\n",
        "- ✓ Robusto ante características irrelevantes\n",
        "- ✓ Proporciona estimaciones de probabilidad\n",
        "\n",
        "**Desventajas:**\n",
        "\n",
        "- ✗ La asunción de independencia es frecuentemente violada\n",
        "- ✗ Puede dar estimaciones de probabilidad sesgadas\n",
        "- ✗ Sensible a la maldición de la dimensionalidad con Gaussian NB\n",
        "\n",
        "#### Ejemplos en Python\n",
        "\n",
        "##### 1. Ejemplo Básico: Gaussian Naive Bayes\n",
        "\n",
        "Comenzamos con un ejemplo simple de clasificación binaria usando Gaussian Naive Bayes:"
      ],
      "id": "cf8311e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-basic\n",
        "#| echo: true\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# Generar datos sintéticos para clasificación binaria\n",
        "np.random.seed(42)\n",
        "X, y = make_classification(\n",
        "    n_samples=300,\n",
        "    n_features=2,        # 2 características para visualización fácil\n",
        "    n_informative=2,     # Ambas características son informativas\n",
        "    n_redundant=0,       # Sin características redundantes\n",
        "    n_clusters_per_class=2,  # 2 grupos por clase\n",
        "    flip_y=0.05,         # 5% de ruido en las etiquetas\n",
        "    class_sep=0.8,       # Separación entre clases\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Dividir en conjunto de entrenamiento (70%) y prueba (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Dimensiones de los datos:\")\n",
        "print(f\"  Entrenamiento: {X_train.shape}\")\n",
        "print(f\"  Prueba: {X_test.shape}\")"
      ],
      "id": "naive-bayes-basic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-train\n",
        "#| echo: true\n",
        "\n",
        "# Crear y entrenar el modelo Gaussian Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred = gnb.predict(X_test)\n",
        "y_proba = gnb.predict_proba(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Exactitud (Accuracy): {accuracy:.3f}\")\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(pd.DataFrame(cm,\n",
        "                   columns=['Predicho 0', 'Predicho 1'],\n",
        "                   index=['Real 0', 'Real 1']))\n",
        "\n",
        "# Parámetros aprendidos por el modelo\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"PARÁMETROS APRENDIDOS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nProbabilidades a priori (prior):\")\n",
        "print(f\"  P(Y=0) = {gnb.class_prior_[0]:.3f}\")\n",
        "print(f\"  P(Y=1) = {gnb.class_prior_[1]:.3f}\")\n",
        "\n",
        "print(f\"\\nMedias de cada característica por clase:\")\n",
        "for i, clase in enumerate([0, 1]):\n",
        "    print(f\"  Clase {clase}: μ₁={gnb.theta_[i, 0]:.3f}, μ₂={gnb.theta_[i, 1]:.3f}\")\n",
        "\n",
        "print(f\"\\nVarianzas de cada característica por clase:\")\n",
        "for i, clase in enumerate([0, 1]):\n",
        "    print(f\"  Clase {clase}: σ²₁={gnb.var_[i, 0]:.3f}, σ²₂={gnb.var_[i, 1]:.3f}\")"
      ],
      "id": "naive-bayes-train",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2. Visualización de la Frontera de Decisión"
      ],
      "id": "de269140"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 5
      },
      "source": [
        "#| label: naive-bayes-visualization\n",
        "#| fig-cap: Frontera de decisión de Gaussian Naive Bayes\n",
        "#| echo: true\n",
        "\n",
        "# Función auxiliar para visualizar fronteras de decisión\n",
        "def visualizar_clasificador(X, y, classifier, title):\n",
        "    \"\"\"\n",
        "    Visualiza la frontera de decisión de un clasificador\n",
        "\n",
        "    Parámetros:\n",
        "    - X: características (n_samples, 2)\n",
        "    - y: etiquetas (n_samples,)\n",
        "    - classifier: modelo entrenado\n",
        "    - title: título del gráfico\n",
        "    \"\"\"\n",
        "    h = 0.02  # Tamaño del paso en la malla\n",
        "\n",
        "    # Crear una malla de puntos para evaluar el clasificador\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predecir probabilidades para cada punto de la malla\n",
        "    Z = classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Crear la visualización\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Panel 1: Datos y frontera\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.4, cmap='RdBu_r', levels=20)\n",
        "    plt.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
        "    plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', edgecolors='black',\n",
        "                s=50, label='Clase 0', alpha=0.7)\n",
        "    plt.scatter(X[y==1, 0], X[y==1, 1], c='red', edgecolors='black',\n",
        "                s=50, label='Clase 1', alpha=0.7)\n",
        "    plt.xlabel('Característica 1')\n",
        "    plt.ylabel('Característica 2')\n",
        "    plt.title(f'{title} - Frontera de Decisión')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Panel 2: Mapa de probabilidades\n",
        "    plt.subplot(1, 2, 2)\n",
        "    contour = plt.contourf(xx, yy, Z, levels=20, cmap='RdBu_r', alpha=0.8)\n",
        "    plt.colorbar(contour, label='P(Y=1|X)')\n",
        "    plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', edgecolors='black',\n",
        "                s=30, alpha=0.5)\n",
        "    plt.scatter(X[y==1, 0], X[y==1, 1], c='red', edgecolors='black',\n",
        "                s=30, alpha=0.5)\n",
        "    plt.xlabel('Característica 1')\n",
        "    plt.ylabel('Característica 2')\n",
        "    plt.title(f'{title} - Probabilidades')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar nuestro modelo entrenado\n",
        "visualizar_clasificador(X_train, y_train, gnb, 'Gaussian Naive Bayes')"
      ],
      "id": "naive-bayes-visualization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3. Comparación de Variantes de Naive Bayes\n",
        "\n",
        "Ahora comparemos las tres variantes principales de Naive Bayes:"
      ],
      "id": "d5481ea5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-variants-prep\n",
        "#| echo: true\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Preparar diferentes versiones de los datos para cada variante\n",
        "\n",
        "# 1. Gaussian NB: usa los datos originales\n",
        "X_gaussian = X_train.copy()\n",
        "\n",
        "# 2. Multinomial NB: necesita valores no negativos (frecuencias)\n",
        "scaler = MinMaxScaler()\n",
        "X_multinomial = scaler.fit_transform(X_train) + 0.1  # Asegurar valores positivos\n",
        "\n",
        "# 3. Bernoulli NB: necesita valores binarios\n",
        "X_bernoulli = (X_train > np.median(X_train, axis=0)).astype(float)\n",
        "\n",
        "print(\"Forma de los datos para cada variante:\")\n",
        "print(f\"  Gaussian: {X_gaussian.shape} - Valores continuos\")\n",
        "print(f\"  Multinomial: {X_multinomial.shape} - Valores positivos\")\n",
        "print(f\"  Bernoulli: {X_bernoulli.shape} - Valores binarios\")\n",
        "\n",
        "# Mostrar ejemplos de los primeros 3 datos\n",
        "print(\"\\nEjemplo de transformación (primeras 3 muestras, primera característica):\")\n",
        "print(f\"  Original: {X_gaussian[:3, 0]}\")\n",
        "print(f\"  Multinomial: {X_multinomial[:3, 0]}\")\n",
        "print(f\"  Bernoulli: {X_bernoulli[:3, 0]}\")"
      ],
      "id": "naive-bayes-variants-prep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-variants-train\n",
        "#| echo: true\n",
        "\n",
        "# Entrenar las tres variantes\n",
        "modelos = {\n",
        "    'Gaussian NB': (GaussianNB(), X_gaussian),\n",
        "    'Multinomial NB': (MultinomialNB(), X_multinomial),\n",
        "    'Bernoulli NB': (BernoulliNB(), X_bernoulli)\n",
        "}\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for nombre, (modelo, X_train_variant) in modelos.items():\n",
        "    # Entrenar\n",
        "    modelo.fit(X_train_variant, y_train)\n",
        "\n",
        "    # Preparar datos de prueba según la variante\n",
        "    if nombre == 'Gaussian NB':\n",
        "        X_test_variant = X_test\n",
        "    elif nombre == 'Multinomial NB':\n",
        "        X_test_variant = scaler.transform(X_test) + 0.1\n",
        "    else:  # Bernoulli\n",
        "        X_test_variant = (X_test > np.median(X_train, axis=0)).astype(float)\n",
        "\n",
        "    # Predecir\n",
        "    y_pred = modelo.predict(X_test_variant)\n",
        "\n",
        "    # Guardar resultados\n",
        "    resultados[nombre] = {\n",
        "        'modelo': modelo,\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{nombre}:\")\n",
        "    print(f\"  Accuracy: {resultados[nombre]['accuracy']:.3f}\")"
      ],
      "id": "naive-bayes-variants-train",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 10,
        "fig-height": 4
      },
      "source": [
        "#| label: naive-bayes-comparison-plot\n",
        "#| fig-cap: Comparación de variantes de Naive Bayes\n",
        "#| echo: true\n",
        "\n",
        "# Visualizar comparación de resultados\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "# Gráfico de barras de accuracy\n",
        "nombres = list(resultados.keys())\n",
        "accuracies = [resultados[n]['accuracy'] for n in nombres]\n",
        "\n",
        "bars = axes[0].bar(nombres, accuracies, color=['blue', 'green', 'red'], alpha=0.7)\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('Comparación de Exactitud')\n",
        "axes[0].set_ylim([0, 1])\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Añadir valores en las barras\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                 f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Matrices de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "axes[1].axis('off')\n",
        "for i, nombre in enumerate(nombres):\n",
        "    cm = confusion_matrix(y_test, resultados[nombre]['y_pred'])\n",
        "\n",
        "    # Crear subtabla\n",
        "    ax_sub = plt.subplot2grid((1, 6), (0, 4 + i*2//3), colspan=2//3 + 1)\n",
        "    ax_sub.imshow(cm, cmap='Blues', aspect='auto')\n",
        "    ax_sub.set_title(f'{nombre.split()[0]} NB', fontsize=9)\n",
        "\n",
        "    # Añadir texto en cada celda\n",
        "    for (i, j), val in np.ndenumerate(cm):\n",
        "        ax_sub.text(j, i, str(val), ha='center', va='center')\n",
        "\n",
        "    if i == 0:\n",
        "        ax_sub.set_ylabel('Real', fontsize=8)\n",
        "    ax_sub.set_xlabel('Pred', fontsize=8)\n",
        "    ax_sub.set_xticks([0, 1])\n",
        "    ax_sub.set_yticks([0, 1])\n",
        "    ax_sub.tick_params(labelsize=8)\n",
        "\n",
        "plt.suptitle('Comparación de Variantes de Naive Bayes', y=1.05)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "naive-bayes-comparison-plot",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 4. Ejemplo Práctico: Clasificación de Texto"
      ],
      "id": "a2fef4c6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-text-example\n",
        "#| echo: true\n",
        "\n",
        "# Simular un conjunto de datos de texto\n",
        "# Imaginemos que tenemos documentos con conteo de palabras\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"EJEMPLO: CLASIFICACIÓN DE DOCUMENTOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Crear datos simulados de texto\n",
        "np.random.seed(42)\n",
        "n_docs = 100\n",
        "n_palabras = 10\n",
        "\n",
        "# Nombres de las \"palabras\" para mejor interpretación\n",
        "palabras = ['tecnología', 'computadora', 'software', 'datos', 'algoritmo',\n",
        "            'deporte', 'equipo', 'juego', 'campeonato', 'jugador']\n",
        "\n",
        "# Crear matriz de frecuencias\n",
        "# Clase 0: documentos sobre tecnología (más palabras 0-4)\n",
        "# Clase 1: documentos sobre deportes (más palabras 5-9)\n",
        "X_text = np.random.poisson(1, (n_docs, n_palabras))\n",
        "y_text = np.array([0] * 50 + [1] * 50)  # 50 docs de cada clase\n",
        "\n",
        "# Sesgar frecuencias según la clase\n",
        "X_text[:50, :5] *= 3   # Docs de tecnología: más palabras técnicas\n",
        "X_text[50:, 5:] *= 3   # Docs de deportes: más palabras deportivas\n",
        "\n",
        "# Crear DataFrame para mejor visualización\n",
        "df_text = pd.DataFrame(X_text, columns=palabras)\n",
        "df_text['clase'] = y_text\n",
        "df_text['tipo_documento'] = df_text['clase'].map({0: 'Tecnología', 1: 'Deportes'})\n",
        "\n",
        "print(\"\\nPrimeros 5 documentos:\")\n",
        "print(df_text.head())\n",
        "\n",
        "print(\"\\nEstadísticas por clase:\")\n",
        "print(df_text.groupby('tipo_documento')[palabras].mean().round(2))"
      ],
      "id": "naive-bayes-text-example",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-text-train\n",
        "#| echo: true\n",
        "\n",
        "# Dividir datos de texto\n",
        "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(\n",
        "    X_text, y_text, test_size=0.3, random_state=42, stratify=y_text\n",
        ")\n",
        "\n",
        "# Entrenar Multinomial Naive Bayes (ideal para datos de conteo)\n",
        "mnb_text = MultinomialNB(alpha=1.0)  # alpha: parámetro de suavizado Laplace\n",
        "mnb_text.fit(X_text_train, y_text_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_text = mnb_text.predict(X_text_test)\n",
        "y_proba_text = mnb_text.predict_proba(X_text_test)\n",
        "\n",
        "# Evaluación\n",
        "print(\"Resultados de Clasificación de Texto:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_text_test, y_pred_text):.3f}\")\n",
        "\n",
        "# Matriz de confusión\n",
        "cm_text = confusion_matrix(y_text_test, y_pred_text)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(pd.DataFrame(cm_text,\n",
        "                   columns=['Pred Tecnología', 'Pred Deportes'],\n",
        "                   index=['Real Tecnología', 'Real Deportes']))\n",
        "\n",
        "# Importancia de las palabras\n",
        "print(\"\\nImportancia de palabras por clase (log-probabilidades):\")\n",
        "log_probs = mnb_text.feature_log_prob_\n",
        "importancia_df = pd.DataFrame(log_probs.T,\n",
        "                               columns=['Tecnología', 'Deportes'],\n",
        "                               index=palabras)\n",
        "print(importancia_df.round(3))"
      ],
      "id": "naive-bayes-text-train",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 5
      },
      "source": [
        "#| label: naive-bayes-text-visualization\n",
        "#| fig-cap: Importancia de palabras en clasificación de texto\n",
        "#| echo: true\n",
        "\n",
        "# Visualizar importancia de palabras\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Diferencia en log-probabilidades (palabras más discriminativas)\n",
        "diff_log_prob = log_probs[0] - log_probs[1]  # Tecnología - Deportes\n",
        "indices_sorted = np.argsort(diff_log_prob)\n",
        "\n",
        "# Panel 1: Palabras más importantes para cada clase\n",
        "y_pos = np.arange(len(palabras))\n",
        "axes[0].barh(y_pos, diff_log_prob[indices_sorted],\n",
        "             color=['red' if x < 0 else 'blue' for x in diff_log_prob[indices_sorted]],\n",
        "             alpha=0.7)\n",
        "axes[0].set_yticks(y_pos)\n",
        "axes[0].set_yticklabels([palabras[i] for i in indices_sorted])\n",
        "axes[0].set_xlabel('Diferencia en log-probabilidad\\n(← Deportes | Tecnología →)')\n",
        "axes[0].set_title('Palabras Discriminativas')\n",
        "axes[0].grid(True, alpha=0.3, axis='x')\n",
        "axes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# Panel 2: Matriz de probabilidades\n",
        "im = axes[1].imshow(np.exp(log_probs), cmap='YlOrRd', aspect='auto')\n",
        "axes[1].set_xticks(range(len(palabras)))\n",
        "axes[1].set_xticklabels(palabras, rotation=45, ha='right')\n",
        "axes[1].set_yticks([0, 1])\n",
        "axes[1].set_yticklabels(['Tecnología', 'Deportes'])\n",
        "axes[1].set_title('Probabilidades de Palabras por Clase')\n",
        "plt.colorbar(im, ax=axes[1], label='Probabilidad')\n",
        "\n",
        "# Añadir valores en la matriz\n",
        "for i in range(2):\n",
        "    for j in range(len(palabras)):\n",
        "        text = axes[1].text(j, i, f'{np.exp(log_probs[i, j]):.2f}',\n",
        "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "naive-bayes-text-visualization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5. Ejemplo con Dataset Real: Iris"
      ],
      "id": "5208cb8c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 5
      },
      "source": [
        "#| label: naive-bayes-iris\n",
        "#| fig-cap: Clasificación multiclase con Naive Bayes en dataset Iris\n",
        "#| echo: true\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Cargar dataset Iris\n",
        "iris = load_iris()\n",
        "X_iris = iris.data[:, [0, 2]]  # Usar solo 2 características para visualización\n",
        "y_iris = iris.target\n",
        "nombres_clases = iris.target_names\n",
        "nombres_features = [iris.feature_names[0], iris.feature_names[2]]\n",
        "\n",
        "print(\"Dataset Iris:\")\n",
        "print(f\"  Número de muestras: {X_iris.shape[0]}\")\n",
        "print(f\"  Número de características: {X_iris.shape[1]}\")\n",
        "print(f\"  Clases: {nombres_clases}\")\n",
        "print(f\"  Características usadas: {nombres_features}\")\n",
        "\n",
        "# Dividir datos\n",
        "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.3, random_state=42, stratify=y_iris\n",
        ")\n",
        "\n",
        "# Entrenar Gaussian Naive Bayes\n",
        "gnb_iris = GaussianNB()\n",
        "gnb_iris.fit(X_iris_train, y_iris_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_iris = gnb_iris.predict(X_iris_test)\n",
        "accuracy_iris = accuracy_score(y_iris_test, y_pred_iris)\n",
        "\n",
        "print(f\"\\nAccuracy en Iris: {accuracy_iris:.3f}\")\n",
        "\n",
        "# Visualización\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Panel 1: Datos y fronteras de decisión\n",
        "h = .02\n",
        "x_min, x_max = X_iris[:, 0].min() - 1, X_iris[:, 0].max() + 1\n",
        "y_min, y_max = X_iris[:, 1].min() - 1, X_iris[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "Z = gnb_iris.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "axes[0].contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
        "scatter = axes[0].scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris,\n",
        "                          cmap='viridis', edgecolors='black', s=50)\n",
        "axes[0].set_xlabel(nombres_features[0])\n",
        "axes[0].set_ylabel(nombres_features[1])\n",
        "axes[0].set_title('Gaussian NB - Dataset Iris (3 clases)')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Añadir leyenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor=plt.cm.viridis(i/2), label=nombres_clases[i])\n",
        "                   for i in range(3)]\n",
        "axes[0].legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "# Panel 2: Matriz de confusión\n",
        "cm_iris = confusion_matrix(y_iris_test, y_pred_iris)\n",
        "im = axes[1].imshow(cm_iris, cmap='Blues', aspect='auto')\n",
        "axes[1].set_xticks(range(3))\n",
        "axes[1].set_yticks(range(3))\n",
        "axes[1].set_xticklabels(nombres_clases)\n",
        "axes[1].set_yticklabels(nombres_clases)\n",
        "axes[1].set_xlabel('Predicción')\n",
        "axes[1].set_ylabel('Valor Real')\n",
        "axes[1].set_title(f'Matriz de Confusión (Accuracy: {accuracy_iris:.3f})')\n",
        "\n",
        "# Añadir valores\n",
        "for (i, j), val in np.ndenumerate(cm_iris):\n",
        "    axes[1].text(j, i, str(val), ha='center', va='center',\n",
        "                 color='white' if val > cm_iris.max()/2 else 'black')\n",
        "\n",
        "plt.colorbar(im, ax=axes[1])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "naive-bayes-iris",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 6. Implementación Desde Cero de Gaussian Naive Bayes\n",
        "\n",
        "Para comprender mejor el funcionamiento interno del algoritmo, vamos a implementar Gaussian Naive Bayes paso a paso:"
      ],
      "id": "4ee3e469"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-from-scratch-class\n",
        "#| echo: true\n",
        "\n",
        "class GaussianNBDesdesCero:\n",
        "    \"\"\"\n",
        "    Implementación educativa de Gaussian Naive Bayes\n",
        "\n",
        "    Esta clase implementa el algoritmo paso a paso para\n",
        "    fines pedagógicos.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.clases = None\n",
        "        self.priors = {}        # P(Y=k) para cada clase k\n",
        "        self.medias = {}        # μ para cada clase y característica\n",
        "        self.varianzas = {}     # σ² para cada clase y característica\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        \"\"\"\n",
        "        Fase de entrenamiento: calcular estadísticas\n",
        "\n",
        "        Parámetros:\n",
        "        - X: matriz de características (n_muestras, n_características)\n",
        "        - y: vector de etiquetas (n_muestras,)\n",
        "        \"\"\"\n",
        "        self.clases = np.unique(y)\n",
        "        n_muestras = len(y)\n",
        "        n_caracteristicas = X.shape[1]\n",
        "\n",
        "        print(f\"Entrenando con {n_muestras} muestras y {n_caracteristicas} características\")\n",
        "        print(f\"Clases encontradas: {self.clases}\")\n",
        "\n",
        "        for clase in self.clases:\n",
        "            # Filtrar datos de esta clase\n",
        "            X_clase = X[y == clase]\n",
        "            n_clase = len(X_clase)\n",
        "\n",
        "            # Calcular probabilidad a priori P(Y=clase)\n",
        "            self.priors[clase] = n_clase / n_muestras\n",
        "\n",
        "            # Calcular media y varianza para cada característica\n",
        "            self.medias[clase] = np.mean(X_clase, axis=0)\n",
        "            self.varianzas[clase] = np.var(X_clase, axis=0) + 1e-9  # Evitar división por cero\n",
        "\n",
        "            print(f\"\\nClase {clase}: {n_clase} muestras ({self.priors[clase]:.1%})\")\n",
        "            print(f\"  Medias: {self.medias[clase]}\")\n",
        "            print(f\"  Varianzas: {self.varianzas[clase]}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _calcular_gaussiana(self, x, media, varianza):\n",
        "        \"\"\"\n",
        "        Calcula P(x|μ,σ²) usando la distribución gaussiana\n",
        "\n",
        "        Fórmula: P(x|μ,σ²) = 1/√(2πσ²) * exp(-(x-μ)²/(2σ²))\n",
        "        \"\"\"\n",
        "        coeficiente = 1.0 / np.sqrt(2.0 * np.pi * varianza)\n",
        "        exponente = -((x - media) ** 2) / (2.0 * varianza)\n",
        "        return coeficiente * np.exp(exponente)\n",
        "\n",
        "    def predecir_probabilidades(self, X):\n",
        "        \"\"\"\n",
        "        Calcula P(Y=k|X) para cada clase k\n",
        "\n",
        "        Usa el teorema de Bayes:\n",
        "        P(Y=k|X) ∝ P(X|Y=k) * P(Y=k)\n",
        "        \"\"\"\n",
        "        n_muestras = X.shape[0]\n",
        "        n_clases = len(self.clases)\n",
        "        probabilidades = np.zeros((n_muestras, n_clases))\n",
        "\n",
        "        for i, x in enumerate(X):\n",
        "            for j, clase in enumerate(self.clases):\n",
        "                # Calcular P(Y=clase) - prior\n",
        "                prob_prior = self.priors[clase]\n",
        "\n",
        "                # Calcular P(X|Y=clase) - verosimilitud\n",
        "                # Producto de probabilidades (asumiendo independencia)\n",
        "                verosimilitud = 1.0\n",
        "                for k in range(len(x)):\n",
        "                    prob_caracteristica = self._calcular_gaussiana(\n",
        "                        x[k],\n",
        "                        self.medias[clase][k],\n",
        "                        self.varianzas[clase][k]\n",
        "                    )\n",
        "                    verosimilitud *= prob_caracteristica\n",
        "\n",
        "                # P(Y=clase|X) ∝ P(X|Y=clase) * P(Y=clase)\n",
        "                probabilidades[i, j] = verosimilitud * prob_prior\n",
        "\n",
        "            # Normalizar para que sumen 1\n",
        "            probabilidades[i] = probabilidades[i] / np.sum(probabilidades[i])\n",
        "\n",
        "        return probabilidades\n",
        "\n",
        "    def predecir(self, X):\n",
        "        \"\"\"\n",
        "        Predice la clase con mayor probabilidad posterior\n",
        "        \"\"\"\n",
        "        probabilidades = self.predecir_probabilidades(X)\n",
        "        indices_maximos = np.argmax(probabilidades, axis=1)\n",
        "        return self.clases[indices_maximos]"
      ],
      "id": "naive-bayes-from-scratch-class",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-from-scratch-test\n",
        "#| echo: true\n",
        "\n",
        "# Crear y entrenar nuestro modelo\n",
        "print(\"=\" * 60)\n",
        "print(\"IMPLEMENTACIÓN DESDE CERO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Usar un conjunto pequeño para demostración\n",
        "X_demo = X_train[:20]\n",
        "y_demo = y_train[:20]\n",
        "X_test_demo = X_test[:10]\n",
        "y_test_demo = y_test[:10]\n",
        "\n",
        "# Entrenar nuestro modelo\n",
        "modelo_propio = GaussianNBDesdesCero()\n",
        "modelo_propio.entrenar(X_demo, y_demo)\n",
        "\n",
        "# Hacer predicciones\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PREDICCIONES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "y_pred_propio = modelo_propio.predecir(X_test_demo)\n",
        "probabilidades = modelo_propio.predecir_probabilidades(X_test_demo)\n",
        "\n",
        "# Mostrar resultados detallados\n",
        "for i in range(5):  # Mostrar solo las primeras 5\n",
        "    print(f\"\\nMuestra {i+1}:\")\n",
        "    print(f\"  Características: [{X_test_demo[i, 0]:.2f}, {X_test_demo[i, 1]:.2f}]\")\n",
        "    print(f\"  Probabilidades: P(Y=0|X)={probabilidades[i, 0]:.3f}, P(Y=1|X)={probabilidades[i, 1]:.3f}\")\n",
        "    print(f\"  Predicción: {y_pred_propio[i]}\")\n",
        "    print(f\"  Valor real: {y_test_demo[i]}\")\n",
        "    print(f\"  {'✓ Correcto' if y_pred_propio[i] == y_test_demo[i] else '✗ Incorrecto'}\")"
      ],
      "id": "naive-bayes-from-scratch-test",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: naive-bayes-comparison-final\n",
        "#| echo: true\n",
        "\n",
        "# Comparación con scikit-learn\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"COMPARACIÓN CON SCIKIT-LEARN\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Entrenar modelo de scikit-learn con los mismos datos\n",
        "gnb_sklearn_demo = GaussianNB()\n",
        "gnb_sklearn_demo.fit(X_demo, y_demo)\n",
        "y_pred_sklearn_demo = gnb_sklearn_demo.predict(X_test_demo)\n",
        "\n",
        "# Comparar resultados\n",
        "print(\"\\nPredicciones:\")\n",
        "print(f\"  Implementación propia: {y_pred_propio}\")\n",
        "print(f\"  Scikit-learn:         {y_pred_sklearn_demo}\")\n",
        "print(f\"  Valores reales:       {y_test_demo}\")\n",
        "\n",
        "# Calcular accuracy\n",
        "acc_propio = np.mean(y_pred_propio == y_test_demo)\n",
        "acc_sklearn = np.mean(y_pred_sklearn_demo == y_test_demo)\n",
        "\n",
        "print(f\"\\nAccuracy:\")\n",
        "print(f\"  Implementación propia: {acc_propio:.3f}\")\n",
        "print(f\"  Scikit-learn:         {acc_sklearn:.3f}\")\n",
        "\n",
        "# Verificar que los parámetros aprendidos son similares\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"VERIFICACIÓN DE PARÁMETROS APRENDIDOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for clase in [0, 1]:\n",
        "    print(f\"\\nClase {clase}:\")\n",
        "    print(f\"  Priors:\")\n",
        "    print(f\"    Propio: {modelo_propio.priors[clase]:.3f}\")\n",
        "    print(f\"    Sklearn: {gnb_sklearn_demo.class_prior_[clase]:.3f}\")\n",
        "    print(f\"  Medias (primera característica):\")\n",
        "    print(f\"    Propio: {modelo_propio.medias[clase][0]:.3f}\")\n",
        "    print(f\"    Sklearn: {gnb_sklearn_demo.theta_[clase, 0]:.3f}\")"
      ],
      "id": "naive-bayes-comparison-final",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cuándo Usar Naive Bayes\n",
        "\n",
        "Naive Bayes es particularmente efectivo en:\n",
        "\n",
        "1. **Clasificación de texto y procesamiento de lenguaje natural**\n",
        "\n",
        "   - Filtrado de spam\n",
        "   - Análisis de sentimientos\n",
        "   - Categorización de documentos\n",
        "\n",
        "2. **Sistemas de recomendación**\n",
        "\n",
        "   - Predicción de preferencias basada en características\n",
        "\n",
        "3. **Diagnóstico médico**\n",
        "\n",
        "   - Cuando las características son síntomas relativamente independientes\n",
        "\n",
        "4. **Aplicaciones en tiempo real**\n",
        "\n",
        "   - Cuando se necesitan predicciones muy rápidas\n",
        "\n",
        "5. **Conjuntos de datos pequeños**\n",
        "\n",
        "   - Cuando hay pocos ejemplos de entrenamiento por clase\n",
        "\n",
        "El clasificador Naive Bayes, a pesar de su simplicidad, sigue siendo uno de los algoritmos fundamentales en machine learning, especialmente valioso como baseline y en aplicaciones donde la velocidad y simplicidad son críticas.\n",
        "\n",
        "### Regresión Logística\n",
        "\n",
        "La **regresión logística** es uno de los modelos más utilizados para clasificación binaria. Modela directamente la probabilidad posterior usando una transformación logística de una combinación lineal de las características.\n",
        "\n",
        "#### Modelo\n",
        "\n",
        "La regresión logística modela la probabilidad de que $Y = 1$ como:\n",
        "\n",
        "$$P(Y = 1 | \\mathbf{X} = \\mathbf{x}) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p)}} = \\frac{1}{1 + e^{-\\mathbf{x}^T\\boldsymbol{\\beta}}}$$\n",
        "\n",
        "Esta función se conoce como función **sigmoide** o **logística**:\n",
        "\n",
        "$$\\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{e^z}{1 + e^z}$$\n",
        "\n",
        "#### Transformación Logit\n",
        "\n",
        "El modelo puede reescribirse usando la transformación **logit** (log-odds):\n",
        "\n",
        "$$\\log\\left(\\frac{P(Y = 1 | \\mathbf{x})}{P(Y = 0 | \\mathbf{x})}\\right) = \\log\\left(\\frac{p(\\mathbf{x})}{1-p(\\mathbf{x})}\\right) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$$\n",
        "\n",
        "Esto muestra que el log-odds es una función lineal de las características.\n",
        "\n",
        "#### Estimación de Parámetros\n",
        "\n",
        "Los parámetros $\\boldsymbol{\\beta}$ se estiman maximizando la verosimilitud. Para $n$ observaciones:\n",
        "\n",
        "$$L(\\boldsymbol{\\beta}) = \\prod_{i=1}^{n} p(\\mathbf{x}_i)^{y_i} \\cdot (1-p(\\mathbf{x}_i))^{1-y_i}$$\n",
        "\n",
        "Tomando el logaritmo:\n",
        "\n",
        "$$\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} [y_i \\log(p(\\mathbf{x}_i)) + (1-y_i) \\log(1-p(\\mathbf{x}_i))]$$\n",
        "\n",
        "Esta es exactamente la negativa de la pérdida logarítmica. No existe solución analítica, por lo que se utiliza optimización numérica (típicamente Newton-Raphson o gradiente descendente).\n",
        "\n",
        "#### Frontera de Decisión\n",
        "\n",
        "La frontera de decisión en regresión logística es **lineal** en el espacio de características:\n",
        "\n",
        "$$\\{\\mathbf{x} : P(Y = 1 | \\mathbf{x}) = 0.5\\} = \\{\\mathbf{x} : \\mathbf{x}^T\\boldsymbol{\\beta} = 0\\}$$\n",
        "\n",
        "Esto define un hiperplano que separa las dos clases.\n",
        "\n",
        "#### Ejemplo en Python"
      ],
      "id": "34ee57f7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 5
      },
      "source": [
        "#| label: logistic-regression-example\n",
        "#| fig-cap: 'Regresión logística: datos, probabilidades y frontera de decisión'\n",
        "#| echo: false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generar datos de ejemplo\n",
        "np.random.seed(42)\n",
        "X, y = make_classification(n_samples=200, n_features=2, n_informative=2,\n",
        "                          n_redundant=0, n_clusters_per_class=1,\n",
        "                          flip_y=0.1, class_sep=1.5)\n",
        "\n",
        "# Estandarizar características\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Ajustar regresión logística\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_scaled, y)\n",
        "\n",
        "# Crear grid para visualización\n",
        "xx, yy = np.meshgrid(np.linspace(X_scaled[:, 0].min()-1, X_scaled[:, 0].max()+1, 100),\n",
        "                     np.linspace(X_scaled[:, 1].min()-1, X_scaled[:, 1].max()+1, 100))\n",
        "Z = log_reg.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Visualización\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
        "\n",
        "# Panel 1: Datos\n",
        "axes[0].scatter(X_scaled[y==0, 0], X_scaled[y==0, 1], c='blue',\n",
        "                alpha=0.6, edgecolors='k', label='Clase 0')\n",
        "axes[0].scatter(X_scaled[y==1, 0], X_scaled[y==1, 1], c='red',\n",
        "                alpha=0.6, edgecolors='k', label='Clase 1')\n",
        "axes[0].set_xlabel('$x_1$')\n",
        "axes[0].set_ylabel('$x_2$')\n",
        "axes[0].set_title('Datos de Entrenamiento')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Panel 2: Probabilidades\n",
        "contour = axes[1].contourf(xx, yy, Z, levels=20, cmap='RdBu_r', alpha=0.8)\n",
        "axes[1].scatter(X_scaled[y==0, 0], X_scaled[y==0, 1], c='blue',\n",
        "                alpha=0.6, edgecolors='k', s=20)\n",
        "axes[1].scatter(X_scaled[y==1, 0], X_scaled[y==1, 1], c='red',\n",
        "                alpha=0.6, edgecolors='k', s=20)\n",
        "axes[1].set_xlabel('$x_1$')\n",
        "axes[1].set_ylabel('$x_2$')\n",
        "axes[1].set_title('Probabilidad $P(Y=1|\\\\mathbf{x})$')\n",
        "plt.colorbar(contour, ax=axes[1])\n",
        "\n",
        "# Panel 3: Frontera de decisión\n",
        "axes[2].contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
        "axes[2].contourf(xx, yy, Z, levels=[0, 0.5, 1], colors=['lightblue', 'lightcoral'], alpha=0.4)\n",
        "axes[2].scatter(X_scaled[y==0, 0], X_scaled[y==0, 1], c='blue',\n",
        "                alpha=0.6, edgecolors='k', s=20, label='Clase 0')\n",
        "axes[2].scatter(X_scaled[y==1, 0], X_scaled[y==1, 1], c='red',\n",
        "                alpha=0.6, edgecolors='k', s=20, label='Clase 1')\n",
        "axes[2].set_xlabel('$x_1$')\n",
        "axes[2].set_ylabel('$x_2$')\n",
        "axes[2].set_title('Frontera de Decisión')\n",
        "axes[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrar coeficientes\n",
        "print(f\"Intercepto (β₀): {log_reg.intercept_[0]:.3f}\")\n",
        "print(f\"Coeficientes: β₁ = {log_reg.coef_[0][0]:.3f}, β₂ = {log_reg.coef_[0][1]:.3f}\")"
      ],
      "id": "logistic-regression-example",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Interpretación de Coeficientes\n",
        "\n",
        "##### Conceptos Fundamentales: Odds y Log-Odds\n",
        "\n",
        "Antes de interpretar los coeficientes, definamos los conceptos clave:\n",
        "\n",
        "**Odds (momios o chances)**: La razón entre la probabilidad de éxito y la probabilidad de fracaso:\n",
        "\n",
        "$$\\text{Odds} = \\frac{P(Y = 1)}{P(Y = 0)} = \\frac{p}{1-p}$$\n",
        "\n",
        "Si $p = 0.75$, entonces los odds son $\\frac{0.75}{0.25} = 3$, es decir, el éxito es 3 veces más probable que el fracaso.\n",
        "\n",
        "**Log-odds (logit)**: El logaritmo natural de los odds:\n",
        "\n",
        "$$\\text{Log-odds} = \\log\\left(\\frac{p}{1-p}\\right) = \\text{logit}(p)$$\n",
        "\n",
        "##### Derivación Matemática\n",
        "\n",
        "Partiendo del modelo de regresión logística:\n",
        "\n",
        "$$P(Y = 1 | \\mathbf{x}) = \\frac{1}{1 + e^{-(\\beta_0 + \\sum_{j=1}^p \\beta_j x_j)}}$$\n",
        "\n",
        "Calculemos el log-odds:\n",
        "\n",
        "$$\\log\\left(\\frac{P(Y = 1 | \\mathbf{x})}{1 - P(Y = 1 | \\mathbf{x})}\\right) = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j$$\n",
        "\n",
        "Ahora, consideremos qué sucede cuando incrementamos $x_k$ en una unidad (de $x_k$ a $x_k + 1$):\n",
        "\n",
        "**Log-odds original**:\n",
        "$$L_0 = \\beta_0 + \\beta_1 x_1 + ... + \\beta_k x_k + ... + \\beta_p x_p$$\n",
        "\n",
        "**Log-odds después del incremento**:\n",
        "$$L_1 = \\beta_0 + \\beta_1 x_1 + ... + \\beta_k (x_k + 1) + ... + \\beta_p x_p$$\n",
        "\n",
        "**Cambio en log-odds**:\n",
        "$$\\Delta L = L_1 - L_0 = \\beta_k$$\n",
        "\n",
        "Por lo tanto, **$\\beta_k$ representa el cambio en log-odds cuando $x_k$ aumenta en una unidad**.\n",
        "\n",
        "##### Odds Ratio\n",
        "\n",
        "El **odds ratio** compara los odds antes y después del cambio:\n",
        "\n",
        "$$\\text{Odds ratio} = \\frac{\\text{Odds}_{\\text{nuevo}}}{\\text{Odds}_{\\text{original}}} = \\frac{e^{L_1}}{e^{L_0}} = e^{L_1 - L_0} = e^{\\beta_k}$$\n",
        "\n",
        "Esto significa que **$e^{\\beta_k}$ es el factor por el cual se multiplican los odds cuando $x_k$ aumenta en una unidad**.\n",
        "\n",
        "##### Ejemplo Práctico: Clicks en Memes y Edad\n",
        "\n",
        "Imaginemos un estudio sobre la probabilidad de que una persona haga click en un meme según su edad. Nuestro modelo de regresión logística es:\n",
        "\n",
        "$$\\log\\left(\\frac{P(\\text{click} = 1)}{P(\\text{click} = 0)}\\right) = 2.5 - 0.08 \\cdot \\text{edad}$$\n",
        "\n",
        "Donde:\n",
        "- $\\beta_0 = 2.5$ (intercepto)\n",
        "- $\\beta_{\\text{edad}} = -0.08$ (coeficiente de edad)\n",
        "\n",
        "**Interpretaciones**:\n",
        "\n",
        "1. **Coeficiente $\\beta_{\\text{edad}} = -0.08$**:\n",
        "   - Por cada año adicional de edad, el log-odds de hacer click disminuye en 0.08\n",
        "   - El signo negativo indica que personas mayores tienen menor probabilidad de hacer click\n",
        "\n",
        "2. **Odds ratio $e^{-0.08} \\approx 0.923$**:\n",
        "   - Por cada año adicional de edad, los odds de hacer click se multiplican por 0.923\n",
        "   - Equivalentemente: los odds disminuyen un 7.7% por cada año adicional\n",
        "\n",
        "3. **Ejemplo numérico concreto**:\n",
        "\n",
        "Para una persona de 20 años:\n",
        "$$\\text{Log-odds}_{20} = 2.5 - 0.08(20) = 0.9$$\n",
        "$$\\text{Odds}_{20} = e^{0.9} \\approx 2.46$$\n",
        "$$P(\\text{click})_{20} = \\frac{2.46}{1 + 2.46} \\approx 0.71$$\n",
        "\n",
        "Para una persona de 30 años:\n",
        "$$\\text{Log-odds}_{30} = 2.5 - 0.08(30) = 0.1$$\n",
        "$$\\text{Odds}_{30} = e^{0.1} \\approx 1.11$$\n",
        "$$P(\\text{click})_{30} = \\frac{1.11}{1 + 1.11} \\approx 0.53$$\n",
        "\n",
        "**Verificación del odds ratio**:\n",
        "$$\\frac{\\text{Odds}_{30}}{\\text{Odds}_{20}} = \\frac{1.11}{2.46} \\approx 0.45 = e^{-0.08 \\times 10} = (e^{-0.08})^{10}$$\n",
        "\n",
        "Esto confirma que en 10 años (de 20 a 30), los odds se multiplican por $(0.923)^{10} \\approx 0.45$.\n",
        "\n",
        "##### Resumen de Interpretaciones\n",
        "\n",
        "| Parámetro | Interpretación | Ejemplo (edad y clicks) |\n",
        "|-----------|---------------|-------------------------|\n",
        "| $\\beta_j > 0$ | Variable aumenta log-odds | Los jóvenes clickean más |\n",
        "| $\\beta_j < 0$ | Variable disminuye log-odds | Los mayores clickean menos |\n",
        "| $\\beta_j$ | Cambio en log-odds por unidad | -0.08: cada año reduce log-odds |\n",
        "| $e^{\\beta_j} > 1$ | Odds aumentan | - |\n",
        "| $e^{\\beta_j} < 1$ | Odds disminuyen | 0.923: odds bajan 7.7% por año |\n",
        "| $e^{\\beta_j} = 2$ | Odds se duplican | - |\n",
        "| $e^{\\beta_j} = 0.5$ | Odds se reducen a la mitad | - |\n",
        "\n",
        "## Métricas de Evaluación de Modelos de Clasificación\n",
        "\n",
        "Una vez entrenado un modelo de clasificación, necesitamos evaluar su desempeño de manera rigurosa. Mientras que las funciones de pérdida (como Brier Score y Log Loss) son útiles durante el entrenamiento, las **métricas de evaluación** nos permiten interpretar el rendimiento del modelo desde diferentes perspectivas y tomar decisiones informadas sobre su uso en producción.\n",
        "\n",
        "### La Matriz de Confusión: Fundamento de las Métricas\n",
        "\n",
        "La **matriz de confusión** es la herramienta fundamental para entender el comportamiento de un clasificador binario. Para clasificación binaria (clase positiva = 1, clase negativa = 0), la matriz tiene la siguiente estructura:\n",
        "\n",
        "|                    | Predicción Positiva (1) | Predicción Negativa (0) |\n",
        "|-------------------|------------------------|------------------------|\n",
        "| **Clase Real Positiva (1)** | Verdaderos Positivos (VP) | Falsos Negativos (FN) |\n",
        "| **Clase Real Negativa (0)** | Falsos Positivos (FP) | Verdaderos Negativos (VN) |\n",
        "\n",
        "Donde:\n",
        "\n",
        "- **Verdaderos Positivos (VP)**: Casos positivos correctamente identificados\n",
        "- **Verdaderos Negativos (VN)**: Casos negativos correctamente identificados\n",
        "- **Falsos Positivos (FP)**: Casos negativos incorrectamente clasificados como positivos (Error Tipo I)\n",
        "- **Falsos Negativos (FN)**: Casos positivos incorrectamente clasificados como negativos (Error Tipo II)\n",
        "\n",
        "#### Interpretación en Contexto\n",
        "\n",
        "La importancia relativa de cada tipo de error depende del contexto de aplicación:\n",
        "\n",
        "**Ejemplo 1: Detección de Spam**\n",
        "\n",
        "- **FP (Error Tipo I)**: Email legítimo marcado como spam → Usuario pierde email importante\n",
        "- **FN (Error Tipo II)**: Spam no detectado → Usuario recibe spam (menor consecuencia)\n",
        "- **Prioridad**: Minimizar FP (alta precisión)\n",
        "\n",
        "**Ejemplo 2: Diagnóstico de Cáncer**\n",
        "\n",
        "- **FP (Error Tipo I)**: Falso positivo → Paciente sano sometido a pruebas adicionales\n",
        "- **FN (Error Tipo II)**: Falso negativo → Paciente enfermo no recibe tratamiento\n",
        "- **Prioridad**: Minimizar FN (alta sensibilidad/recall)\n",
        "\n",
        "**Ejemplo 3: Detección de Fraude Bancario**\n",
        "\n",
        "- **FP (Error Tipo I)**: Transacción legítima bloqueada → Cliente molesto\n",
        "- **FN (Error Tipo II)**: Fraude no detectado → Pérdida económica\n",
        "- **Prioridad**: Balance entre ambos (F1-score)\n",
        "\n",
        "### Métricas Derivadas de la Matriz de Confusión\n",
        "\n",
        "#### 1. Exactitud (Accuracy)\n",
        "\n",
        "La **exactitud** es la proporción de predicciones correctas sobre el total:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{VP + VN}{VP + VN + FP + FN}$$\n",
        "\n",
        "**Ventajas:**\n",
        "\n",
        "- ✓ Interpretación intuitiva\n",
        "- ✓ Métrica general del desempeño\n",
        "\n",
        "**Desventajas:**\n",
        "\n",
        "- ✗ Engañosa con **clases desbalanceadas**\n",
        "- ✗ No distingue entre tipos de errores\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Limitación\n",
        "\n",
        "Si el 95% de los emails son legítimos, un clasificador que siempre predice \"no spam\" tendrá 95% de accuracy, pero es completamente inútil.\n",
        "\n",
        ":::\n",
        "\n",
        "#### 2. Precisión (Precision)\n",
        "\n",
        "La **precisión** mide la proporción de predicciones positivas que son realmente positivas:\n",
        "\n",
        "$$\\text{Precision} = \\frac{VP}{VP + FP} = \\frac{VP}{\\text{Total Predicciones Positivas}}$$\n",
        "\n",
        "**Interpretación**: \"De todos los casos que el modelo predijo como positivos, ¿qué proporción es realmente positiva?\"\n",
        "\n",
        "**Cuándo usar:**\n",
        "\n",
        "- Cuando los **falsos positivos son costosos**\n",
        "- Ejemplo: Recomendación de productos (no queremos recomendar productos irrelevantes)\n",
        "\n",
        "#### 3. Sensibilidad (Recall, Sensitivity, True Positive Rate)\n",
        "\n",
        "La **sensibilidad** o **recall** mide la proporción de casos positivos que fueron correctamente identificados:\n",
        "\n",
        "$$\\text{Recall} = \\frac{VP}{VP + FN} = \\frac{VP}{\\text{Total Casos Positivos Reales}}$$\n",
        "\n",
        "**Interpretación**: \"De todos los casos que son realmente positivos, ¿qué proporción detectó el modelo?\"\n",
        "\n",
        "**Cuándo usar:**\n",
        "\n",
        "- Cuando los **falsos negativos son críticos**\n",
        "- Ejemplo: Detección de enfermedades graves (no queremos dejar casos sin diagnosticar)\n",
        "\n",
        "#### 4. Especificidad (Specificity, True Negative Rate)\n",
        "\n",
        "La **especificidad** mide la proporción de casos negativos correctamente identificados:\n",
        "\n",
        "$$\\text{Specificity} = \\frac{VN}{VN + FP} = \\frac{VN}{\\text{Total Casos Negativos Reales}}$$\n",
        "\n",
        "**Interpretación**: \"De todos los casos que son realmente negativos, ¿qué proporción identificó correctamente el modelo?\"\n",
        "\n",
        "#### 5. F1-Score\n",
        "\n",
        "El **F1-Score** es la media armónica de precisión y recall:\n",
        "\n",
        "$$F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = \\frac{2 \\cdot VP}{2 \\cdot VP + FP + FN}$$\n",
        "\n",
        "**Propiedades:**\n",
        "\n",
        "- Rango: $[0, 1]$ (mayor es mejor)\n",
        "- Penaliza desbalances entre precision y recall\n",
        "- Si precision = recall, entonces $F_1 = \\text{precision} = \\text{recall}$\n",
        "\n",
        "**Cuándo usar:**\n",
        "\n",
        "- Cuando se necesita un **balance** entre precision y recall\n",
        "- Con **clases desbalanceadas**\n",
        "- Como métrica única de comparación entre modelos\n",
        "\n",
        "#### 6. F-Beta Score\n",
        "\n",
        "Generalización del F1-Score que permite ponderar la importancia relativa de precision y recall:\n",
        "\n",
        "$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\beta^2 \\cdot \\text{Precision} + \\text{Recall}}$$\n",
        "\n",
        "Donde $\\beta$ controla el peso relativo:\n",
        "\n",
        "- $\\beta < 1$: Más peso a la precisión (ej: $F_{0.5}$)\n",
        "- $\\beta = 1$: Peso igual (F1-Score)\n",
        "- $\\beta > 1$: Más peso al recall (ej: $F_2$)\n",
        "\n",
        "### Umbral de Decisión\n",
        "\n",
        "Hasta ahora hemos hablado de \"predicciones\" como si fueran categóricas (clase 0 o clase 1), pero es importante entender que la mayoría de los modelos de clasificación en realidad producen **probabilidades** que luego se convierten en predicciones discretas mediante un **umbral de decisión** (decision threshold).\n",
        "\n",
        "#### De Probabilidades a Predicciones\n",
        "\n",
        "Los modelos probabilísticos (como regresión logística, Naive Bayes, redes neuronales) no predicen directamente una clase, sino que estiman:\n",
        "\n",
        "$$\\hat{p} = P(Y = 1 | \\mathbf{x})$$\n",
        "\n",
        "Para convertir esta probabilidad en una predicción categórica, se utiliza un **umbral de decisión** $\\tau$:\n",
        "\n",
        "$$\\hat{y} = \\begin{cases}\n",
        "1 & \\text{si } \\hat{p} \\geq \\tau \\\\\n",
        "0 & \\text{si } \\hat{p} < \\tau\n",
        "\\end{cases}$$\n",
        "\n",
        "#### El Umbral Estándar: 0.5\n",
        "\n",
        "Por defecto, la mayoría de las implementaciones usan $\\tau = 0.5$:\n",
        "\n",
        "- Si $P(Y = 1 | \\mathbf{x}) \\geq 0.5$ → Predecir clase positiva (1)\n",
        "- Si $P(Y = 1 | \\mathbf{x}) < 0.5$ → Predecir clase negativa (0)\n",
        "\n",
        "Esta elección parece natural desde una perspectiva bayesiana (seleccionar la clase más probable), pero **no siempre es óptima** en la práctica.\n",
        "\n",
        "#### ¿Por Qué Cambiar el Umbral?\n",
        "\n",
        "El umbral de decisión debe ajustarse según el **contexto y los costos relativos de los errores**:\n",
        "\n",
        "**Ejemplo 1: Detección de Cáncer**\n",
        "\n",
        "- **Costo de FN (no detectar cáncer)**: Muy alto (riesgo de vida)\n",
        "- **Costo de FP (falsa alarma)**: Moderado (pruebas adicionales, ansiedad)\n",
        "- **Solución**: Usar $\\tau = 0.3$ o menor → Más sensible, captura más casos positivos\n",
        "\n",
        "**Ejemplo 2: Recomendación de Productos Premium**\n",
        "\n",
        "- **Costo de FP (recomendar a quien no comprará)**: Alto (recursos desperdiciados)\n",
        "- **Costo de FN (no recomendar a comprador potencial)**: Moderado\n",
        "- **Solución**: Usar $\\tau = 0.7$ o mayor → Más preciso, solo casos muy probables\n",
        "\n",
        "**Ejemplo 3: Filtro de Spam**\n",
        "\n",
        "- **Costo de FP (email legítimo marcado como spam)**: Alto (pérdida de información importante)\n",
        "- **Costo de FN (spam no detectado)**: Bajo (molestia menor)\n",
        "- **Solución**: Usar $\\tau = 0.6$ → Balance hacia alta precisión\n",
        "\n",
        "#### Impacto del Umbral en las Métricas\n",
        "\n",
        "Veamos con un ejemplo concreto cómo el umbral afecta las predicciones:"
      ],
      "id": "83dee80f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: threshold-example\n",
        "#| echo: true\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Ejemplo: 10 casos con sus probabilidades predichas y etiquetas reales\n",
        "np.random.seed(42)\n",
        "n_ejemplos = 10\n",
        "\n",
        "# Simular probabilidades y etiquetas reales\n",
        "data_ejemplo = pd.DataFrame({\n",
        "    'ID': range(1, n_ejemplos + 1),\n",
        "    'Probabilidad': [0.15, 0.32, 0.48, 0.55, 0.62, 0.71, 0.78, 0.85, 0.91, 0.95],\n",
        "    'Clase_Real': [0, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n",
        "})\n",
        "\n",
        "print(\"DATOS DE EJEMPLO\")\n",
        "print(\"=\" * 60)\n",
        "print(data_ejemplo.to_string(index=False))\n",
        "\n",
        "# Probar diferentes umbrales\n",
        "umbrales = [0.3, 0.5, 0.7]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"IMPACTO DEL UMBRAL EN LAS PREDICCIONES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for tau in umbrales:\n",
        "    # Aplicar umbral\n",
        "    predicciones = (data_ejemplo['Probabilidad'] >= tau).astype(int)\n",
        "\n",
        "    # Calcular métricas\n",
        "    cm = confusion_matrix(data_ejemplo['Clase_Real'], predicciones)\n",
        "    precision = precision_score(data_ejemplo['Clase_Real'], predicciones, zero_division=0)\n",
        "    recall = recall_score(data_ejemplo['Clase_Real'], predicciones)\n",
        "    f1 = f1_score(data_ejemplo['Clase_Real'], predicciones, zero_division=0)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Umbral τ = {tau}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Predicciones: {predicciones.tolist()}\")\n",
        "    print(f\"VP={cm[1,1]}, VN={cm[0,0]}, FP={cm[0,1]}, FN={cm[1,0]}\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall:    {recall:.3f}\")\n",
        "    print(f\"F1-Score:  {f1:.3f}\")"
      ],
      "id": "threshold-example",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como podemos observar:\n",
        "\n",
        "- **Umbral bajo (τ = 0.3)**: Más predicciones positivas → Mayor recall, menor precision\n",
        "- **Umbral medio (τ = 0.5)**: Caso estándar (balance)\n",
        "- **Umbral alto (τ = 0.7)**: Menos predicciones positivas → Mayor precision, menor recall\n",
        "\n",
        "#### Selección del Umbral Óptimo\n",
        "\n",
        "La selección del umbral óptimo depende de:\n",
        "\n",
        "1. **Costos de negocio**: Cuantificar el costo relativo de FP vs FN\n",
        "2. **Métricas objetivo**: Optimizar para la métrica más relevante (precision, recall, F1, etc.)\n",
        "3. **Restricciones operacionales**: Capacidad para manejar volumen de casos positivos\n",
        "4. **Validación empírica**: Usar curvas Precision-Recall o ROC para explorar opciones\n",
        "\n",
        "### Trade-off entre Precisión y Recall\n",
        "\n",
        "Ahora que comprendemos el concepto de umbral de decisión, podemos analizar el **trade-off fundamental** entre precision y recall:\n",
        "\n",
        "- **Aumentar el umbral** ($\\tau \\uparrow$) → Más conservador → ↑ Precision, ↓ Recall\n",
        "- **Disminuir el umbral** ($\\tau \\downarrow$) → Más liberal → ↓ Precision, ↑ Recall\n",
        "\n",
        "Este trade-off es inherente a cualquier clasificador probabilístico y no puede eliminarse, solo puede balancearse según las necesidades del problema."
      ],
      "id": "717a2acb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 5
      },
      "source": [
        "#| label: precision-recall-tradeoff\n",
        "#| fig-cap: Trade-off entre Precisión y Recall según el umbral de decisión\n",
        "#| echo: false\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "\n",
        "# Generar datos\n",
        "np.random.seed(42)\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n",
        "                          n_redundant=5, weights=[0.7, 0.3], flip_y=0.05)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Entrenar modelo\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Obtener probabilidades\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular precision-recall para diferentes umbrales\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Visualización\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Panel 1: Precision vs Recall\n",
        "axes[0].plot(recall, precision, linewidth=2, color='blue')\n",
        "axes[0].fill_between(recall, precision, alpha=0.2)\n",
        "axes[0].set_xlabel('Recall (Sensibilidad)', fontsize=12)\n",
        "axes[0].set_ylabel('Precision', fontsize=12)\n",
        "axes[0].set_title('Curva Precision-Recall', fontsize=13)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xlim([0, 1])\n",
        "axes[0].set_ylim([0, 1])\n",
        "\n",
        "# Marcar algunos puntos importantes\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
        "best_f1_idx = np.argmax(f1_scores)\n",
        "axes[0].scatter(recall[best_f1_idx], precision[best_f1_idx],\n",
        "               color='red', s=100, zorder=5, label=f'Mejor F1={f1_scores[best_f1_idx]:.2f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# Panel 2: Precision y Recall vs Umbral\n",
        "# Ajustar longitud de thresholds_pr para que coincida\n",
        "thresholds_plot = np.append(thresholds_pr, 1)  # Agregar umbral máximo\n",
        "\n",
        "axes[1].plot(thresholds_plot, precision, label='Precision', linewidth=2)\n",
        "axes[1].plot(thresholds_plot, recall, label='Recall', linewidth=2)\n",
        "axes[1].plot(thresholds_plot, f1_scores, label='F1-Score', linewidth=2, linestyle='--')\n",
        "axes[1].axvline(x=0.5, color='black', linestyle=':', linewidth=1, label='Umbral=0.5')\n",
        "axes[1].set_xlabel('Umbral de Decisión', fontsize=12)\n",
        "axes[1].set_ylabel('Valor de Métrica', fontsize=12)\n",
        "axes[1].set_title('Métricas vs Umbral de Decisión', fontsize=13)\n",
        "axes[1].legend(loc='best')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].set_xlim([0, 1])\n",
        "axes[1].set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Imprimir estadísticas para umbral estándar (0.5)\n",
        "y_pred_05 = (y_proba >= 0.5).astype(int)\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "print(f\"Métricas con umbral = 0.5:\")\n",
        "print(f\"  Precision: {precision_score(y_test, y_pred_05):.3f}\")\n",
        "print(f\"  Recall:    {recall_score(y_test, y_pred_05):.3f}\")\n",
        "print(f\"  F1-Score:  {f1_score(y_test, y_pred_05):.3f}\")"
      ],
      "id": "precision-recall-tradeoff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Curva ROC y AUC\n",
        "\n",
        "#### Curva ROC (Receiver Operating Characteristic)\n",
        "\n",
        "La **curva ROC** visualiza el desempeño del clasificador en todos los posibles umbrales de decisión, graficando:\n",
        "\n",
        "- **Eje Y**: Tasa de Verdaderos Positivos (TPR = Recall = Sensibilidad)\n",
        "- **Eje X**: Tasa de Falsos Positivos (FPR = 1 - Especificidad)\n",
        "\n",
        "$$\\text{TPR} = \\frac{VP}{VP + FN}, \\quad \\text{FPR} = \\frac{FP}{FP + VN}$$\n",
        "\n",
        "**Puntos de referencia:**\n",
        "\n",
        "- Clasificador perfecto: TPR = 1, FPR = 0 (esquina superior izquierda)\n",
        "- Clasificador aleatorio: Línea diagonal (TPR = FPR)\n",
        "- Peor clasificador: TPR = 0, FPR = 1\n",
        "\n",
        "#### AUC (Area Under the Curve)\n",
        "\n",
        "El **AUC** es el área bajo la curva ROC:\n",
        "\n",
        "$$\\text{AUC} \\in [0, 1]$$\n",
        "\n",
        "**Interpretación:**\n",
        "\n",
        "- AUC = 1.0: Clasificador perfecto\n",
        "- AUC = 0.9-1.0: Excelente\n",
        "- AUC = 0.8-0.9: Muy bueno\n",
        "- AUC = 0.7-0.8: Bueno\n",
        "- AUC = 0.6-0.7: Regular\n",
        "- AUC = 0.5: No mejor que azar\n",
        "- AUC < 0.5: Peor que azar (predicciones invertidas)\n",
        "\n",
        "**Interpretación probabilística**\n",
        "\n",
        "El AUC representa la probabilidad de que el modelo asigne una mayor probabilidad a un ejemplo positivo aleatorio que a un ejemplo negativo aleatorio."
      ],
      "id": "7f975fb4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 5
      },
      "source": [
        "#| label: roc-curve-comparison\n",
        "#| fig-cap: Curvas ROC y AUC para comparación de modelos\n",
        "#| echo: false\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Entrenar múltiples modelos\n",
        "modelos = {\n",
        "    'Regresión Logística': LogisticRegression(max_iter=1000),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Árbol de Decisión': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "}\n",
        "\n",
        "resultados_roc = {}\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    resultados_roc[nombre] = {'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}\n",
        "\n",
        "# Visualización\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Panel 1: Todas las curvas ROC\n",
        "colors = ['blue', 'green', 'red', 'purple']\n",
        "for (nombre, datos), color in zip(resultados_roc.items(), colors):\n",
        "    axes[0].plot(datos['fpr'], datos['tpr'], linewidth=2, color=color,\n",
        "                label=f\"{nombre} (AUC={datos['auc']:.3f})\")\n",
        "\n",
        "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Clasificador Aleatorio (AUC=0.5)')\n",
        "axes[0].set_xlabel('Tasa de Falsos Positivos (FPR)', fontsize=12)\n",
        "axes[0].set_ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=12)\n",
        "axes[0].set_title('Curvas ROC - Comparación de Modelos', fontsize=13)\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xlim([0, 1])\n",
        "axes[0].set_ylim([0, 1])\n",
        "\n",
        "# Panel 2: Comparación de AUC\n",
        "nombres_modelos = list(resultados_roc.keys())\n",
        "auc_values = [resultados_roc[n]['auc'] for n in nombres_modelos]\n",
        "\n",
        "bars = axes[1].barh(nombres_modelos, auc_values, color=colors, alpha=0.7)\n",
        "axes[1].axvline(x=0.5, color='black', linestyle='--', linewidth=1, label='Azar')\n",
        "axes[1].set_xlabel('AUC', fontsize=12)\n",
        "axes[1].set_title('Comparación de AUC por Modelo', fontsize=13)\n",
        "axes[1].set_xlim([0, 1])\n",
        "axes[1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Añadir valores en las barras\n",
        "for bar, auc_val in zip(bars, auc_values):\n",
        "    width = bar.get_width()\n",
        "    axes[1].text(width + 0.02, bar.get_y() + bar.get_height()/2,\n",
        "                f'{auc_val:.3f}', va='center', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "roc-curve-comparison",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejemplo Completo: Evaluación de un Modelo"
      ],
      "id": "264303cc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: complete-evaluation-example\n",
        "#| echo: true\n",
        "\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                            accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, roc_auc_score)\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Usar el modelo de Regresión Logística entrenado anteriormente\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"EVALUACIÓN COMPLETA DEL MODELO DE CLASIFICACIÓN\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Matriz de Confusión\n",
        "print(\"\\n1. MATRIZ DE CONFUSIÓN\")\n",
        "print(\"-\" * 70)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     columns=['Predicho Negativo (0)', 'Predicho Positivo (1)'],\n",
        "                     index=['Real Negativo (0)', 'Real Positivo (1)'])\n",
        "print(cm_df)\n",
        "\n",
        "# Extraer valores\n",
        "VP = cm[1, 1]  # Verdaderos Positivos\n",
        "VN = cm[0, 0]  # Verdaderos Negativos\n",
        "FP = cm[0, 1]  # Falsos Positivos\n",
        "FN = cm[1, 0]  # Falsos Negativos\n",
        "\n",
        "print(f\"\\n  VP (Verdaderos Positivos): {VP}\")\n",
        "print(f\"  VN (Verdaderos Negativos): {VN}\")\n",
        "print(f\"  FP (Falsos Positivos):     {FP}\")\n",
        "print(f\"  FN (Falsos Negativos):     {FN}\")\n",
        "\n",
        "# 2. Métricas principales\n",
        "print(\"\\n2. MÉTRICAS DE DESEMPEÑO\")\n",
        "print(\"-\" * 70)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "specificity = VN / (VN + FP)\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "metricas = {\n",
        "    'Métrica': ['Accuracy', 'Precision', 'Recall (Sensibilidad)',\n",
        "                'Specificity', 'F1-Score', 'AUC-ROC'],\n",
        "    'Valor': [accuracy, precision, recall, specificity, f1, auc_score],\n",
        "    'Interpretación': [\n",
        "        'Proporción de predicciones correctas',\n",
        "        'De las predicciones positivas, proporción correcta',\n",
        "        'De los casos positivos reales, proporción detectada',\n",
        "        'De los casos negativos reales, proporción correcta',\n",
        "        'Media armónica de Precision y Recall',\n",
        "        'Área bajo la curva ROC'\n",
        "    ]\n",
        "}\n",
        "\n",
        "metricas_df = pd.DataFrame(metricas)\n",
        "metricas_df['Valor'] = metricas_df['Valor'].apply(lambda x: f'{x:.3f}')\n",
        "print(metricas_df.to_string(index=False))\n",
        "\n",
        "# 3. Reporte de clasificación completo\n",
        "print(\"\\n3. REPORTE DE CLASIFICACIÓN DETALLADO\")\n",
        "print(\"-\" * 70)\n",
        "print(classification_report(y_test, y_pred, target_names=['Clase 0', 'Clase 1']))"
      ],
      "id": "complete-evaluation-example",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 8,
        "fig-height": 6
      },
      "source": [
        "#| label: confusion-matrix-visualization\n",
        "#| fig-cap: Visualización de la Matriz de Confusión\n",
        "#| echo: true\n",
        "\n",
        "# Visualización mejorada de la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Crear matriz de confusión normalizada\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Crear anotaciones personalizadas con conteos y porcentajes\n",
        "annot = np.empty_like(cm, dtype=object)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        annot[i, j] = f'{cm[i, j]}\\n({cm_normalized[i, j]:.1%})'\n",
        "\n",
        "# Crear heatmap\n",
        "sns.heatmap(cm_normalized, annot=annot, fmt='', cmap='Blues',\n",
        "            xticklabels=['Predicho: 0', 'Predicho: 1'],\n",
        "            yticklabels=['Real: 0', 'Real: 1'],\n",
        "            cbar_kws={'label': 'Proporción'},\n",
        "            vmin=0, vmax=1, linewidths=2, linecolor='white')\n",
        "\n",
        "plt.title(f'Matriz de Confusión (Accuracy = {accuracy:.3f})', fontsize=14, pad=15)\n",
        "plt.ylabel('Clase Real', fontsize=12)\n",
        "plt.xlabel('Clase Predicha', fontsize=12)\n",
        "\n",
        "# Añadir etiquetas descriptivas\n",
        "plt.text(-0.5, 0.5, f'VN\\n{VN}', ha='center', va='center', fontsize=10,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
        "plt.text(1.5, 0.5, f'FP\\n{FP}', ha='center', va='center', fontsize=10,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
        "plt.text(-0.5, 1.5, f'FN\\n{FN}', ha='center', va='center', fontsize=10,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
        "plt.text(1.5, 1.5, f'VP\\n{VP}', ha='center', va='center', fontsize=10,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "confusion-matrix-visualization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Selección de Métricas según el Contexto\n",
        "\n",
        "La elección de la métrica apropiada depende del problema específico:\n",
        "\n",
        "| Contexto | Métrica Recomendada | Razón |\n",
        "|----------|-------------------|-------|\n",
        "| **Clases balanceadas** | Accuracy | Proporción general de aciertos es suficiente |\n",
        "| **Clases desbalanceadas** | F1-Score, AUC-ROC | Accuracy puede ser engañosa |\n",
        "| **Costo alto de FP** | Precision | Minimizar falsos positivos |\n",
        "| **Costo alto de FN** | Recall | Minimizar falsos negativos |\n",
        "| **Balance entre FP y FN** | F1-Score | Considera ambos errores |\n",
        "| **Comparación de modelos** | AUC-ROC | Independiente del umbral |\n",
        "| **Diagnóstico médico** | Recall, AUC-ROC | No perder casos positivos |\n",
        "| **Filtro de spam** | Precision, F1-Score | No bloquear emails legítimos |\n",
        "| **Detección de fraude** | F1-Score, Recall | Balance según costo relativo |\n",
        "\n",
        "### Métricas para Clasificación Multiclase\n",
        "\n",
        "Para problemas con $K > 2$ clases, las métricas se generalizan de dos formas:\n",
        "\n",
        "#### 1. Macro-averaging\n",
        "\n",
        "Calcula la métrica para cada clase por separado y promedia:\n",
        "\n",
        "$$\\text{Precision}_{\\text{macro}} = \\frac{1}{K} \\sum_{k=1}^{K} \\text{Precision}_k$$\n",
        "\n",
        "**Ventaja**: Trata todas las clases por igual (útil si todas las clases son igualmente importantes)\n",
        "\n",
        "#### 2. Weighted-averaging\n",
        "\n",
        "Promedio ponderado por el número de muestras reales de cada clase:\n",
        "\n",
        "$$\\text{Precision}_{\\text{weighted}} = \\sum_{k=1}^{K} w_k \\cdot \\text{Precision}_k$$\n",
        "\n",
        "Donde $w_k = \\frac{n_k}{n}$ (proporción de muestras de la clase $k$)\n",
        "\n",
        "**Ventaja**: Tiene en cuenta el desbalance de clases"
      ],
      "id": "43f8c36e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: multiclass-metrics-example\n",
        "#| echo: true\n",
        "\n",
        "# Ejemplo con dataset Iris (3 clases)\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Cargar datos\n",
        "iris = load_iris()\n",
        "X_iris_full = iris.data\n",
        "y_iris_full = iris.target\n",
        "\n",
        "# Dividir datos\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
        "    X_iris_full, y_iris_full, test_size=0.3, random_state=42, stratify=y_iris_full\n",
        ")\n",
        "\n",
        "# Entrenar modelo\n",
        "model_iris = LogisticRegression(max_iter=1000)\n",
        "model_iris.fit(X_train_iris, y_train_iris)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_iris = model_iris.predict(X_test_iris)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"EVALUACIÓN MULTICLASE (Dataset Iris - 3 clases)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Reporte de clasificación con macro y weighted averaging\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test_iris, y_pred_iris,\n",
        "                          target_names=iris.target_names,\n",
        "                          digits=3))\n",
        "\n",
        "# Matriz de confusión multiclase\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "cm_iris = confusion_matrix(y_test_iris, y_pred_iris)\n",
        "cm_iris_df = pd.DataFrame(cm_iris,\n",
        "                          columns=[f'Pred: {name}' for name in iris.target_names],\n",
        "                          index=[f'Real: {name}' for name in iris.target_names])\n",
        "print(cm_iris_df)"
      ],
      "id": "multiclass-metrics-example",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 8,
        "fig-height": 6
      },
      "source": [
        "#| label: multiclass-confusion-matrix\n",
        "#| fig-cap: Matriz de Confusión para Clasificación Multiclase\n",
        "#| echo: false\n",
        "\n",
        "# Visualización de matriz de confusión multiclase\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Normalizar por filas\n",
        "cm_iris_norm = cm_iris.astype('float') / cm_iris.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Crear anotaciones con conteos y porcentajes\n",
        "annot_iris = np.empty_like(cm_iris, dtype=object)\n",
        "for i in range(cm_iris.shape[0]):\n",
        "    for j in range(cm_iris.shape[1]):\n",
        "        annot_iris[i, j] = f'{cm_iris[i, j]}\\n({cm_iris_norm[i, j]:.1%})'\n",
        "\n",
        "sns.heatmap(cm_iris_norm, annot=annot_iris, fmt='', cmap='YlOrRd',\n",
        "            xticklabels=iris.target_names,\n",
        "            yticklabels=iris.target_names,\n",
        "            cbar_kws={'label': 'Proporción'},\n",
        "            vmin=0, vmax=1, linewidths=2, linecolor='white')\n",
        "\n",
        "plt.title('Matriz de Confusión - Clasificación Multiclase (Iris)', fontsize=14, pad=15)\n",
        "plt.ylabel('Clase Real', fontsize=12)\n",
        "plt.xlabel('Clase Predicha', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "multiclass-confusion-matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Consideraciones Finales\n",
        "\n",
        "**Principios clave para la evaluación de modelos de clasificación:**\n",
        "\n",
        "1. **Nunca confíes solo en accuracy** - Especialmente con clases desbalanceadas\n",
        "2. **Analiza la matriz de confusión** - Comprende qué tipos de errores comete tu modelo\n",
        "3. **Selecciona métricas según el contexto** - Considera el costo relativo de FP vs FN\n",
        "4. **Usa múltiples métricas** - Una sola métrica raramente cuenta toda la historia\n",
        "5. **Evalúa en datos independientes** - Usa conjuntos de validación/prueba no vistos\n",
        "6. **Considera el umbral de decisión** - El umbral 0.5 no siempre es óptimo\n",
        "7. **Visualiza el desempeño** - Curvas ROC y Precision-Recall proveen información valiosa\n",
        "\n",
        "La evaluación rigurosa del desempeño es fundamental para construir modelos de clasificación confiables y tomar decisiones informadas sobre su uso en aplicaciones del mundo real.\n",
        "\n",
        "::: {.callout-note icon=false}\n",
        "## 💬 Discusión en Parejas (15 minutos)\n",
        "\n",
        "**Escenario de Análisis:**\n",
        "\n",
        "Tu equipo ha desarrollado un modelo de clasificación para una aplicación real. Ahora deben presentar los resultados al equipo de negocio y justificar la elección de métricas.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1. **Formen parejas** y lean el siguiente escenario asignado por el instructor (o elijan uno):\n",
        "\n",
        "   **Escenario A: Sistema de Detección de Fraude con Tarjetas de Crédito**\n",
        "\n",
        "   - El modelo predice si una transacción es fraudulenta (clase positiva) o legítima (clase negativa)\n",
        "   - Solo el 0.5% de las transacciones son fraudulentas (alta desbalance)\n",
        "   - Costos: Bloquear una transacción legítima = $5 de molestia al cliente; No detectar un fraude = $150 de pérdida\n",
        "\n",
        "   **Escenario B: Sistema de Recomendación de Contenido Premium**\n",
        "\n",
        "   - El modelo predice si un usuario comprará contenido premium (clase positiva) o no (clase negativa)\n",
        "   - 20% de los usuarios compran contenido premium\n",
        "   - Costos: Mostrar anuncio a usuario no interesado = $0.50 de recursos desperdiciados; No mostrar anuncio a comprador potencial = $15 de venta perdida\n",
        "\n",
        "   **Escenario C: Sistema de Diagnóstico Médico de Enfermedad Rara**\n",
        "\n",
        "   - El modelo predice si un paciente tiene una enfermedad rara (clase positiva) o está sano (clase negativa)\n",
        "   - Solo el 2% de los pacientes tienen la enfermedad\n",
        "   - Costos: Falso positivo = $500 en pruebas adicionales + ansiedad; Falso negativo = enfermedad no tratada (alto riesgo)\n",
        "\n",
        "2. **Discutan en pareja (10 minutos):**\n",
        "\n",
        "   a) **Análisis de costos:**\n",
        "\n",
        "      - ¿Qué tipo de error es más costoso: FP o FN?\n",
        "      - ¿Por qué el accuracy no es una buena métrica para este problema?\n",
        "\n",
        "   b) **Selección de métricas:**\n",
        "\n",
        "      - ¿Qué métrica(s) deberían reportar al equipo de negocio?\n",
        "      - ¿Usarían el umbral estándar de 0.5 o lo ajustarían? ¿Hacia dónde y por qué?\n",
        "\n",
        "   c) **Interpretación de resultados:**\n",
        "\n",
        "      - Si el modelo tiene Precision = 0.85 y Recall = 0.60, ¿es aceptable para este caso?\n",
        "      - ¿Qué cambios harían para mejorar el modelo según las prioridades del negocio?\n",
        "\n",
        "3. **Preparen** (2 minutos):\n",
        "   \n",
        "   - Una conclusión de 1-2 frases sobre la métrica más importante para su escenario\n",
        "   - Un argumento breve de por qué eligieron esa métrica\n",
        "\n",
        "4. **Compartan** con otra pareja o con la clase (3 minutos):\n",
        "\n",
        "   - Presenten su razonamiento\n",
        "   - Escuchen el análisis de otro escenario\n",
        "\n",
        "**Preguntas guía para profundizar:**\n",
        "\n",
        "- ¿Cómo cambiaría su respuesta si los costos fueran diferentes?\n",
        "- ¿Qué información adicional necesitarían del negocio para tomar una mejor decisión?\n",
        "- ¿Cómo comunicarían las limitaciones del modelo a stakeholders no técnicos?\n",
        "\n",
        ":::"
      ],
      "id": "79299cb4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/xwing/miniforge3/envs/mineria_datos/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}