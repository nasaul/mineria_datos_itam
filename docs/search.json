[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Minería de Datos",
    "section": "",
    "text": "Temario\n\nIntroducción al aprendizaje de máquina\nPrincipios de aprendizaje supervisado\nRegresión lineal\nMétodos de remuestreo y validación cruzada\nPrincipios de Regularización\nProblemas de clasificación, métricas y evaluación\nÁrboles, bosques aleatorios y boosting\nRedes neuronales\nMétodos no supervisados\n\n\nEvaluación\n\nDos exámenes parciales (40%)\nProyecto final (30%):\n\nEntrega (75%)\nExposición (25%)\n\n\nExamen final (30%)\n\nExistirá una parte extra a los alumnos que contribuyan al aprendizaje de sus compañeros:\n\nContribuciones al repositorio: añadiendo redacción más entendible, añadiendo ejemplos particulares a sus carreras, etc.\nActividad en el canal de Slack: contestando dudas de sus compañeros, iniciando discusiones para resolver problemas.\n\n\n\nProfesor\nNombre: Saúl Caballero Ramírez\nCorreo: saul.caballero.ramirez@gmail.com\nCorreo alternativo: saul@nixtla.io\nEl canal más rápido y efectivo será el siguiente canal de Slack. La idea de este canal es que puedan comunicarse entre ustedes para ayudarse a aprender y si necesitan de mi ayuda intentaré contestar en un periodo corto de tiempo. Cualquier comportamiento inadecuado dentro de este foro será penalizado por las reglas de convivencia del ITAM.\n\n\nReferencias principales\n\nAn Introduction to Statistical Learning, James et al. (2023)\nThe Elements of Statistical Learning, Hastie, Tibshirani, y Friedman (2017)\n\n\n\n\n\nHastie, Trevor, Robert Tibshirani, y Jerome Friedman. 2017. The Elements of Statistical Learning. Springer Series en Statistics. Springer New York Inc. https://hastie.su.domains/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, y Jonathan Taylor. 2023. An Introduction to Statistical Learning: With Applications in Python. Springer Texts en Statistics. Cham: Springer. https://doi.org/10.1007/978-3-031-38747-0.",
    "crumbs": [
      "Temario"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 ¿Qué es aprendizaje de máquina?\nMétodos computacionales para aprender de datos con el fin de producir reglas para mejorar el desempeño en alguna tarea o toma de decisión.\nEn este curso nos enfocamos en las tareas de aprendizaje supervisado (predecir o estimar una variable respuesta a partir de datos de entrada) y aprendizaje no supervisado (describir estructuras interesantes en datos, donde no necesariamente hay una respuesta que predecir). Existe también aprendizaje por refuerzo, en donde buscamos aprender a tomar decisiones en un entorno en donde la decisión afecta directa e inmediatamente al entorno.\nLas tareas más apropiadas para este enfoque, en general, son aquellas en donde:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#qué-es-aprendizaje-de-máquina",
    "href": "01-introduccion.html#qué-es-aprendizaje-de-máquina",
    "title": "1  Introducción",
    "section": "",
    "text": "Existe una cantidad considerable de datos relevantes para aprender a ejecutar la tarea.\nEl costo por errores al ejecutar la tarea es relativamente bajo (al menos comparado con alternativas).\nLa tarea se repite de manera más o menos homogénea una cantidad grande de veces.\n\n\nEjemplos de tareas de aprendizaje:\n\nPredecir si un cliente de tarjeta de crédito va a caer en impago en los próximos doce meses.\nEstimar el ingreso mensual de un hogar a partir de las características de la vivienda, posesiones y equipamiento y localización geográfica.\nDividir a los clientes de Netflix según sus gustos.\nRecomendar artículos a clientes de un programa de lealtad o servicio online.\nReconocer un tipos de documentos (identificación, comprobante de domicilio, comprobante de ingresos) para acelerar el proceso de evaluación de crédito.\n\nLas razones usuales para intentar resolver estos problemas computacionalmente son diversas:\n\nQuisiéramos obtener una respuesta barata, rápida, automatizada, y con suficiente precisión. Por ejemplo, reconocer caracteres en una placa de coche de una fotografía se puede hacer por personas, pero eso es lento y costoso. Hacer mediciones directas del ingreso de un hogar requiere mucho tiempo y esfuerzo.\nQuisiéramos superar el desempeño actual de los expertos o de reglas simples utilizando datos: por ejemplo, en la decisión de dar o no un préstamo a un solicitante, puede ser posible tomar mejores decisiones con algoritmos que con evaluaciones personales o con reglas simples que toman en cuenta el ingreso mensual, por ejemplo.\nAl resolver estos problemas computacionalmente tenemos oportunidad de aprender más del problema que nos interesa: estas soluciones forman parte de un ciclo de análisis de datos donde podemos aprender de una forma más concentrada cuáles son características y patrones importantes de nuestros datos.\n\nEs posible aproximarse a todos estos problemas usando reglas (por ejemplo, si los pixeles del centro de la imagen están vacíos, entonces es un cero, si el crédito total es mayor al 50% del ingreso anual, declinar el préstamo, etc). Las razones para no tomar un enfoque de reglas construidas “a mano”:\n\nCuando conjuntos de reglas creadas a mano se desempeñan mal (por ejemplo, para otorgar créditos, reconocer caracteres, etc.)\nReglas creadas a mano pueden ser difíciles de mantener (por ejemplo, un corrector ortográfico), pues para problemas interesantes muchas veces se requieren grandes cantidades de reglas. Por ejemplo: ¿qué búsquedas www se enfocan en dar direcciones como resultados? ¿cómo filtrar comentarios no aceptables en foros?\nFinalmente, notamos que en estos problemas nuestro interés principal no es entender qué variables influyen en otras (en el proceso natural o de negocio). Sin más teoría o diseño de datos, los métodos que utilizaremos explotan patrones en los datos que no necesariamente explican cómo funcionan los sistemas de interés.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "href": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "title": "1  Introducción",
    "section": "1.2 Aprendizaje supervisado y no supervisado",
    "text": "1.2 Aprendizaje supervisado y no supervisado\nLas tareas de aprendizaje se dividen en dos grandes partes: aprendizaje supervisado y aprendizaje no supervisado.\nEn Aprendizaje supervisado buscamos construir un modelo o algoritmo para predecir o estimar un target o una respuesta a partir de ciertas variables de entrada.\nPredecir y estimar, en este contexto, se refieren a cosas similares. Generalmente se usa predecir cuando se trata de variables que no son observables ahora, sino en el futuro, y estimar cuando nos interesan variables actuales que no podemos observar ahora por costos o por la naturaleza del fenómeno.\nPor ejemplo, para identificar a los clientes con alto riesgo de impago de tarjeta de crédito, utilizamos datos históricos de clientes que han pagado y no han pagado. Con estos datos entrenamos un algoritmo para detectar anticipadamente los clientes con alto riesgo de impago.\nUsualmente dividimos los problemas de aprendizaje supervisado en dos tipos, dependiendo de la variables salida:\n\nProblemas de regresión: cuando la salida es una variable numérica. El ejemplo de estimación de ingreso es un problema de regresión\nProblemas de clasificación: cuando la salida es una variable categórica. El ejemplo de detección de dígitos escritos a manos es un problema de clasificación.\n\nEn contraste, en Aprendizaje no supervisado no hay target o variable respuesta. Buscamos modelar y entender las relaciones entre variables y entre observaciones, o patrones importantes o interesantes en los datos.\nLos problemas supervisados tienen un objetivo claro: hacer las mejores predicciones posibles bajo ciertas restricciones. Los problemas no supervisados tienden a tener objetivos más vagos, y por lo mismo pueden ser más difíciles.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "02-principios.html",
    "href": "02-principios.html",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "",
    "text": "2.1 Definición de aprendizaje supervisado\nSupongamos que observamos una variable cuantitativa \\(Y \\in \\mathbb{R}\\) y tenemos \\(p\\) variables predictoras, \\(X_1, X_2, ..., X_p\\), las cuales denotaremos como \\(X = (X_1, X_2, ..., X_p)\\). Supongamos que existe alguna reluación entre ellas y se puede expresar de la siguiente forma:\n\\[ Y = f(x) + \\epsilon\\]\nLa tarea del aprendizaje supervisado es aprender la función \\(f\\). Existen dos razones por las cuales estimar \\(f\\): predicción e inferencia.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "02-principios.html#definición-de-aprendizaje-supervisado",
    "href": "02-principios.html#definición-de-aprendizaje-supervisado",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "",
    "text": "Función \\(f\\): función desconocida que relaciona a \\(X\\) con \\(Y\\). Representa la información sistémica que \\(X\\) aporta a \\(Y\\).\nError \\(\\epsilon\\): representa qué tan equivocados estamos con respecto al verdadero valor de \\(Y\\).\n\n\n\n2.1.1 Predicción\nEn muchas ocasiones existen un conjunto de variables \\(X\\) que están listas para aprovecharse, sin embargo, puede que no se pueda obtener la variable \\(Y\\) de manera inmediata. En este sentido, podemos predecir la variable \\(Y\\) siguiendo la ecuación:\n\\[\\hat{Y} = \\hat{f}(X)\\]\ndonde \\(\\hat{f}\\) representa nuestro estimador de \\(f\\) y \\(\\hat{Y}\\) es nuestra predicción de \\(Y\\). En este sentido \\(\\hat{f}\\) es una caja negra en el sentido en el que no nos preocupa cuál es la función, sino que provee predicciones precisas para \\(Y\\).\nLa precisión de \\(\\hat{Y}\\) depende de dos cantidades:\n\nError reducible: En general, \\(\\hat{f}\\) no será un estimador perfecto de \\(f\\) y esto introducirá un error el cuál puede reducirse. Ejemplos: Introducir una estructura lineal cuándo el problema tiene estructura cuadrática, falta de variables explicativas, exceso de variables que no contribuyen a la predicción.\nError ireducible: La variable \\(Y\\) es una función también de \\(\\epsilon\\) y por definición nuestra predicción tendra un error inherente. Ejemplos: Predecir que comerán mañana, determinar si lloverá o no, determinar cuándo ocurrirá un temblor, ¿quién ganará una elección?.\n\n\\[ \\begin{align*}\n\\mathbb{E}[(Y-\\hat{Y})^2] &= \\mathbb{E}[(f(X) + \\epsilon -\\hat{f}(x))^2]\\\\\n&= \\underset{Reducible}{\\underbrace{\\mathbb{E}[(f(X) - \\hat{f}(x))^2]}} + \\underset{Irreducible}{\\underbrace{\\text{Var}(\\epsilon)}}\n\\end{align*}\\]\nEl objetivo del curso se enfoca en técnicas para estimar \\(f\\) con el objectivo de minimizar el error reducible. Es importante tener en cuenta que el error irreducible siempre nos pondrá una cota en la predicción de \\(Y\\).\n\n\n2.1.2 Inferencia\nExisten problemas en donde nos interesa más entender la relación intrinseca que existe entre \\(Y\\) y \\(X\\). En esta situación nuestro objetivo no es hacer predicción, entonces \\(\\hat{f}\\) ya no puede ser tratada como una caja negra. En este tipo de enfoque se contestan preguntas cómo:\n\n¿Cuáles son los predictores que se asocian con la variable \\(Y\\)?: Muchas veces solo un subconjunto de los datos \\(X\\) son los que realmente están relacionados con \\(Y\\).\n¿Cuál es la relación entre \\(Y\\) y \\(X_i\\)?\n¿La relación entre \\(Y\\) y \\(X_i\\) es lineal o más compleja?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "02-principios.html#cómo-estimar-f",
    "href": "02-principios.html#cómo-estimar-f",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.2 ¿Cómo estimar \\(f\\)?",
    "text": "2.2 ¿Cómo estimar \\(f\\)?\nAsumiremos que tenemos \\(n\\) datos diferentes estas observaciones serán llamadas conjunto de entrenamiento. \\(x_{ij}\\) representa el valor del predictor \\(j\\) para la observación \\(i\\), donde \\(i=1,2,...,n\\) y \\(j=1,2,...,p\\). \\(y_i\\) representa la variable respuesta de la observación \\(i\\). Entonces nuestro conjunto de entrenamiento consiste en:\n\\[{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)}\\]\ndonde \\(x_i=(x_{i1}, x_{i2}, ..., x_{ip})^T\\).\nNuestro objetivo es aplicar un método de aprendizaje en el conjunto de datos para poder estimar una función desconocida de \\(f\\). Nos encantaría encontrar una función \\(\\hat{f}\\) de forma tal que \\(Y\\simeq \\hat{f}(X)\\) para cualquier observación \\((X, Y)\\). Muchos de estos enfoque se pueden caracterizar como métodos paramétricos o no paramétricos.\n\n2.2.1 Métodos paramétricos\nLos métodos paramétricos involucran un enfoque de dos pasos:\n\nHacemos un supuesto de la forma función de \\(f\\). Por ejemplo, la más sencilla es que \\(f\\) es linear en \\(\\beta\\):\n\n\\[ f(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]\nUna vez haciendo haciendo el supuesto de linealidad el problema de estimar \\(f\\) es simplificado ya que en lugar de explorar el espacio funcional uno solo necesita estimar \\(p+1\\) coeficientes \\(\\beta_0, ..., \\beta_p\\).\n\nNecesitamos un proceso que utilice los datos de entrenamiento para ajustar u entrenar el modelo. El enfoque más sencillo es el método de mínimos cuadrados ordinarios (OLS):\n\n\\[\\underset{\\beta_0, \\beta_1, ..., \\beta_p}{min} \\sum_{i=1}^{N}(y_i - (\\beta_0 + \\beta_1 x_{i1} +\\beta_2 x_{i2} + ... + \\beta_p X_p))^2\\]\nEl enfoque basado en modelado se refiere a los modelos paramétricos; reduce el problema de estimar \\(f\\) a estimar un conjunto de parámetros. La desventaja potencial es que el modelo podría no ser igual a la verdadera \\(f\\) y tendremos malas estimaciones del valor de \\(y\\).\n\n\n2.2.2 Métodos no paramétricos",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html",
    "href": "03-regresion_lineal.html",
    "title": "3  Regresión lineal",
    "section": "",
    "text": "3.1 Regresión Lineal Simple\nComenzaremos con el caso más sencillo: predecir una variable de resultado Y a partir de una única variable predictora X.\nEl modelo matemático que queremos ajustar es una línea recta:\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\nDonde:\nNuestro objetivo 🎯 es encontrar los mejores valores posibles para los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) usando los datos que tenemos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#regresión-lineal-simple",
    "href": "03-regresion_lineal.html#regresión-lineal-simple",
    "title": "3  Regresión lineal",
    "section": "",
    "text": "\\(Y\\): La variable dependiente (lo que queremos predecir).\n\\(X\\): La variable independiente (nuestro predictor).\n\\(\\beta_0\\): El intercepto (el valor de \\(Y\\) cuando \\(X=0\\)).\n\\(\\beta_1\\): La pendiente (cuánto cambia \\(Y\\) por cada unidad que aumenta \\(X\\)).\n\\(\\epsilon\\): El término de error (la parte de \\(Y\\) que nuestro modelo no puede explicar).\n\n\n\n3.1.1 ¿Cómo estimamos los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\)?\n“Mejor” para nosotros significa encontrar la línea que minimice la distancia vertical entre cada punto de dato y la propia línea. Específicamente, minimizamos la Suma de los Errores al Cuadrado (SEC o Sum of Squared Errors, SSE).\nLa función de costo (o pérdida) que queremos minimizar es:\n\\[J(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))^2\\]\nTenemos dos métodos principales para encontrar los \\(\\beta\\) que minimizan esta función:\n\n3.1.1.1 Método 1: Las Ecuaciones Normales (La solución analítica 🧠)\nEste método utiliza cálculo para encontrar el mínimo exacto de la función de costo. Para ello, tomamos las derivadas parciales de \\(J\\) con respecto a \\(\\beta_0\\) y \\(\\beta_1\\), las igualamos a cero y resolvemos para los coeficientes.\n\n\n\n\n\n\nDerivada parcial con respecto a \\(\\beta_0\\):\n\n\n\n\n\n\\[\\frac{\\partial J}{\\partial \\beta_0} = \\sum_{i=1}^{n} -2(y_i - \\beta_0 - \\beta_1 x_i) = 0\\] \\[\\sum y_i - n\\beta_0 - \\beta_1 \\sum x_i = 0\\] \\[\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\]\n\n\n\n\n\n\n\n\n\nDerivada parcial con respecto a \\(\\beta_1\\)\n\n\n\n\n\n\\[\\frac{\\partial J}{\\partial \\beta_1} = \\sum_{i=1}^{n} -2x_i(y_i - \\beta_0 - \\beta_1 x_i) = 0\\] Sustituyendo \\(\\beta_0\\) de la primera ecuación y resolviendo, llegamos a: \\[\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\n\n\n\nEstas fórmulas nos dan los valores óptimos y exactos de los coeficientes directamente a partir de los datos.\n\n\n3.1.1.2 Método 2: Descenso en Gradiente (La solución iterativa ⚙️)\nEste es un método computacional que nos “acerca” progresivamente a la solución. Es especialmente útil cuando tenemos una cantidad masiva de datos y calcular la solución analítica es muy costoso.\nLa intuición: Imagina que estás en una montaña (la función de costo) y quieres llegar al valle (el costo mínimo). El Descenso en Gradiente te dice que mires a tu alrededor y des un paso en la dirección más inclinada hacia abajo. Repites esto hasta llegar al fondo.\nEl algoritmo funciona así:\n\nInicializa los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) con valores aleatorios (o en ceros).\nCalcula el gradiente de la función de costo. El gradiente es un vector que apunta en la dirección del máximo ascenso. Nosotros iremos en la dirección opuesta.\n\n\\(\\frac{\\partial J}{\\partial \\beta_0} = -2 \\sum (y_i - (\\beta_0 + \\beta_1 x_i))\\)\n\\(\\frac{\\partial J}{\\partial \\beta_1} = -2 \\sum x_i(y_i - (\\beta_0 + \\beta_1 x_i))\\)\n\nActualiza los coeficientes usando una tasa de aprendizaje (\\(\\alpha\\)), que controla el tamaño del paso que damos.\n\n\\(\\beta_0 := \\beta_0 - \\alpha \\frac{\\partial J}{\\partial \\beta_0}\\)\n\\(\\beta_1 := \\beta_1 - \\alpha \\frac{\\partial J}{\\partial \\beta_1}\\)\n\nRepite los pasos 2 y 3 durante un número determinado de iteraciones o hasta que el cambio en el costo sea muy pequeño (convergencia).\n\n\n\n\n\n\n\nExplicacion visual",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#cuáles-son-los-supuestos-de-la-regresión",
    "href": "03-regresion_lineal.html#cuáles-son-los-supuestos-de-la-regresión",
    "title": "3  Regresión lineal",
    "section": "3.2 ¿Cuáles son los supuestos de la regresión? 🧐",
    "text": "3.2 ¿Cuáles son los supuestos de la regresión? 🧐\nPara que nuestro modelo sea confiable (es decir, para que los coeficientes y las predicciones tengan sentido), debemos cumplir con ciertos supuestos.\n\nLinealidad: La relación entre \\(\\beta\\) y \\(Y\\) debe ser lineal.\n\n¿Para qué sirve? Si la relación no es lineal, nuestro modelo de línea recta será intrínsecamente incorrecto.\n\nIndependencia de los errores: Los errores (residuos) no deben estar correlacionados entre sí.\n\n¿Para qué sirve? Es crucial para datos de series temporales. Si los errores están correlacionados, la información de un error nos da pistas sobre el siguiente, lo cual viola la idea de que cada observación es independiente.\n\nHomocedasticidad (Varianza constante de los errores): La varianza de los errores debe ser constante para todos los niveles de \\(X\\).\n\n¿Para qué sirve? Si la varianza cambia (heterocedasticidad), nuestras predicciones serán mejores para algunas partes de los datos que para otras, y los intervalos de confianza para los coeficientes serán poco fiables. Visualmente, en un gráfico de residuos vs. valores predichos, no queremos ver una forma de cono o embudo.\n\nNormalidad de los errores: Los errores deben seguir una distribución normal con media cero.\n\n¿Para qué sirve? Este supuesto es fundamental para poder realizar pruebas de hipótesis sobre los coeficientes (como los p-values) y construir intervalos de confianza. Podemos verificarlo con un histograma de los residuos o un gráfico Q-Q.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#cómo-evaluar-la-precisión-del-modelo",
    "href": "03-regresion_lineal.html#cómo-evaluar-la-precisión-del-modelo",
    "title": "3  Regresión lineal",
    "section": "3.3 ¿Cómo evaluar la precisión del modelo? 📈",
    "text": "3.3 ¿Cómo evaluar la precisión del modelo? 📈\nUna vez que hemos ajustado el modelo, ¿cómo sabemos si es bueno?\n\n3.3.1 Coeficiente de Determinación (\\(R^2\\))\nEl \\(R^2\\) mide la proporción de la varianza total en la variable dependiente (\\(Y\\)) que es explicada por nuestro modelo.\n\\[R^2 = 1 - \\frac{\\text{Suma de Errores al Cuadrado (SEC)}}{\\text{Suma Total de Cuadrados (STC)}} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\\]\n\n\\(R^2\\) varía entre 0 y 1 (o 0% y 100%).\nUn \\(R^2\\) de 0.85 significa que el 85% de la variabilidad en \\(Y\\) puede ser explicada por \\(X\\).\nUn \\(R^2\\) más alto generalmente indica un mejor ajuste del modelo.\n\n\n\n3.3.2 p-values (Valores p)\nEl p-value nos ayuda a determinar si nuestra variable predictora \\(X\\) es estadísticamente significativa. Responde a la pregunta: ¿Es probable que la relación que observamos entre \\(X\\) y \\(Y\\) haya ocurrido por puro azar?\n\nHipótesis Nula (\\(H_0\\)): No hay relación entre \\(X\\) y \\(Y\\) (es decir, \\(\\beta_1 = 0\\)).\nHipótesis Alternativa (\\(H_a\\)): Sí hay una relación entre \\(X\\) y \\(Y\\) (es decir, \\(\\beta_1 \\neq 0\\)).\n\nUn p-value pequeño (típicamente &lt; 0.05) nos da evidencia para rechazar la hipótesis nula. Esto sugiere que nuestra variable \\(X\\) es un predictor útil para \\(Y\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#métricas-de-error-de-predicción",
    "href": "03-regresion_lineal.html#métricas-de-error-de-predicción",
    "title": "3  Regresión lineal",
    "section": "3.4 Métricas de Error de Predicción",
    "text": "3.4 Métricas de Error de Predicción\nAdemás del \\(R^2\\), existen múltiples métricas para evaluar qué tan bien predice nuestro modelo. Cada una tiene sus ventajas y casos de uso específicos:\n\n3.4.1 Error Cuadrático Medio (MSE)\nEl MSE mide el promedio de los errores al cuadrado:\n\\[MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\]\n\nVentajas: Penaliza fuertemente errores grandes, diferenciable (útil para optimización)\nDesventajas: Sensible a valores atípicos, difícil de interpretar (unidades al cuadrado)\nCuándo usar: Cuando errores grandes son especialmente costosos\n\n\n\n3.4.2 Raíz del Error Cuadrático Medio (RMSE)\nEl RMSE es la raíz cuadrada del MSE:\n\\[RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\\]\n\nVentajas: Mismas unidades que la variable objetivo, interpretable\nDesventajas: Aún sensible a valores atípicos\nInterpretación: “En promedio, nuestras predicciones se desvían X unidades del valor real”\n\n\n\n3.4.3 Error Absoluto Medio (MAE)\nEl MAE mide el promedio de los errores absolutos:\n\\[MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\\]\n\nVentajas: Robusto a valores atípicos, fácil de interpretar\nDesventajas: No diferenciable en cero, trata todos los errores por igual\nCuándo usar: Cuando hay valores atípicos o todos los errores tienen igual importancia\n\n\n\n3.4.4 Error Porcentual Absoluto Medio (MAPE)\nEl MAPE expresa el error como porcentaje del valor real:\n\\[MAPE = \\frac{100}{n} \\sum_{i=1}^{n} \\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right|\\]\n\nVentajas: Interpretable (% de error), adimensional, útil para comparar modelos en diferentes escalas\nDesventajas: Indefinido cuando \\(y_i = 0\\), asimétrico (penaliza más las sobreestimaciones)\nInterpretación: “Nuestras predicciones se desvían en promedio X% del valor real”\nCuándo usar: Para comparar precisión entre diferentes productos, regiones, o escalas\n\n\n\n3.4.5 Error Porcentual Absoluto Medio Simétrico (SMAPE)\nEl SMAPE es una versión simétrica del MAPE:\n\\[SMAPE = \\frac{100}{n} \\sum_{i=1}^{n} \\frac{|y_i - \\hat{y}_i|}{(|y_i| + |\\hat{y}_i|)/2}\\]\n\nVentajas: Simétrico, acotado entre 0% y 200%\nDesventajas: Puede ser contraintuitivo, no tan estándar como MAPE\nCuándo usar: Cuando queremos evitar el sesgo del MAPE hacia sobreestimaciones\n\n\n\n3.4.6 Error Logarítmico Cuadrático Medio (MSLE)\nEl MSLE usa transformación logarítmica:\n\\[MSLE = \\frac{1}{n} \\sum_{i=1}^{n} (\\log(1 + y_i) - \\log(1 + \\hat{y}_i))^2\\]\n\nVentajas: Penaliza más las subestimaciones que las sobreestimaciones\nDesventajas: Solo para valores positivos, menos interpretable\nCuándo usar: Cuando subestimar es más costoso que sobreestimar (ej: demanda de inventario)\n\n\n\n3.4.7 \\(R^2\\) Ajustado\nEl \\(R^2\\) ajustado penaliza por el número de variables en el modelo:\n\\[R^2_{adj} = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}\\]\nDonde \\(p\\) es el número de predictores.\n\nVentajas: No aumenta automáticamente al añadir variables\nCuándo usar: Para comparar modelos con diferente número de variables\nInterpretación: Similar a \\(R^2\\) pero más conservador\n\n\n3.4.7.1 ¿Cuál métrica elegir?\nLa elección de métrica depende del contexto del problema:\n\n\n\n\n\n\n\n\nMétrica\nMejor para\nEvitar cuando\n\n\n\n\nRMSE\nErrores grandes son costosos\nHay muchos valores atípicos\n\n\nMAE\nErrores tienen igual importancia\nNecesitas diferenciabilidad\n\n\nMAPE\nComparar diferentes escalas\nHay valores cercanos a cero\n\n\nSMAPE\nComparar con simetría\nInterpretación debe ser simple\n\n\nR²\nExplicar variabilidad\nSolo importa precisión de predicción\n\n\n\n\n\n\n\n\n\nRecomendación práctica\n\n\n\nUsa múltiples métricas para evaluar tu modelo. Una combinación típica sería: - RMSE para precisión general - MAPE para interpretabilidad de negocio\n- R² para explicación de variabilidad",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#regresión-lineal-múltiple",
    "href": "03-regresion_lineal.html#regresión-lineal-múltiple",
    "title": "3  Regresión lineal",
    "section": "3.5 Regresión Lineal Múltiple",
    "text": "3.5 Regresión Lineal Múltiple\nAhora, ¿qué pasa si tenemos múltiples predictores (\\(X_1, X_2, ..., X_p\\))? El modelo se expande:\n\\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\epsilon\\]\nLa intuición es la misma, pero en lugar de ajustar una línea, estamos ajustando un hiperplano en un espacio multidimensional.\nPara manejar esto de forma elegante, usamos notación matricial:\n\\[\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\]\nDonde: - \\(\\mathbf{y}\\) es el vector de observaciones. - \\(\\mathbf{X}\\) es la matriz de diseño (con una primera columna de unos para el intercepto). - \\(\\boldsymbol{\\beta}\\) es el vector de coeficientes. - \\(\\boldsymbol{\\epsilon}\\) es el vector de errores.\nLa función de costo en forma matricial es: \\[J(\\boldsymbol{\\beta}) = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#transformaciones-comunes-en-modelos-lineales",
    "href": "03-regresion_lineal.html#transformaciones-comunes-en-modelos-lineales",
    "title": "3  Regresión lineal",
    "section": "3.6 Transformaciones Comunes en Modelos Lineales",
    "text": "3.6 Transformaciones Comunes en Modelos Lineales\nA veces, la relación entre X e Y no es estrictamente lineal. Las transformaciones logarítmicas nos permiten modelar relaciones no lineales y, además, ofrecen interpretaciones muy útiles en términos de cambios porcentuales.\n\n3.6.1 Modelo Log-Nivel (Transformación en Y)\nEste modelo se usa cuando el efecto de X sobre Y no es absoluto, sino porcentual. Por ejemplo, cómo un año más de educación afecta el porcentaje de aumento salarial.\n\nEcuación: \\(\\ln(Y) = \\beta_0 + \\beta_1 X + \\epsilon\\)\nInterpretación: Un incremento de una unidad en \\(X\\) está asociado con un cambio de \\((100 \\cdot \\beta_1)\\%\\) en \\(Y\\).\n\n\n\n\n\n\n\nExplicación Matemática de la Aproximación\n\n\n\n\n\nLa clave está en la propiedad del logaritmo y el cálculo. La derivada de \\(\\ln(Y)\\) con respecto a \\(X\\) es \\(\\beta_1\\): \\[\\frac{d(\\ln(Y))}{dX} = \\beta_1\\] Sabemos que \\(d(\\ln(Y)) = \\frac{dY}{Y}\\). Por tanto: \\[\\frac{dY/Y}{dX} = \\beta_1\\] Para cambios pequeños (o discretos, \\(\\Delta\\)), podemos aproximar los diferenciales: \\[\\beta_1 \\approx \\frac{\\Delta Y / Y}{\\Delta X}\\] Si consideramos un cambio unitario en X, \\(\\Delta X = 1\\), entonces: \\[\\beta_1 \\approx \\frac{\\Delta Y}{Y}\\] Esto significa que \\(\\beta_1\\) es la aproximación del cambio porcentual en \\(Y\\) ante un cambio de una unidad en \\(X\\).\n\n\n\n\n\n3.6.2 Modelo Nivel-Log (Transformación en X)\nEste modelo es útil cuando el efecto de X sobre Y se reduce a medida que X aumenta (rendimientos decrecientes). Por ejemplo, el efecto de añadir presupuesto de marketing sobre las ventas.\n\nEcuación: \\(Y = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\\)\nInterpretación: Un incremento del 1% en \\(X\\) está asociado con un cambio de \\((\\beta_1 / 100)\\) unidades en \\(Y\\).\n\n\n\n\n\n\n\nExplicación Matemática de la Aproximación\n\n\n\n\n\nTomamos la derivada de \\(Y\\) con respecto a \\(\\ln(X)\\): \\[\\frac{dY}{d(\\ln(X))} = \\beta_1\\] Usando la regla de la cadena, sabemos que \\(d(\\ln(X)) = \\frac{dX}{X}\\). Sustituyendo: \\[\\frac{dY}{dX/X} = \\beta_1 \\implies dY = \\beta_1 \\frac{dX}{X}\\] Para cambios discretos, aproximamos: \\[\\Delta Y \\approx \\beta_1 \\frac{\\Delta X}{X}\\] Si consideramos un cambio del 1% en X, entonces \\(\\frac{\\Delta X}{X} = 0.01\\). La ecuación se convierte en: \\[\\Delta Y \\approx \\beta_1 (0.01) = \\frac{\\beta_1}{100}\\] Esto significa que un cambio del 1% en \\(X\\) provoca un cambio de \\(\\beta_1/100\\) unidades en \\(Y\\).\n\n\n\n\n\n3.6.3 Modelo Log-Log (Transformación en X e Y)\nEste modelo es muy común en economía y modela la elasticidad constante entre dos variables.\n\nEcuación: \\(\\ln(Y) = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\\)\nInterpretación: Un incremento del 1% en \\(X\\) está asociado con un cambio del \\(\\beta_1\\%\\) en \\(Y\\).\n\n\n\n\n\n\n\nExplicación Matemática de la Aproximación\n\n\n\n\n\nEste caso combina los dos anteriores. \\(\\beta_1\\) es la derivada de \\(\\ln(Y)\\) con respecto a \\(\\ln(X)\\), que es la definición de elasticidad. \\[\\beta_1 = \\frac{d(\\ln(Y))}{d(\\ln(X))}\\] Usando las propiedades del cálculo que vimos antes: \\[\\beta_1 = \\frac{dY/Y}{dX/X}\\] Aproximando para cambios discretos: \\[\\beta_1 \\approx \\frac{\\Delta Y / Y}{\\Delta X / X}\\] Esta es la definición de elasticidad: el cambio porcentual en \\(Y\\) dividido por el cambio porcentual en \\(X\\). Por lo tanto, si \\(X\\) cambia en un 1% (\\(\\Delta X / X = 0.01\\)), el cambio porcentual en \\(Y\\) (\\(\\Delta Y / Y\\)) será aproximadamente \\(\\beta_1 \\times 0.01\\), es decir, un \\(\\beta_1\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#regresión-regularizada-penalizada",
    "href": "03-regresion_lineal.html#regresión-regularizada-penalizada",
    "title": "3  Regresión lineal",
    "section": "3.7 Regresión Regularizada (Penalizada) 🎯",
    "text": "3.7 Regresión Regularizada (Penalizada) 🎯\nHasta ahora hemos visto la regresión lineal clásica, pero ¿qué pasa cuando tenemos muchas variables o cuando nuestro modelo sufre de sobreajuste? Aquí es donde entran las técnicas de regularización.\n\n3.7.1 ¿Por qué necesitamos regularización?\nLa regresión lineal ordinaria (OLS) puede presentar varios problemas:\n\nSobreajuste: Cuando tenemos muchas variables relativas al número de observaciones\nMulticolinealidad: Variables predictoras altamente correlacionadas\nInestabilidad: Pequeños cambios en los datos causan grandes cambios en los coeficientes\nInterpretabilidad: Demasiadas variables hacen difícil entender el modelo\n\nLa regularización añade una penalización a la función de costo para controlar la complejidad del modelo.\n\n\n\n3.7.2 Ridge Regression (Regresión Ridge) 🏔️\nLa regresión Ridge añade una penalización L2 (suma de cuadrados) a los coeficientes:\n\\[J_{Ridge}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\\]\nDonde: - \\(\\lambda &gt; 0\\) es el parámetro de regularización - \\(\\sum_{j=1}^{p} \\beta_j^2\\) es la penalización L2\n\n3.7.2.1 Características de Ridge:\n✅ Ventajas: - Reduce el sobreajuste - Maneja bien la multicolinealidad - Siempre tiene solución única - Estabiliza los coeficientes\n❌ Desventajas: - NO elimina variables (coeficientes nunca son exactamente cero) - Dificulta la interpretabilidad - Requiere estandarizar las variables\n\n\n3.7.2.2 Solución Analítica:\n\\[\\hat{\\boldsymbol{\\beta}}_{Ridge} = (\\mathbf{X}^T\\mathbf{X} + \\lambda\\mathbf{I})^{-1}\\mathbf{X}^T\\mathbf{y}\\]\nEl término \\(\\lambda\\mathbf{I}\\) hace que la matriz sea invertible incluso con multicolinealidad.\n\n\n3.7.2.3 ¿Cómo elegir λ?\n\nλ = 0: Regresión ordinaria (sin penalización)\nλ → ∞: Todos los coeficientes → 0\nλ óptimo: Se encuentra usando validación cruzada\n\n\n\n\n\n3.7.3 Lasso Regression (Least Absolute Shrinkage and Selection Operator) ✂️\nLa regresión Lasso usa penalización L1 (suma de valores absolutos):\n\\[J_{Lasso}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|\\]\n\n3.7.3.1 Características de Lasso:\n✅ Ventajas: - Selección automática de variables (coeficientes = 0) - Modelos más interpretables y simples - Útil cuando muchas variables son irrelevantes\n❌ Desventajas: - Puede ser inestable con grupos de variables correlacionadas - Selecciona arbitrariamente entre variables correlacionadas - No tiene solución analítica cerrada\n\n\n3.7.3.2 La “Magia” de L1: ¿Por qué produce ceros exactos?\nLa penalización L1 crea una región factible con esquinas puntiagudas. La solución óptima tiende a ocurrir en estas esquinas, donde algunos coeficientes son exactamente cero.\n\n\n\n\n\n\nIntuición Geométrica\n\n\n\n\n\nImagina que estás minimizando una función bajo la restricción de que \\(|\\beta_1| + |\\beta_2| \\leq t\\). Esta restricción forma un diamante en 2D. La función objetivo forma elipses. La solución está donde la elipse más pequeña toca el diamante, y esto frecuentemente ocurre en los vértices (donde \\(\\beta_1 = 0\\) o \\(\\beta_2 = 0\\)).\n\n\n\n\n\n\n\n3.7.4 Elastic Net: Lo Mejor de Ambos Mundos 🕸️\nElastic Net combina las penalizaciones L1 y L2:\n\\[J_{ElasticNet}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda_1 \\sum_{j=1}^{p} |\\beta_j| + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2\\]\nO equivalentemente, con un parámetro de mezcla \\(\\alpha\\):\n\\[J_{ElasticNet}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda \\left[ \\alpha \\sum_{j=1}^{p} |\\beta_j| + (1-\\alpha) \\sum_{j=1}^{p} \\beta_j^2 \\right]\\]\nDonde: - \\(\\alpha \\in [0,1]\\) controla la mezcla entre L1 y L2 - \\(\\alpha = 0\\): Pure Ridge - \\(\\alpha = 1\\): Pure Lasso - \\(\\alpha = 0.5\\): Igual peso a ambas penalizaciones\n\n3.7.4.1 Características de Elastic Net:\n✅ Ventajas: - Selección de variables como Lasso - Estabilidad como Ridge - Maneja bien grupos de variables correlacionadas - Más flexible que Ridge o Lasso por separado\n❌ Desventajas: - Dos hiperparámetros para ajustar (\\(\\lambda\\) y \\(\\alpha\\)) - Más complejo computacionalmente\n\n\n\n\n3.7.5 Comparación Visual: Ridge vs Lasso vs Elastic Net\n\n\n\n\n\n\n\n\n\nAspecto\nRidge\nLasso\nElastic Net\n\n\n\n\nPenalización\nL2: \\(\\sum \\beta_j^2\\)\nL1: \\(\\sum |\\beta_j|\\)\nL1 + L2 combinadas\n\n\nSelección de variables\n❌ No\n✅ Sí\n✅ Sí\n\n\nCoeficientes exactamente cero\n❌ No\n✅ Sí\n✅ Sí\n\n\nManejo de multicolinealidad\n✅ Excelente\n⚠️ Problemático\n✅ Muy bueno\n\n\nEstabilidad\n✅ Alta\n⚠️ Media\n✅ Alta\n\n\nInterpretabilidad\n⚠️ Media\n✅ Alta\n✅ Alta\n\n\nCuando usar\nTodas las variables importan\nPocas variables importantes\nSituaciones mixtas\n\n\n\n\n\n3.7.6 ¿Cuándo usar cada método?\n\n3.7.6.1 Usa Ridge cuando:\n\nCrees que todas las variables contribuyen al modelo\nTienes multicolinealidad severa\nQuieres estabilizar coeficientes sin eliminar variables\nEl número de observaciones es pequeño relativo a variables\n\n\n\n3.7.6.2 Usa Lasso cuando:\n\nCrees que pocas variables son realmente importantes\nQuieres un modelo simple e interpretable\nNecesitas selección automática de variables\nTienes muchas variables irrelevantes\n\n\n\n3.7.6.3 Usa Elastic Net cuando:\n\nNo estás seguro de cuántas variables son importantes\nTienes grupos de variables correlacionadas\nQuieres balancear selección y estabilidad\nEs tu primera opción cuando no conoces la estructura de los datos\n\n\n\n\n\n3.7.7 Validación de Modelos y Selección de Hiperparámetros\n\n3.7.7.1 ¿Por qué necesitamos dividir nuestros datos?\nCuando construimos modelos de machine learning, enfrentamos un dilema fundamental: ¿cómo sabemos si nuestro modelo funcionará bien con datos nuevos?\n\n3.7.7.1.1 El Problema del Sobreajuste\nImagina que estás preparándote para un examen. Si solo estudias las preguntas exactas que aparecerán en el examen, podrías obtener una calificación perfecta. Pero si las preguntas cambian ligeramente, tu rendimiento se desplomaría. Esto es sobreajuste: el modelo memoriza los datos de entrenamiento pero no generaliza.\n\n\n\n3.7.7.2 División Típica de Datos: Entrenamiento/Validación/Prueba\nLa estrategia estándar es dividir nuestros datos en tres conjuntos:\n📊 Dataset Completo (100%)\n├── 🏋️ Entrenamiento (60%) - Para ajustar coeficientes\n├── 🎯 Validación (20%)     - Para seleccionar hiperparámetros  \n└── 🧪 Prueba (20%)         - Para evaluación final\n\n3.7.7.2.1 Conjunto de Entrenamiento (60%)\n\nPropósito: Ajustar los coeficientes \\(\\beta\\) del modelo\nAnalogía: Los ejercicios que haces para aprender\n\n\n\n3.7.7.2.2 Conjunto de Validación (20%)\n\nPropósito: Comparar diferentes hiperparámetros (como \\(\\lambda\\) en Ridge/Lasso)\nAnalogía: Exámenes de práctica para decidir qué estrategia de estudio funciona mejor\n\n\n\n3.7.7.2.3 Conjunto de Prueba (20%)\n\nPropósito: Evaluación final y honesta del modelo\nAnalogía: El examen final real\n⚠️ Regla de Oro: ¡Solo se usa UNA vez al final!\n\n\n\n\n3.7.7.3 ¿Qué pasa si tenemos pocos datos?\nCuando nuestro dataset es pequeño (&lt; 1000 observaciones), dividir en tres partes puede ser problemático:\n❌ Problemas con datasets pequeños: - Conjunto de entrenamiento muy pequeño → modelo pobre - Conjunto de validación pequeño → selección inestable de hiperparámetros - Conjunto de prueba pequeño → evaluación poco confiable\nSolución: ¡Validación Cruzada!\n\n\n\n3.7.7.4 Validación Cruzada (Cross-Validation)\nLa validación cruzada es una técnica que maximiza el uso de nuestros datos limitados. En lugar de usar una sola división, usamos múltiples divisiones.\n\n3.7.7.4.1 Validación Cruzada k-fold\nEl método más común es k-fold cross-validation:\n\nDividir el dataset en \\(k\\) “pliegues” (folds) de igual tamaño\nRepetir \\(k\\) veces:\n\nUsar \\(k-1\\) pliegues para entrenamiento\nUsar 1 pliegue para validación\n\nPromediar los resultados de las \\(k\\) evaluaciones\n\n\n\n\n\n\nVisualización de 5-Fold Cross Validation mostrando cómo se dividen los datos en cada iteración\n\n\n\n\n\n\n3.7.7.4.2 Ventajas de la Validación Cruzada\n✅ Maximiza el uso de datos: Cada observación se usa tanto para entrenamiento como validación\n✅ Estimación más robusta: Promedia múltiples evaluaciones independientes\n✅ Reduce la varianza: Menos dependiente de una división particular\n✅ Detecta inestabilidad: Si los resultados varían mucho entre folds, el modelo es inestable\n\n\n\n3.7.7.5 Validación Cruzada para Selección de Hiperparámetros\nEn regresión regularizada, usamos CV para encontrar el mejor \\(\\lambda\\):\n\n\n🎯 SELECCIÓN DE HIPERPARÁMETROS CON VALIDACIÓN CRUZADA\n============================================================\nPara cada valor de λ:\n  1. Aplicar 5-fold CV\n  2. Calcular error promedio\n  3. Seleccionar λ con menor error\n\n\n\n\n\nCurva de validación mostrando cómo seleccionar el hiperparámetro óptimo λ usando validación cruzada\n\n\n\n\n\n📈 Resultado: λ óptimo = 0.1274\n📉 Error de CV mínimo = 0.4776\n\n\n\n\n3.7.7.6 Proceso Completo de Validación\nEl flujo completo para modelos regularizados es:\n1. 📊 Dividir datos originales\n   └── 80% para desarrollo (entrenamiento + validación)\n   └── 20% para prueba final (¡NO TOCAR hasta el final!)\n\n2. 🔄 En el conjunto de desarrollo:\n   └── Para cada λ candidato:\n       ├── Aplicar k-fold CV\n       ├── Calcular error promedio\n       └── Guardar resultado\n\n3. 🎯 Seleccionar λ con menor error de CV\n\n4. 🏗️ Entrenar modelo final con λ óptimo en TODO el conjunto de desarrollo\n\n5. 🧪 Evaluación final en conjunto de prueba\n\n\n3.7.7.7 Variantes de Validación Cruzada\n\n3.7.7.7.1 Leave-One-Out CV (LOOCV)\n\nk = n (número de observaciones)\nVentaja: Máximo uso de datos para entrenamiento\nDesventaja: Computacionalmente costoso, alta varianza\n\n\n\n3.7.7.7.2 Stratified CV\n\nPara problemas de clasificación\nMantiene la proporción de clases en cada fold\n\n\n\n3.7.7.7.3 Time Series CV\n\nPara datos temporales\nRespeta el orden temporal (no mezcla futuro con pasado)\n\n\n\n\n\n\n\n⚠️ Errores Comunes\n\n\n\n\nData Leakage: Usar información del conjunto de prueba durante el desarrollo\nMúltiples evaluaciones: Evaluar repetidamente en el conjunto de prueba\nSelección de modelo sesgada: Elegir el modelo basándose en el conjunto de prueba\nCV incorrecto: Aplicar transformaciones antes de la división de CV\n\n\n\n\n\n\n3.7.7.8 ¿Cuándo usar cada enfoque?\n\n\n\n\n\n\n\n\nTamaño del Dataset\nEnfoque Recomendado\nRazón\n\n\n\n\nGrande (&gt;10,000)\nTrain/Validation/Test\nSuficientes datos para división estable\n\n\nMediano (1,000-10,000)\nTrain/Test + CV\nCV para hiperparámetros, test para evaluación final\n\n\nPequeño (&lt;1,000)\nSolo CV (sin test separado)\nMaximizar datos disponibles\n\n\nMuy pequeño (&lt;100)\nLOOCV o Bootstrap\nCada observación es valiosa\n\n\n\n\n\n\n\n\n\nConsejo Práctico\n\n\n\nEmpieza siempre con Elastic Net con \\(\\alpha = 0.5\\). Si el modelo selecciona muchas variables, prueba valores de \\(\\alpha\\) más cercanos a 1 (más Lasso). Si elimina variables importantes, prueba valores cercanos a 0 (más Ridge).\n\n\n\n\n\n\n3.7.8 Ejercicio Práctico: Comparando los Tres Métodos\nEn el notebook correspondiente, implementaremos:\n\nGeneración de datos con diferentes estructuras de correlación\nComparación visual de los caminos de regularización\nValidación cruzada para selección de hiperparámetros\nEvaluación del rendimiento en datos de prueba\nInterpretación de los coeficientes seleccionados\n\nPregunta de reflexión: ¿En qué situaciones esperarías que Ridge supere a Lasso, y viceversa?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regresión lineal</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The\nElements of Statistical Learning. Springer Series in Statistics.\nSpringer New York Inc. https://hastie.su.domains/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, and\nJonathan Taylor. 2023. An Introduction to\nStatistical Learning: With Applications in Python. Springer\nTexts in Statistics. Cham: Springer. https://doi.org/10.1007/978-3-031-38747-0.",
    "crumbs": [
      "Referencias"
    ]
  }
]