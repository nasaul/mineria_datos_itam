[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Miner√≠a de Datos",
    "section": "",
    "text": "Temario\n\nIntroducci√≥n al aprendizaje de m√°quina\nPrincipios de aprendizaje supervisado\nRegresi√≥n lineal\nM√©todos de remuestreo y validaci√≥n cruzada\nPrincipios de Regularizaci√≥n\nProblemas de clasificaci√≥n, m√©tricas y evaluaci√≥n\n√Årboles, bosques aleatorios y boosting\nRedes neuronales\nM√©todos no supervisados\n\n\nEvaluaci√≥n\n\nDos ex√°menes parciales (40%)\nProyecto final (30%):\n\nEntrega (75%)\nExposici√≥n (25%)\n\n\nExamen final (30%)\n\nExistir√° una parte extra a los alumnos que contribuyan al aprendizaje de sus compa√±eros:\n\nContribuciones al repositorio: a√±adiendo redacci√≥n m√°s entendible, a√±adiendo ejemplos particulares a sus carreras, etc.\nActividad en el canal de Slack: contestando dudas de sus compa√±eros, iniciando discusiones para resolver problemas.\n\n\n\nProfesor\nNombre: Sa√∫l Caballero Ram√≠rez\nCorreo: saul.caballero.ramirez@gmail.com\nCorreo alternativo: saul@nixtla.io\nEl canal m√°s r√°pido y efectivo ser√° el siguiente canal de Slack. La idea de este canal es que puedan comunicarse entre ustedes para ayudarse a aprender y si necesitan de mi ayuda intentar√© contestar en un periodo corto de tiempo. Cualquier comportamiento inadecuado dentro de este foro ser√° penalizado por las reglas de convivencia del ITAM.\n\n\nReferencias principales\n\nAn Introduction to Statistical Learning, James et¬†al. (2023)\nThe Elements of Statistical Learning, Hastie, Tibshirani, y Friedman (2017)\n\n\n\n\n\nHastie, Trevor, Robert Tibshirani, y Jerome Friedman. 2017. The Elements of Statistical Learning. Springer Series en Statistics. Springer New York Inc. https://hastie.su.domains/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, y Jonathan Taylor. 2023. An Introduction to Statistical Learning: With Applications in Python. Springer Texts en Statistics. Cham: Springer. https://doi.org/10.1007/978-3-031-38747-0.",
    "crumbs": [
      "Temario"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1¬† Introducci√≥n",
    "section": "",
    "text": "1.1 ¬øQu√© es aprendizaje de m√°quina?\nM√©todos computacionales para aprender de datos con el fin de producir reglas para mejorar el desempe√±o en alguna tarea o toma de decisi√≥n.\nEn este curso nos enfocamos en las tareas de aprendizaje supervisado (predecir o estimar una variable respuesta a partir de datos de entrada) y aprendizaje no supervisado (describir estructuras interesantes en datos, donde no necesariamente hay una respuesta que predecir). Existe tambi√©n aprendizaje por refuerzo, en donde buscamos aprender a tomar decisiones en un entorno en donde la decisi√≥n afecta directa e inmediatamente al entorno.\nLas tareas m√°s apropiadas para este enfoque, en general, son aquellas en donde:",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#qu√©-es-aprendizaje-de-m√°quina",
    "href": "01-introduccion.html#qu√©-es-aprendizaje-de-m√°quina",
    "title": "1¬† Introducci√≥n",
    "section": "",
    "text": "Existe una cantidad considerable de datos relevantes para aprender a ejecutar la tarea.\nEl costo por errores al ejecutar la tarea es relativamente bajo (al menos comparado con alternativas).\nLa tarea se repite de manera m√°s o menos homog√©nea una cantidad grande de veces.\n\n\nEjemplos de tareas de aprendizaje:\n\nPredecir si un cliente de tarjeta de cr√©dito va a caer en impago en los pr√≥ximos doce meses.\nEstimar el ingreso mensual de un hogar a partir de las caracter√≠sticas de la vivienda, posesiones y equipamiento y localizaci√≥n geogr√°fica.\nDividir a los clientes de Netflix seg√∫n sus gustos.\nRecomendar art√≠culos a clientes de un programa de lealtad o servicio online.\nReconocer un tipos de documentos (identificaci√≥n, comprobante de domicilio, comprobante de ingresos) para acelerar el proceso de evaluaci√≥n de cr√©dito.\n\nLas razones usuales para intentar resolver estos problemas computacionalmente son diversas:\n\nQuisi√©ramos obtener una respuesta barata, r√°pida, automatizada, y con suficiente precisi√≥n. Por ejemplo, reconocer caracteres en una placa de coche de una fotograf√≠a se puede hacer por personas, pero eso es lento y costoso. Hacer mediciones directas del ingreso de un hogar requiere mucho tiempo y esfuerzo.\nQuisi√©ramos superar el desempe√±o actual de los expertos o de reglas simples utilizando datos: por ejemplo, en la decisi√≥n de dar o no un pr√©stamo a un solicitante, puede ser posible tomar mejores decisiones con algoritmos que con evaluaciones personales o con reglas simples que toman en cuenta el ingreso mensual, por ejemplo.\nAl resolver estos problemas computacionalmente tenemos oportunidad de aprender m√°s del problema que nos interesa: estas soluciones forman parte de un ciclo de an√°lisis de datos donde podemos aprender de una forma m√°s concentrada cu√°les son caracter√≠sticas y patrones importantes de nuestros datos.\n\nEs posible aproximarse a todos estos problemas usando reglas (por ejemplo, si los pixeles del centro de la imagen est√°n vac√≠os, entonces es un cero, si el cr√©dito total es mayor al 50% del ingreso anual, declinar el pr√©stamo, etc). Las razones para no tomar un enfoque de reglas construidas ‚Äúa mano‚Äù:\n\nCuando conjuntos de reglas creadas a mano se desempe√±an mal (por ejemplo, para otorgar cr√©ditos, reconocer caracteres, etc.)\nReglas creadas a mano pueden ser dif√≠ciles de mantener (por ejemplo, un corrector ortogr√°fico), pues para problemas interesantes muchas veces se requieren grandes cantidades de reglas. Por ejemplo: ¬øqu√© b√∫squedas www se enfocan en dar direcciones como resultados? ¬øc√≥mo filtrar comentarios no aceptables en foros?\nFinalmente, notamos que en estos problemas nuestro inter√©s principal no es entender qu√© variables influyen en otras (en el proceso natural o de negocio). Sin m√°s teor√≠a o dise√±o de datos, los m√©todos que utilizaremos explotan patrones en los datos que no necesariamente explican c√≥mo funcionan los sistemas de inter√©s.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "href": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "title": "1¬† Introducci√≥n",
    "section": "1.2 Aprendizaje supervisado y no supervisado",
    "text": "1.2 Aprendizaje supervisado y no supervisado\nLas tareas de aprendizaje se dividen en dos grandes partes: aprendizaje supervisado y aprendizaje no supervisado.\nEn Aprendizaje supervisado buscamos construir un modelo o algoritmo para predecir o estimar un target o una respuesta a partir de ciertas variables de entrada.\nPredecir y estimar, en este contexto, se refieren a cosas similares. Generalmente se usa predecir cuando se trata de variables que no son observables ahora, sino en el futuro, y estimar cuando nos interesan variables actuales que no podemos observar ahora por costos o por la naturaleza del fen√≥meno.\nPor ejemplo, para identificar a los clientes con alto riesgo de impago de tarjeta de cr√©dito, utilizamos datos hist√≥ricos de clientes que han pagado y no han pagado. Con estos datos entrenamos un algoritmo para detectar anticipadamente los clientes con alto riesgo de impago.\nUsualmente dividimos los problemas de aprendizaje supervisado en dos tipos, dependiendo de la variables salida:\n\nProblemas de regresi√≥n: cuando la salida es una variable num√©rica. El ejemplo de estimaci√≥n de ingreso es un problema de regresi√≥n\nProblemas de clasificaci√≥n: cuando la salida es una variable categ√≥rica. El ejemplo de detecci√≥n de d√≠gitos escritos a manos es un problema de clasificaci√≥n.\n\nEn contraste, en Aprendizaje no supervisado no hay target o variable respuesta. Buscamos modelar y entender las relaciones entre variables y entre observaciones, o patrones importantes o interesantes en los datos.\nLos problemas supervisados tienen un objetivo claro: hacer las mejores predicciones posibles bajo ciertas restricciones. Los problemas no supervisados tienden a tener objetivos m√°s vagos, y por lo mismo pueden ser m√°s dif√≠ciles.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "02-principios.html",
    "href": "02-principios.html",
    "title": "2¬† Principios de aprendizaje supervisado",
    "section": "",
    "text": "2.1 Definici√≥n de aprendizaje supervisado\nSupongamos que observamos una variable cuantitativa \\(Y \\in \\mathbb{R}\\) y tenemos \\(p\\) variables predictoras, \\(X_1, X_2, ..., X_p\\), las cuales denotaremos como \\(X = (X_1, X_2, ..., X_p)\\). Supongamos que existe alguna reluaci√≥n entre ellas y se puede expresar de la siguiente forma:\n\\[ Y = f(x) + \\epsilon\\]\nLa tarea del aprendizaje supervisado es aprender la funci√≥n \\(f\\). Existen dos razones por las cuales estimar \\(f\\): predicci√≥n e inferencia.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "02-principios.html#definici√≥n-de-aprendizaje-supervisado",
    "href": "02-principios.html#definici√≥n-de-aprendizaje-supervisado",
    "title": "2¬† Principios de aprendizaje supervisado",
    "section": "",
    "text": "Funci√≥n \\(f\\): funci√≥n desconocida que relaciona a \\(X\\) con \\(Y\\). Representa la informaci√≥n sist√©mica que \\(X\\) aporta a \\(Y\\).\nError \\(\\epsilon\\): representa qu√© tan equivocados estamos con respecto al verdadero valor de \\(Y\\).\n\n\n\n2.1.1 Predicci√≥n\nEn muchas ocasiones existen un conjunto de variables \\(X\\) que est√°n listas para aprovecharse, sin embargo, puede que no se pueda obtener la variable \\(Y\\) de manera inmediata. En este sentido, podemos predecir la variable \\(Y\\) siguiendo la ecuaci√≥n:\n\\[\\hat{Y} = \\hat{f}(X)\\]\ndonde \\(\\hat{f}\\) representa nuestro estimador de \\(f\\) y \\(\\hat{Y}\\) es nuestra predicci√≥n de \\(Y\\). En este sentido \\(\\hat{f}\\) es una caja negra en el sentido en el que no nos preocupa cu√°l es la funci√≥n, sino que provee predicciones precisas para \\(Y\\).\nLa precisi√≥n de \\(\\hat{Y}\\) depende de dos cantidades:\n\nError reducible: En general, \\(\\hat{f}\\) no ser√° un estimador perfecto de \\(f\\) y esto introducir√° un error el cu√°l puede reducirse. Ejemplos: Introducir una estructura lineal cu√°ndo el problema tiene estructura cuadr√°tica, falta de variables explicativas, exceso de variables que no contribuyen a la predicci√≥n.\nError ireducible: La variable \\(Y\\) es una funci√≥n tambi√©n de \\(\\epsilon\\) y por definici√≥n nuestra predicci√≥n tendra un error inherente. Ejemplos: Predecir que comer√°n ma√±ana, determinar si llover√° o no, determinar cu√°ndo ocurrir√° un temblor, ¬øqui√©n ganar√° una elecci√≥n?.\n\n\\[ \\begin{align*}\n\\mathbb{E}[(Y-\\hat{Y})^2] &= \\mathbb{E}[(f(X) + \\epsilon -\\hat{f}(x))^2]\\\\\n&= \\underset{Reducible}{\\underbrace{\\mathbb{E}[(f(X) - \\hat{f}(x))^2]}} + \\underset{Irreducible}{\\underbrace{\\text{Var}(\\epsilon)}}\n\\end{align*}\\]\nEl objetivo del curso se enfoca en t√©cnicas para estimar \\(f\\) con el objectivo de minimizar el error reducible. Es importante tener en cuenta que el error irreducible siempre nos pondr√° una cota en la predicci√≥n de \\(Y\\).\n\n\n2.1.2 Inferencia\nExisten problemas en donde nos interesa m√°s entender la relaci√≥n intrinseca que existe entre \\(Y\\) y \\(X\\). En esta situaci√≥n nuestro objetivo no es hacer predicci√≥n, entonces \\(\\hat{f}\\) ya no puede ser tratada como una caja negra. En este tipo de enfoque se contestan preguntas c√≥mo:\n\n¬øCu√°les son los predictores que se asocian con la variable \\(Y\\)?: Muchas veces solo un subconjunto de los datos \\(X\\) son los que realmente est√°n relacionados con \\(Y\\).\n¬øCu√°l es la relaci√≥n entre \\(Y\\) y \\(X_i\\)?\n¬øLa relaci√≥n entre \\(Y\\) y \\(X_i\\) es lineal o m√°s compleja?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "02-principios.html#c√≥mo-estimar-f",
    "href": "02-principios.html#c√≥mo-estimar-f",
    "title": "2¬† Principios de aprendizaje supervisado",
    "section": "2.2 ¬øC√≥mo estimar \\(f\\)?",
    "text": "2.2 ¬øC√≥mo estimar \\(f\\)?\nAsumiremos que tenemos \\(n\\) datos diferentes estas observaciones ser√°n llamadas conjunto de entrenamiento. \\(x_{ij}\\) representa el valor del predictor \\(j\\) para la observaci√≥n \\(i\\), donde \\(i=1,2,...,n\\) y \\(j=1,2,...,p\\). \\(y_i\\) representa la variable respuesta de la observaci√≥n \\(i\\). Entonces nuestro conjunto de entrenamiento consiste en:\n\\[{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)}\\]\ndonde \\(x_i=(x_{i1}, x_{i2}, ..., x_{ip})^T\\).\nNuestro objetivo es aplicar un m√©todo de aprendizaje en el conjunto de datos para poder estimar una funci√≥n desconocida de \\(f\\). Nos encantar√≠a encontrar una funci√≥n \\(\\hat{f}\\) de forma tal que \\(Y\\simeq \\hat{f}(X)\\) para cualquier observaci√≥n \\((X, Y)\\). Muchos de estos enfoque se pueden caracterizar como m√©todos param√©tricos o no param√©tricos.\n\n2.2.1 M√©todos param√©tricos\nLos m√©todos param√©tricos involucran un enfoque de dos pasos:\n\nHacemos un supuesto de la forma funci√≥n de \\(f\\). Por ejemplo, la m√°s sencilla es que \\(f\\) es linear en \\(\\beta\\):\n\n\\[ f(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]\nUna vez haciendo haciendo el supuesto de linealidad el problema de estimar \\(f\\) es simplificado ya que en lugar de explorar el espacio funcional uno solo necesita estimar \\(p+1\\) coeficientes \\(\\beta_0, ..., \\beta_p\\).\n\nNecesitamos un proceso que utilice los datos de entrenamiento para ajustar u entrenar el modelo. El enfoque m√°s sencillo es el m√©todo de m√≠nimos cuadrados ordinarios (OLS):\n\n\\[\\underset{\\beta_0, \\beta_1, ..., \\beta_p}{min} \\sum_{i=1}^{N}(y_i - (\\beta_0 + \\beta_1 x_{i1} +\\beta_2 x_{i2} + ... + \\beta_p X_p))^2\\]\nEl enfoque basado en modelado se refiere a los modelos param√©tricos; reduce el problema de estimar \\(f\\) a estimar un conjunto de par√°metros. La desventaja potencial es que el modelo podr√≠a no ser igual a la verdadera \\(f\\) y tendremos malas estimaciones del valor de \\(y\\).\n\n\n2.2.2 M√©todos no param√©tricos",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html",
    "href": "03-regresion_lineal.html",
    "title": "3¬† Regresi√≥n lineal",
    "section": "",
    "text": "3.1 Regresi√≥n Lineal Simple\nComenzaremos con el caso m√°s sencillo: predecir una variable de resultado Y a partir de una √∫nica variable predictora X.\nEl modelo matem√°tico que queremos ajustar es una l√≠nea recta:\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\nDonde:\nNuestro objetivo üéØ es encontrar los mejores valores posibles para los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) usando los datos que tenemos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#regresi√≥n-lineal-simple",
    "href": "03-regresion_lineal.html#regresi√≥n-lineal-simple",
    "title": "3¬† Regresi√≥n lineal",
    "section": "",
    "text": "\\(Y\\): La variable dependiente (lo que queremos predecir).\n\\(X\\): La variable independiente (nuestro predictor).\n\\(\\beta_0\\): El intercepto (el valor de \\(Y\\) cuando \\(X=0\\)).\n\\(\\beta_1\\): La pendiente (cu√°nto cambia \\(Y\\) por cada unidad que aumenta \\(X\\)).\n\\(\\epsilon\\): El t√©rmino de error (la parte de \\(Y\\) que nuestro modelo no puede explicar).\n\n\n\n3.1.1 ¬øC√≥mo estimamos los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\)?\n‚ÄúMejor‚Äù para nosotros significa encontrar la l√≠nea que minimice la distancia vertical entre cada punto de dato y la propia l√≠nea. Espec√≠ficamente, minimizamos la Suma de los Errores al Cuadrado (SEC o Sum of Squared Errors, SSE).\nLa funci√≥n de costo (o p√©rdida) que queremos minimizar es:\n\\[J(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))^2\\]\nTenemos dos m√©todos principales para encontrar los \\(\\beta\\) que minimizan esta funci√≥n:\n\n3.1.1.1 M√©todo 1: Las Ecuaciones Normales (La soluci√≥n anal√≠tica üß†)\nEste m√©todo utiliza c√°lculo para encontrar el m√≠nimo exacto de la funci√≥n de costo. Para ello, tomamos las derivadas parciales de \\(J\\) con respecto a \\(\\beta_0\\) y \\(\\beta_1\\), las igualamos a cero y resolvemos para los coeficientes.\n\n\n\n\n\n\nDerivada parcial con respecto a \\(\\beta_0\\):\n\n\n\n\n\n\\[\\frac{\\partial J}{\\partial \\beta_0} = \\sum_{i=1}^{n} -2(y_i - \\beta_0 - \\beta_1 x_i) = 0\\] \\[\\sum y_i - n\\beta_0 - \\beta_1 \\sum x_i = 0\\] \\[\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\]\n\n\n\n\n\n\n\n\n\nDerivada parcial con respecto a \\(\\beta_1\\)\n\n\n\n\n\n\\[\\frac{\\partial J}{\\partial \\beta_1} = \\sum_{i=1}^{n} -2x_i(y_i - \\beta_0 - \\beta_1 x_i) = 0\\] Sustituyendo \\(\\beta_0\\) de la primera ecuaci√≥n y resolviendo, llegamos a: \\[\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\n\n\n\nEstas f√≥rmulas nos dan los valores √≥ptimos y exactos de los coeficientes directamente a partir de los datos.\n\n\n3.1.1.2 M√©todo 2: Descenso en Gradiente (La soluci√≥n iterativa ‚öôÔ∏è)\nEste es un m√©todo computacional que nos ‚Äúacerca‚Äù progresivamente a la soluci√≥n. Es especialmente √∫til cuando tenemos una cantidad masiva de datos y calcular la soluci√≥n anal√≠tica es muy costoso.\nLa intuici√≥n: Imagina que est√°s en una monta√±a (la funci√≥n de costo) y quieres llegar al valle (el costo m√≠nimo). El Descenso en Gradiente te dice que mires a tu alrededor y des un paso en la direcci√≥n m√°s inclinada hacia abajo. Repites esto hasta llegar al fondo.\nEl algoritmo funciona as√≠:\n\nInicializa los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) con valores aleatorios (o en ceros).\nCalcula el gradiente de la funci√≥n de costo. El gradiente es un vector que apunta en la direcci√≥n del m√°ximo ascenso. Nosotros iremos en la direcci√≥n opuesta.\n\n\\(\\frac{\\partial J}{\\partial \\beta_0} = -2 \\sum (y_i - (\\beta_0 + \\beta_1 x_i))\\)\n\\(\\frac{\\partial J}{\\partial \\beta_1} = -2 \\sum x_i(y_i - (\\beta_0 + \\beta_1 x_i))\\)\n\nActualiza los coeficientes usando una tasa de aprendizaje (\\(\\alpha\\)), que controla el tama√±o del paso que damos.\n\n\\(\\beta_0 := \\beta_0 - \\alpha \\frac{\\partial J}{\\partial \\beta_0}\\)\n\\(\\beta_1 := \\beta_1 - \\alpha \\frac{\\partial J}{\\partial \\beta_1}\\)\n\nRepite los pasos 2 y 3 durante un n√∫mero determinado de iteraciones o hasta que el cambio en el costo sea muy peque√±o (convergencia).\n\n\n\n\n\n\n\nExplicacion visual",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#cu√°les-son-los-supuestos-de-la-regresi√≥n",
    "href": "03-regresion_lineal.html#cu√°les-son-los-supuestos-de-la-regresi√≥n",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.2 ¬øCu√°les son los supuestos de la regresi√≥n? üßê",
    "text": "3.2 ¬øCu√°les son los supuestos de la regresi√≥n? üßê\nPara que nuestro modelo sea confiable (es decir, para que los coeficientes y las predicciones tengan sentido), debemos cumplir con ciertos supuestos.\n\nLinealidad: La relaci√≥n entre \\(\\beta\\) y \\(Y\\) debe ser lineal.\n\n¬øPara qu√© sirve? Si la relaci√≥n no es lineal, nuestro modelo de l√≠nea recta ser√° intr√≠nsecamente incorrecto.\n\nIndependencia de los errores: Los errores (residuos) no deben estar correlacionados entre s√≠.\n\n¬øPara qu√© sirve? Es crucial para datos de series temporales. Si los errores est√°n correlacionados, la informaci√≥n de un error nos da pistas sobre el siguiente, lo cual viola la idea de que cada observaci√≥n es independiente.\n\nHomocedasticidad (Varianza constante de los errores): La varianza de los errores debe ser constante para todos los niveles de \\(X\\).\n\n¬øPara qu√© sirve? Si la varianza cambia (heterocedasticidad), nuestras predicciones ser√°n mejores para algunas partes de los datos que para otras, y los intervalos de confianza para los coeficientes ser√°n poco fiables. Visualmente, en un gr√°fico de residuos vs.¬†valores predichos, no queremos ver una forma de cono o embudo.\n\nNormalidad de los errores: Los errores deben seguir una distribuci√≥n normal con media cero.\n\n¬øPara qu√© sirve? Este supuesto es fundamental para poder realizar pruebas de hip√≥tesis sobre los coeficientes (como los p-values) y construir intervalos de confianza. Podemos verificarlo con un histograma de los residuos o un gr√°fico Q-Q.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#c√≥mo-evaluar-la-precisi√≥n-del-modelo",
    "href": "03-regresion_lineal.html#c√≥mo-evaluar-la-precisi√≥n-del-modelo",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.3 ¬øC√≥mo evaluar la precisi√≥n del modelo? üìà",
    "text": "3.3 ¬øC√≥mo evaluar la precisi√≥n del modelo? üìà\nUna vez que hemos ajustado el modelo, ¬øc√≥mo sabemos si es bueno?\n\n3.3.1 Coeficiente de Determinaci√≥n (\\(R^2\\))\nEl \\(R^2\\) mide la proporci√≥n de la varianza total en la variable dependiente (\\(Y\\)) que es explicada por nuestro modelo.\n\\[R^2 = 1 - \\frac{\\text{Suma de Errores al Cuadrado (SEC)}}{\\text{Suma Total de Cuadrados (STC)}} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\\]\n\n\\(R^2\\) var√≠a entre 0 y 1 (o 0% y 100%).\nUn \\(R^2\\) de 0.85 significa que el 85% de la variabilidad en \\(Y\\) puede ser explicada por \\(X\\).\nUn \\(R^2\\) m√°s alto generalmente indica un mejor ajuste del modelo.\n\n\n\n3.3.2 p-values (Valores p)\nEl p-value nos ayuda a determinar si nuestra variable predictora \\(X\\) es estad√≠sticamente significativa. Responde a la pregunta: ¬øEs probable que la relaci√≥n que observamos entre \\(X\\) y \\(Y\\) haya ocurrido por puro azar?\n\nHip√≥tesis Nula (\\(H_0\\)): No hay relaci√≥n entre \\(X\\) y \\(Y\\) (es decir, \\(\\beta_1 = 0\\)).\nHip√≥tesis Alternativa (\\(H_a\\)): S√≠ hay una relaci√≥n entre \\(X\\) y \\(Y\\) (es decir, \\(\\beta_1 \\neq 0\\)).\n\nUn p-value peque√±o (t√≠picamente &lt; 0.05) nos da evidencia para rechazar la hip√≥tesis nula. Esto sugiere que nuestra variable \\(X\\) es un predictor √∫til para \\(Y\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#m√©tricas-de-error-de-predicci√≥n",
    "href": "03-regresion_lineal.html#m√©tricas-de-error-de-predicci√≥n",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.4 M√©tricas de Error de Predicci√≥n",
    "text": "3.4 M√©tricas de Error de Predicci√≥n\nAdem√°s del \\(R^2\\), existen m√∫ltiples m√©tricas para evaluar qu√© tan bien predice nuestro modelo. Cada una tiene sus ventajas y casos de uso espec√≠ficos:\n\n3.4.1 Error Cuadr√°tico Medio (MSE)\nEl MSE mide el promedio de los errores al cuadrado:\n\\[MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\]\n\nVentajas: Penaliza fuertemente errores grandes, diferenciable (√∫til para optimizaci√≥n)\nDesventajas: Sensible a valores at√≠picos, dif√≠cil de interpretar (unidades al cuadrado)\nCu√°ndo usar: Cuando errores grandes son especialmente costosos\n\n\n\n3.4.2 Ra√≠z del Error Cuadr√°tico Medio (RMSE)\nEl RMSE es la ra√≠z cuadrada del MSE:\n\\[RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\\]\n\nVentajas: Mismas unidades que la variable objetivo, interpretable\nDesventajas: A√∫n sensible a valores at√≠picos\nInterpretaci√≥n: ‚ÄúEn promedio, nuestras predicciones se desv√≠an X unidades del valor real‚Äù\n\n\n\n3.4.3 Error Absoluto Medio (MAE)\nEl MAE mide el promedio de los errores absolutos:\n\\[MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\\]\n\nVentajas: Robusto a valores at√≠picos, f√°cil de interpretar\nDesventajas: No diferenciable en cero, trata todos los errores por igual\nCu√°ndo usar: Cuando hay valores at√≠picos o todos los errores tienen igual importancia\n\n\n\n3.4.4 Error Porcentual Absoluto Medio (MAPE)\nEl MAPE expresa el error como porcentaje del valor real:\n\\[MAPE = \\frac{100}{n} \\sum_{i=1}^{n} \\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right|\\]\n\nVentajas: Interpretable (% de error), adimensional, √∫til para comparar modelos en diferentes escalas\nDesventajas: Indefinido cuando \\(y_i = 0\\), asim√©trico (penaliza m√°s las sobreestimaciones)\nInterpretaci√≥n: ‚ÄúNuestras predicciones se desv√≠an en promedio X% del valor real‚Äù\nCu√°ndo usar: Para comparar precisi√≥n entre diferentes productos, regiones, o escalas\n\n\n\n3.4.5 Error Porcentual Absoluto Medio Sim√©trico (SMAPE)\nEl SMAPE es una versi√≥n sim√©trica del MAPE:\n\\[SMAPE = \\frac{100}{n} \\sum_{i=1}^{n} \\frac{|y_i - \\hat{y}_i|}{(|y_i| + |\\hat{y}_i|)/2}\\]\n\nVentajas: Sim√©trico, acotado entre 0% y 200%\nDesventajas: Puede ser contraintuitivo, no tan est√°ndar como MAPE\nCu√°ndo usar: Cuando queremos evitar el sesgo del MAPE hacia sobreestimaciones\n\n\n\n3.4.6 Error Logar√≠tmico Cuadr√°tico Medio (MSLE)\nEl MSLE usa transformaci√≥n logar√≠tmica:\n\\[MSLE = \\frac{1}{n} \\sum_{i=1}^{n} (\\log(1 + y_i) - \\log(1 + \\hat{y}_i))^2\\]\n\nVentajas: Penaliza m√°s las subestimaciones que las sobreestimaciones\nDesventajas: Solo para valores positivos, menos interpretable\nCu√°ndo usar: Cuando subestimar es m√°s costoso que sobreestimar (ej: demanda de inventario)\n\n\n\n3.4.7 \\(R^2\\) Ajustado\nEl \\(R^2\\) ajustado penaliza por el n√∫mero de variables en el modelo:\n\\[R^2_{adj} = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}\\]\nDonde \\(p\\) es el n√∫mero de predictores.\n\nVentajas: No aumenta autom√°ticamente al a√±adir variables\nCu√°ndo usar: Para comparar modelos con diferente n√∫mero de variables\nInterpretaci√≥n: Similar a \\(R^2\\) pero m√°s conservador\n\n\n3.4.7.1 ¬øCu√°l m√©trica elegir?\nLa elecci√≥n de m√©trica depende del contexto del problema:\n\n\n\n\n\n\n\n\nM√©trica\nMejor para\nEvitar cuando\n\n\n\n\nRMSE\nErrores grandes son costosos\nHay muchos valores at√≠picos\n\n\nMAE\nErrores tienen igual importancia\nNecesitas diferenciabilidad\n\n\nMAPE\nComparar diferentes escalas\nHay valores cercanos a cero\n\n\nSMAPE\nComparar con simetr√≠a\nInterpretaci√≥n debe ser simple\n\n\nR¬≤\nExplicar variabilidad\nSolo importa precisi√≥n de predicci√≥n\n\n\n\n\n\n\n\n\n\nRecomendaci√≥n pr√°ctica\n\n\n\nUsa m√∫ltiples m√©tricas para evaluar tu modelo. Una combinaci√≥n t√≠pica ser√≠a: - RMSE para precisi√≥n general - MAPE para interpretabilidad de negocio\n- R¬≤ para explicaci√≥n de variabilidad",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#regresi√≥n-lineal-m√∫ltiple",
    "href": "03-regresion_lineal.html#regresi√≥n-lineal-m√∫ltiple",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.5 Regresi√≥n Lineal M√∫ltiple",
    "text": "3.5 Regresi√≥n Lineal M√∫ltiple\nAhora, ¬øqu√© pasa si tenemos m√∫ltiples predictores (\\(X_1, X_2, ..., X_p\\))? El modelo se expande:\n\\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\epsilon\\]\nLa intuici√≥n es la misma, pero en lugar de ajustar una l√≠nea, estamos ajustando un hiperplano en un espacio multidimensional.\nPara manejar esto de forma elegante, usamos notaci√≥n matricial:\n\\[\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\]\nDonde: - \\(\\mathbf{y}\\) es el vector de observaciones. - \\(\\mathbf{X}\\) es la matriz de dise√±o (con una primera columna de unos para el intercepto). - \\(\\boldsymbol{\\beta}\\) es el vector de coeficientes. - \\(\\boldsymbol{\\epsilon}\\) es el vector de errores.\nLa funci√≥n de costo en forma matricial es: \\[J(\\boldsymbol{\\beta}) = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#transformaciones-comunes-en-modelos-lineales",
    "href": "03-regresion_lineal.html#transformaciones-comunes-en-modelos-lineales",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.6 Transformaciones Comunes en Modelos Lineales",
    "text": "3.6 Transformaciones Comunes en Modelos Lineales\nA veces, la relaci√≥n entre X e Y no es estrictamente lineal. Las transformaciones logar√≠tmicas nos permiten modelar relaciones no lineales y, adem√°s, ofrecen interpretaciones muy √∫tiles en t√©rminos de cambios porcentuales.\n\n3.6.1 Modelo Log-Nivel (Transformaci√≥n en Y)\nEste modelo se usa cuando el efecto de X sobre Y no es absoluto, sino porcentual. Por ejemplo, c√≥mo un a√±o m√°s de educaci√≥n afecta el porcentaje de aumento salarial.\n\nEcuaci√≥n: \\(\\ln(Y) = \\beta_0 + \\beta_1 X + \\epsilon\\)\nInterpretaci√≥n: Un incremento de una unidad en \\(X\\) est√° asociado con un cambio de \\((100 \\cdot \\beta_1)\\%\\) en \\(Y\\).\n\n\n\n\n\n\n\nExplicaci√≥n Matem√°tica de la Aproximaci√≥n\n\n\n\n\n\nLa clave est√° en la propiedad del logaritmo y el c√°lculo. La derivada de \\(\\ln(Y)\\) con respecto a \\(X\\) es \\(\\beta_1\\): \\[\\frac{d(\\ln(Y))}{dX} = \\beta_1\\] Sabemos que \\(d(\\ln(Y)) = \\frac{dY}{Y}\\). Por tanto: \\[\\frac{dY/Y}{dX} = \\beta_1\\] Para cambios peque√±os (o discretos, \\(\\Delta\\)), podemos aproximar los diferenciales: \\[\\beta_1 \\approx \\frac{\\Delta Y / Y}{\\Delta X}\\] Si consideramos un cambio unitario en X, \\(\\Delta X = 1\\), entonces: \\[\\beta_1 \\approx \\frac{\\Delta Y}{Y}\\] Esto significa que \\(\\beta_1\\) es la aproximaci√≥n del cambio porcentual en \\(Y\\) ante un cambio de una unidad en \\(X\\).\n\n\n\n\n\n3.6.2 Modelo Nivel-Log (Transformaci√≥n en X)\nEste modelo es √∫til cuando el efecto de X sobre Y se reduce a medida que X aumenta (rendimientos decrecientes). Por ejemplo, el efecto de a√±adir presupuesto de marketing sobre las ventas.\n\nEcuaci√≥n: \\(Y = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\\)\nInterpretaci√≥n: Un incremento del 1% en \\(X\\) est√° asociado con un cambio de \\((\\beta_1 / 100)\\) unidades en \\(Y\\).\n\n\n\n\n\n\n\nExplicaci√≥n Matem√°tica de la Aproximaci√≥n\n\n\n\n\n\nTomamos la derivada de \\(Y\\) con respecto a \\(\\ln(X)\\): \\[\\frac{dY}{d(\\ln(X))} = \\beta_1\\] Usando la regla de la cadena, sabemos que \\(d(\\ln(X)) = \\frac{dX}{X}\\). Sustituyendo: \\[\\frac{dY}{dX/X} = \\beta_1 \\implies dY = \\beta_1 \\frac{dX}{X}\\] Para cambios discretos, aproximamos: \\[\\Delta Y \\approx \\beta_1 \\frac{\\Delta X}{X}\\] Si consideramos un cambio del 1% en X, entonces \\(\\frac{\\Delta X}{X} = 0.01\\). La ecuaci√≥n se convierte en: \\[\\Delta Y \\approx \\beta_1 (0.01) = \\frac{\\beta_1}{100}\\] Esto significa que un cambio del 1% en \\(X\\) provoca un cambio de \\(\\beta_1/100\\) unidades en \\(Y\\).\n\n\n\n\n\n3.6.3 Modelo Log-Log (Transformaci√≥n en X e Y)\nEste modelo es muy com√∫n en econom√≠a y modela la elasticidad constante entre dos variables.\n\nEcuaci√≥n: \\(\\ln(Y) = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\\)\nInterpretaci√≥n: Un incremento del 1% en \\(X\\) est√° asociado con un cambio del \\(\\beta_1\\%\\) en \\(Y\\).\n\n\n\n\n\n\n\nExplicaci√≥n Matem√°tica de la Aproximaci√≥n\n\n\n\n\n\nEste caso combina los dos anteriores. \\(\\beta_1\\) es la derivada de \\(\\ln(Y)\\) con respecto a \\(\\ln(X)\\), que es la definici√≥n de elasticidad. \\[\\beta_1 = \\frac{d(\\ln(Y))}{d(\\ln(X))}\\] Usando las propiedades del c√°lculo que vimos antes: \\[\\beta_1 = \\frac{dY/Y}{dX/X}\\] Aproximando para cambios discretos: \\[\\beta_1 \\approx \\frac{\\Delta Y / Y}{\\Delta X / X}\\] Esta es la definici√≥n de elasticidad: el cambio porcentual en \\(Y\\) dividido por el cambio porcentual en \\(X\\). Por lo tanto, si \\(X\\) cambia en un 1% (\\(\\Delta X / X = 0.01\\)), el cambio porcentual en \\(Y\\) (\\(\\Delta Y / Y\\)) ser√° aproximadamente \\(\\beta_1 \\times 0.01\\), es decir, un \\(\\beta_1\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#regresi√≥n-regularizada-penalizada",
    "href": "03-regresion_lineal.html#regresi√≥n-regularizada-penalizada",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.7 Regresi√≥n Regularizada (Penalizada) üéØ",
    "text": "3.7 Regresi√≥n Regularizada (Penalizada) üéØ\nHasta ahora hemos visto la regresi√≥n lineal cl√°sica, pero ¬øqu√© pasa cuando tenemos muchas variables o cuando nuestro modelo sufre de sobreajuste? Aqu√≠ es donde entran las t√©cnicas de regularizaci√≥n.\n\n3.7.1 ¬øPor qu√© necesitamos regularizaci√≥n?\nLa regresi√≥n lineal ordinaria (OLS) puede presentar varios problemas:\n\nSobreajuste: Cuando tenemos muchas variables relativas al n√∫mero de observaciones\nMulticolinealidad: Variables predictoras altamente correlacionadas\nInestabilidad: Peque√±os cambios en los datos causan grandes cambios en los coeficientes\nInterpretabilidad: Demasiadas variables hacen dif√≠cil entender el modelo\n\nLa regularizaci√≥n a√±ade una penalizaci√≥n a la funci√≥n de costo para controlar la complejidad del modelo.\n\n\n\n3.7.2 Ridge Regression (Regresi√≥n Ridge) üèîÔ∏è\nLa regresi√≥n Ridge a√±ade una penalizaci√≥n L2 (suma de cuadrados) a los coeficientes:\n\\[J_{Ridge}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\\]\nDonde: - \\(\\lambda &gt; 0\\) es el par√°metro de regularizaci√≥n - \\(\\sum_{j=1}^{p} \\beta_j^2\\) es la penalizaci√≥n L2\n\n3.7.2.1 Caracter√≠sticas de Ridge:\n‚úÖ Ventajas: - Reduce el sobreajuste - Maneja bien la multicolinealidad - Siempre tiene soluci√≥n √∫nica - Estabiliza los coeficientes\n‚ùå Desventajas: - NO elimina variables (coeficientes nunca son exactamente cero) - Dificulta la interpretabilidad - Requiere estandarizar las variables\n\n\n3.7.2.2 Soluci√≥n Anal√≠tica:\n\\[\\hat{\\boldsymbol{\\beta}}_{Ridge} = (\\mathbf{X}^T\\mathbf{X} + \\lambda\\mathbf{I})^{-1}\\mathbf{X}^T\\mathbf{y}\\]\nEl t√©rmino \\(\\lambda\\mathbf{I}\\) hace que la matriz sea invertible incluso con multicolinealidad.\n\n\n3.7.2.3 ¬øC√≥mo elegir Œª?\n\nŒª = 0: Regresi√≥n ordinaria (sin penalizaci√≥n)\nŒª ‚Üí ‚àû: Todos los coeficientes ‚Üí 0\nŒª √≥ptimo: Se encuentra usando validaci√≥n cruzada\n\n\n\n\n\n3.7.3 Lasso Regression (Least Absolute Shrinkage and Selection Operator) ‚úÇÔ∏è\nLa regresi√≥n Lasso usa penalizaci√≥n L1 (suma de valores absolutos):\n\\[J_{Lasso}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|\\]\n\n3.7.3.1 Caracter√≠sticas de Lasso:\n‚úÖ Ventajas: - Selecci√≥n autom√°tica de variables (coeficientes = 0) - Modelos m√°s interpretables y simples - √ötil cuando muchas variables son irrelevantes\n‚ùå Desventajas: - Puede ser inestable con grupos de variables correlacionadas - Selecciona arbitrariamente entre variables correlacionadas - No tiene soluci√≥n anal√≠tica cerrada\n\n\n3.7.3.2 La ‚ÄúMagia‚Äù de L1: ¬øPor qu√© produce ceros exactos?\nLa penalizaci√≥n L1 crea una regi√≥n factible con esquinas puntiagudas. La soluci√≥n √≥ptima tiende a ocurrir en estas esquinas, donde algunos coeficientes son exactamente cero.\n\n\n\n\n\n\nIntuici√≥n Geom√©trica\n\n\n\n\n\nImagina que est√°s minimizando una funci√≥n bajo la restricci√≥n de que \\(|\\beta_1| + |\\beta_2| \\leq t\\). Esta restricci√≥n forma un diamante en 2D. La funci√≥n objetivo forma elipses. La soluci√≥n est√° donde la elipse m√°s peque√±a toca el diamante, y esto frecuentemente ocurre en los v√©rtices (donde \\(\\beta_1 = 0\\) o \\(\\beta_2 = 0\\)).\n\n\n\n\n\n\n\n3.7.4 Elastic Net: Lo Mejor de Ambos Mundos üï∏Ô∏è\nElastic Net combina las penalizaciones L1 y L2:\n\\[J_{ElasticNet}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda_1 \\sum_{j=1}^{p} |\\beta_j| + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2\\]\nO equivalentemente, con un par√°metro de mezcla \\(\\alpha\\):\n\\[J_{ElasticNet}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T\\boldsymbol{\\beta})^2 + \\lambda \\left[ \\alpha \\sum_{j=1}^{p} |\\beta_j| + (1-\\alpha) \\sum_{j=1}^{p} \\beta_j^2 \\right]\\]\nDonde: - \\(\\alpha \\in [0,1]\\) controla la mezcla entre L1 y L2 - \\(\\alpha = 0\\): Pure Ridge - \\(\\alpha = 1\\): Pure Lasso - \\(\\alpha = 0.5\\): Igual peso a ambas penalizaciones\n\n3.7.4.1 Caracter√≠sticas de Elastic Net:\n‚úÖ Ventajas: - Selecci√≥n de variables como Lasso - Estabilidad como Ridge - Maneja bien grupos de variables correlacionadas - M√°s flexible que Ridge o Lasso por separado\n‚ùå Desventajas: - Dos hiperpar√°metros para ajustar (\\(\\lambda\\) y \\(\\alpha\\)) - M√°s complejo computacionalmente\n\n\n\n\n3.7.5 Comparaci√≥n Visual: Ridge vs Lasso vs Elastic Net\n\n\n\n\n\n\n\n\n\nAspecto\nRidge\nLasso\nElastic Net\n\n\n\n\nPenalizaci√≥n\nL2: \\(\\sum \\beta_j^2\\)\nL1: \\(\\sum |\\beta_j|\\)\nL1 + L2 combinadas\n\n\nSelecci√≥n de variables\n‚ùå No\n‚úÖ S√≠\n‚úÖ S√≠\n\n\nCoeficientes exactamente cero\n‚ùå No\n‚úÖ S√≠\n‚úÖ S√≠\n\n\nManejo de multicolinealidad\n‚úÖ Excelente\n‚ö†Ô∏è Problem√°tico\n‚úÖ Muy bueno\n\n\nEstabilidad\n‚úÖ Alta\n‚ö†Ô∏è Media\n‚úÖ Alta\n\n\nInterpretabilidad\n‚ö†Ô∏è Media\n‚úÖ Alta\n‚úÖ Alta\n\n\nCuando usar\nTodas las variables importan\nPocas variables importantes\nSituaciones mixtas\n\n\n\n\n\n3.7.6 ¬øCu√°ndo usar cada m√©todo?\n\n3.7.6.1 Usa Ridge cuando:\n\nCrees que todas las variables contribuyen al modelo\nTienes multicolinealidad severa\nQuieres estabilizar coeficientes sin eliminar variables\nEl n√∫mero de observaciones es peque√±o relativo a variables\n\n\n\n3.7.6.2 Usa Lasso cuando:\n\nCrees que pocas variables son realmente importantes\nQuieres un modelo simple e interpretable\nNecesitas selecci√≥n autom√°tica de variables\nTienes muchas variables irrelevantes\n\n\n\n3.7.6.3 Usa Elastic Net cuando:\n\nNo est√°s seguro de cu√°ntas variables son importantes\nTienes grupos de variables correlacionadas\nQuieres balancear selecci√≥n y estabilidad\nEs tu primera opci√≥n cuando no conoces la estructura de los datos\n\n\n\n\n\n3.7.7 Validaci√≥n de Modelos y Selecci√≥n de Hiperpar√°metros\n\n3.7.7.1 ¬øPor qu√© necesitamos dividir nuestros datos?\nCuando construimos modelos de machine learning, enfrentamos un dilema fundamental: ¬øc√≥mo sabemos si nuestro modelo funcionar√° bien con datos nuevos?\n\n3.7.7.1.1 El Problema del Sobreajuste\nImagina que est√°s prepar√°ndote para un examen. Si solo estudias las preguntas exactas que aparecer√°n en el examen, podr√≠as obtener una calificaci√≥n perfecta. Pero si las preguntas cambian ligeramente, tu rendimiento se desplomar√≠a. Esto es sobreajuste: el modelo memoriza los datos de entrenamiento pero no generaliza.\n\n\n\n3.7.7.2 Divisi√≥n T√≠pica de Datos: Entrenamiento/Validaci√≥n/Prueba\nLa estrategia est√°ndar es dividir nuestros datos en tres conjuntos:\nüìä Dataset Completo (100%)\n‚îú‚îÄ‚îÄ üèãÔ∏è Entrenamiento (60%) - Para ajustar coeficientes\n‚îú‚îÄ‚îÄ üéØ Validaci√≥n (20%)     - Para seleccionar hiperpar√°metros  \n‚îî‚îÄ‚îÄ üß™ Prueba (20%)         - Para evaluaci√≥n final\n\n3.7.7.2.1 Conjunto de Entrenamiento (60%)\n\nProp√≥sito: Ajustar los coeficientes \\(\\beta\\) del modelo\nAnalog√≠a: Los ejercicios que haces para aprender\n\n\n\n3.7.7.2.2 Conjunto de Validaci√≥n (20%)\n\nProp√≥sito: Comparar diferentes hiperpar√°metros (como \\(\\lambda\\) en Ridge/Lasso)\nAnalog√≠a: Ex√°menes de pr√°ctica para decidir qu√© estrategia de estudio funciona mejor\n\n\n\n3.7.7.2.3 Conjunto de Prueba (20%)\n\nProp√≥sito: Evaluaci√≥n final y honesta del modelo\nAnalog√≠a: El examen final real\n‚ö†Ô∏è Regla de Oro: ¬°Solo se usa UNA vez al final!\n\n\n\n\n3.7.7.3 ¬øQu√© pasa si tenemos pocos datos?\nCuando nuestro dataset es peque√±o (&lt; 1000 observaciones), dividir en tres partes puede ser problem√°tico:\n‚ùå Problemas con datasets peque√±os: - Conjunto de entrenamiento muy peque√±o ‚Üí modelo pobre - Conjunto de validaci√≥n peque√±o ‚Üí selecci√≥n inestable de hiperpar√°metros - Conjunto de prueba peque√±o ‚Üí evaluaci√≥n poco confiable\nSoluci√≥n: ¬°Validaci√≥n Cruzada!\n\n\n\n3.7.7.4 Validaci√≥n Cruzada (Cross-Validation)\nLa validaci√≥n cruzada es una t√©cnica que maximiza el uso de nuestros datos limitados. En lugar de usar una sola divisi√≥n, usamos m√∫ltiples divisiones.\n\n3.7.7.4.1 Validaci√≥n Cruzada k-fold\nEl m√©todo m√°s com√∫n es k-fold cross-validation:\n\nDividir el dataset en \\(k\\) ‚Äúpliegues‚Äù (folds) de igual tama√±o\nRepetir \\(k\\) veces:\n\nUsar \\(k-1\\) pliegues para entrenamiento\nUsar 1 pliegue para validaci√≥n\n\nPromediar los resultados de las \\(k\\) evaluaciones\n\n\n\n\n\n\nVisualizaci√≥n de 5-Fold Cross Validation mostrando c√≥mo se dividen los datos en cada iteraci√≥n\n\n\n\n\n\n\n3.7.7.4.2 Ventajas de la Validaci√≥n Cruzada\n‚úÖ Maximiza el uso de datos: Cada observaci√≥n se usa tanto para entrenamiento como validaci√≥n\n‚úÖ Estimaci√≥n m√°s robusta: Promedia m√∫ltiples evaluaciones independientes\n‚úÖ Reduce la varianza: Menos dependiente de una divisi√≥n particular\n‚úÖ Detecta inestabilidad: Si los resultados var√≠an mucho entre folds, el modelo es inestable\n\n\n\n3.7.7.5 Validaci√≥n Cruzada para Selecci√≥n de Hiperpar√°metros\nEn regresi√≥n regularizada, usamos CV para encontrar el mejor \\(\\lambda\\):\n\n\nüéØ SELECCI√ìN DE HIPERPAR√ÅMETROS CON VALIDACI√ìN CRUZADA\n============================================================\nPara cada valor de Œª:\n  1. Aplicar 5-fold CV\n  2. Calcular error promedio\n  3. Seleccionar Œª con menor error\n\n\n\n\n\nCurva de validaci√≥n mostrando c√≥mo seleccionar el hiperpar√°metro √≥ptimo Œª usando validaci√≥n cruzada\n\n\n\n\n\nüìà Resultado: Œª √≥ptimo = 0.1274\nüìâ Error de CV m√≠nimo = 0.4776\n\n\n\n\n3.7.7.6 Proceso Completo de Validaci√≥n\nEl flujo completo para modelos regularizados es:\n1. üìä Dividir datos originales\n   ‚îî‚îÄ‚îÄ 80% para desarrollo (entrenamiento + validaci√≥n)\n   ‚îî‚îÄ‚îÄ 20% para prueba final (¬°NO TOCAR hasta el final!)\n\n2. üîÑ En el conjunto de desarrollo:\n   ‚îî‚îÄ‚îÄ Para cada Œª candidato:\n       ‚îú‚îÄ‚îÄ Aplicar k-fold CV\n       ‚îú‚îÄ‚îÄ Calcular error promedio\n       ‚îî‚îÄ‚îÄ Guardar resultado\n\n3. üéØ Seleccionar Œª con menor error de CV\n\n4. üèóÔ∏è Entrenar modelo final con Œª √≥ptimo en TODO el conjunto de desarrollo\n\n5. üß™ Evaluaci√≥n final en conjunto de prueba\n\n\n3.7.7.7 Variantes de Validaci√≥n Cruzada\n\n3.7.7.7.1 Leave-One-Out CV (LOOCV)\n\nk = n (n√∫mero de observaciones)\nVentaja: M√°ximo uso de datos para entrenamiento\nDesventaja: Computacionalmente costoso, alta varianza\n\n\n\n3.7.7.7.2 Stratified CV\n\nPara problemas de clasificaci√≥n\nMantiene la proporci√≥n de clases en cada fold\n\n\n\n3.7.7.7.3 Time Series CV\n\nPara datos temporales\nRespeta el orden temporal (no mezcla futuro con pasado)\n\n\n\n\n\n\n\n‚ö†Ô∏è Errores Comunes\n\n\n\n\nData Leakage: Usar informaci√≥n del conjunto de prueba durante el desarrollo\nM√∫ltiples evaluaciones: Evaluar repetidamente en el conjunto de prueba\nSelecci√≥n de modelo sesgada: Elegir el modelo bas√°ndose en el conjunto de prueba\nCV incorrecto: Aplicar transformaciones antes de la divisi√≥n de CV\n\n\n\n\n\n\n3.7.7.8 ¬øCu√°ndo usar cada enfoque?\n\n\n\n\n\n\n\n\nTama√±o del Dataset\nEnfoque Recomendado\nRaz√≥n\n\n\n\n\nGrande (&gt;10,000)\nTrain/Validation/Test\nSuficientes datos para divisi√≥n estable\n\n\nMediano (1,000-10,000)\nTrain/Test + CV\nCV para hiperpar√°metros, test para evaluaci√≥n final\n\n\nPeque√±o (&lt;1,000)\nSolo CV (sin test separado)\nMaximizar datos disponibles\n\n\nMuy peque√±o (&lt;100)\nLOOCV o Bootstrap\nCada observaci√≥n es valiosa\n\n\n\n\n\n\n\n\n\nConsejo Pr√°ctico\n\n\n\nEmpieza siempre con Elastic Net con \\(\\alpha = 0.5\\). Si el modelo selecciona muchas variables, prueba valores de \\(\\alpha\\) m√°s cercanos a 1 (m√°s Lasso). Si elimina variables importantes, prueba valores cercanos a 0 (m√°s Ridge).\n\n\n\n\n\n\n3.7.8 Ejercicio Pr√°ctico: Comparando los Tres M√©todos\nEn el notebook correspondiente, implementaremos:\n\nGeneraci√≥n de datos con diferentes estructuras de correlaci√≥n\nComparaci√≥n visual de los caminos de regularizaci√≥n\nValidaci√≥n cruzada para selecci√≥n de hiperpar√°metros\nEvaluaci√≥n del rendimiento en datos de prueba\nInterpretaci√≥n de los coeficientes seleccionados\n\nPregunta de reflexi√≥n: ¬øEn qu√© situaciones esperar√≠as que Ridge supere a Lasso, y viceversa?",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The\nElements of Statistical Learning. Springer Series in Statistics.\nSpringer New York Inc. https://hastie.su.domains/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, and\nJonathan Taylor. 2023. An Introduction to\nStatistical Learning: With Applications in Python. Springer\nTexts in Statistics. Cham: Springer. https://doi.org/10.1007/978-3-031-38747-0.",
    "crumbs": [
      "Referencias"
    ]
  }
]