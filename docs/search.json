[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Miner√≠a de Datos",
    "section": "",
    "text": "Temario\n\nIntroducci√≥n al aprendizaje de m√°quina\nPrincipios de aprendizaje supervisado\nRegresi√≥n lineal\nM√©todos de remuestreo y validaci√≥n cruzada\nPrincipios de Regularizaci√≥n\nProblemas de clasificaci√≥n, m√©tricas y evaluaci√≥n\n√Årboles, bosques aleatorios y boosting\nRedes neuronales\nM√©todos no supervisados\n\n\nEvaluaci√≥n\n\nDos ex√°menes parciales (40%)\nProyecto final (30%):\n\nEntrega (75%)\nExposici√≥n (25%)\n\n\nExamen final (30%)\n\nExistir√° una parte extra a los alumnos que contribuyan al aprendizaje de sus compa√±eros:\n\nContribuciones al repositorio: a√±adiendo redacci√≥n m√°s entendible, a√±adiendo ejemplos particulares a sus carreras, etc.\nActividad en el canal de Slack: contestando dudas de sus compa√±eros, iniciando discusiones para resolver problemas.\n\n\n\nProfesor\nNombre: Sa√∫l Caballero Ram√≠rez\nCorreo: saul.caballero.ramirez@gmail.com\nCorreo alternativo: saul@nixtla.io\nEl canal m√°s r√°pido y efectivo ser√° el siguiente canal de Slack. La idea de este canal es que puedan comunicarse entre ustedes para ayudarse a aprender y si necesitan de mi ayuda intentar√© contestar en un periodo corto de tiempo. Cualquier comportamiento inadecuado dentro de este foro ser√° penalizado por las reglas de convivencia del ITAM.\n\n\nReferencias principales\n\nAn Introduction to Statistical Learning, James et¬†al. (2023)\nThe Elements of Statistical Learning, Hastie, Tibshirani, y Friedman (2017)\n\n\n\n\n\nHastie, Trevor, Robert Tibshirani, y Jerome Friedman. 2017. The Elements of Statistical Learning. Springer Series en Statistics. Springer New York Inc. https://hastie.su.domains/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, y Jonathan Taylor. 2023. An Introduction to Statistical Learning: With Applications in Python. Springer Texts en Statistics. Cham: Springer. https://doi.org/10.1007/978-3-031-38747-0.",
    "crumbs": [
      "Temario"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1¬† Introducci√≥n",
    "section": "",
    "text": "1.1 ¬øQu√© es aprendizaje de m√°quina?\nM√©todos computacionales para aprender de datos con el fin de producir reglas para mejorar el desempe√±o en alguna tarea o toma de decisi√≥n.\nEn este curso nos enfocamos en las tareas de aprendizaje supervisado (predecir o estimar una variable respuesta a partir de datos de entrada) y aprendizaje no supervisado (describir estructuras interesantes en datos, donde no necesariamente hay una respuesta que predecir). Existe tambi√©n aprendizaje por refuerzo, en donde buscamos aprender a tomar decisiones en un entorno en donde la decisi√≥n afecta directa e inmediatamente al entorno.\nLas tareas m√°s apropiadas para este enfoque, en general, son aquellas en donde:",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#qu√©-es-aprendizaje-de-m√°quina",
    "href": "01-introduccion.html#qu√©-es-aprendizaje-de-m√°quina",
    "title": "1¬† Introducci√≥n",
    "section": "",
    "text": "Existe una cantidad considerable de datos relevantes para aprender a ejecutar la tarea.\nEl costo por errores al ejecutar la tarea es relativamente bajo (al menos comparado con alternativas).\nLa tarea se repite de manera m√°s o menos homog√©nea una cantidad grande de veces.\n\n\nEjemplos de tareas de aprendizaje:\n\nPredecir si un cliente de tarjeta de cr√©dito va a caer en impago en los pr√≥ximos doce meses.\nEstimar el ingreso mensual de un hogar a partir de las caracter√≠sticas de la vivienda, posesiones y equipamiento y localizaci√≥n geogr√°fica.\nDividir a los clientes de Netflix seg√∫n sus gustos.\nRecomendar art√≠culos a clientes de un programa de lealtad o servicio online.\nReconocer un tipos de documentos (identificaci√≥n, comprobante de domicilio, comprobante de ingresos) para acelerar el proceso de evaluaci√≥n de cr√©dito.\n\nLas razones usuales para intentar resolver estos problemas computacionalmente son diversas:\n\nQuisi√©ramos obtener una respuesta barata, r√°pida, automatizada, y con suficiente precisi√≥n. Por ejemplo, reconocer caracteres en una placa de coche de una fotograf√≠a se puede hacer por personas, pero eso es lento y costoso. Hacer mediciones directas del ingreso de un hogar requiere mucho tiempo y esfuerzo.\nQuisi√©ramos superar el desempe√±o actual de los expertos o de reglas simples utilizando datos: por ejemplo, en la decisi√≥n de dar o no un pr√©stamo a un solicitante, puede ser posible tomar mejores decisiones con algoritmos que con evaluaciones personales o con reglas simples que toman en cuenta el ingreso mensual, por ejemplo.\nAl resolver estos problemas computacionalmente tenemos oportunidad de aprender m√°s del problema que nos interesa: estas soluciones forman parte de un ciclo de an√°lisis de datos donde podemos aprender de una forma m√°s concentrada cu√°les son caracter√≠sticas y patrones importantes de nuestros datos.\n\nEs posible aproximarse a todos estos problemas usando reglas (por ejemplo, si los pixeles del centro de la imagen est√°n vac√≠os, entonces es un cero, si el cr√©dito total es mayor al 50% del ingreso anual, declinar el pr√©stamo, etc). Las razones para no tomar un enfoque de reglas construidas ‚Äúa mano‚Äù:\n\nCuando conjuntos de reglas creadas a mano se desempe√±an mal (por ejemplo, para otorgar cr√©ditos, reconocer caracteres, etc.)\nReglas creadas a mano pueden ser dif√≠ciles de mantener (por ejemplo, un corrector ortogr√°fico), pues para problemas interesantes muchas veces se requieren grandes cantidades de reglas. Por ejemplo: ¬øqu√© b√∫squedas www se enfocan en dar direcciones como resultados? ¬øc√≥mo filtrar comentarios no aceptables en foros?\nFinalmente, notamos que en estos problemas nuestro inter√©s principal no es entender qu√© variables influyen en otras (en el proceso natural o de negocio). Sin m√°s teor√≠a o dise√±o de datos, los m√©todos que utilizaremos explotan patrones en los datos que no necesariamente explican c√≥mo funcionan los sistemas de inter√©s.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "href": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "title": "1¬† Introducci√≥n",
    "section": "1.2 Aprendizaje supervisado y no supervisado",
    "text": "1.2 Aprendizaje supervisado y no supervisado\nLas tareas de aprendizaje se dividen en dos grandes partes: aprendizaje supervisado y aprendizaje no supervisado.\nEn Aprendizaje supervisado buscamos construir un modelo o algoritmo para predecir o estimar un target o una respuesta a partir de ciertas variables de entrada.\nPredecir y estimar, en este contexto, se refieren a cosas similares. Generalmente se usa predecir cuando se trata de variables que no son observables ahora, sino en el futuro, y estimar cuando nos interesan variables actuales que no podemos observar ahora por costos o por la naturaleza del fen√≥meno.\nPor ejemplo, para identificar a los clientes con alto riesgo de impago de tarjeta de cr√©dito, utilizamos datos hist√≥ricos de clientes que han pagado y no han pagado. Con estos datos entrenamos un algoritmo para detectar anticipadamente los clientes con alto riesgo de impago.\nUsualmente dividimos los problemas de aprendizaje supervisado en dos tipos, dependiendo de la variables salida:\n\nProblemas de regresi√≥n: cuando la salida es una variable num√©rica. El ejemplo de estimaci√≥n de ingreso es un problema de regresi√≥n\nProblemas de clasificaci√≥n: cuando la salida es una variable categ√≥rica. El ejemplo de detecci√≥n de d√≠gitos escritos a manos es un problema de clasificaci√≥n.\n\nEn contraste, en Aprendizaje no supervisado no hay target o variable respuesta. Buscamos modelar y entender las relaciones entre variables y entre observaciones, o patrones importantes o interesantes en los datos.\nLos problemas supervisados tienen un objetivo claro: hacer las mejores predicciones posibles bajo ciertas restricciones. Los problemas no supervisados tienden a tener objetivos m√°s vagos, y por lo mismo pueden ser m√°s dif√≠ciles.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "02-principios.html",
    "href": "02-principios.html",
    "title": "2¬† Principios de aprendizaje supervisado",
    "section": "",
    "text": "2.1 Definici√≥n de aprendizaje supervisado\nSupongamos que observamos una variable cuantitativa \\(Y \\in \\mathbb{R}\\) y tenemos \\(p\\) variables predictoras, \\(X_1, X_2, ..., X_p\\), las cuales denotaremos como \\(X = (X_1, X_2, ..., X_p)\\). Supongamos que existe alguna reluaci√≥n entre ellas y se puede expresar de la siguiente forma:\n\\[ Y = f(x) + \\epsilon\\]\nLa tarea del aprendizaje supervisado es aprender la funci√≥n \\(f\\). Existen dos razones por las cuales estimar \\(f\\): predicci√≥n e inferencia.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "02-principios.html#definici√≥n-de-aprendizaje-supervisado",
    "href": "02-principios.html#definici√≥n-de-aprendizaje-supervisado",
    "title": "2¬† Principios de aprendizaje supervisado",
    "section": "",
    "text": "Funci√≥n \\(f\\): funci√≥n desconocida que relaciona a \\(X\\) con \\(Y\\). Representa la informaci√≥n sist√©mica que \\(X\\) aporta a \\(Y\\).\nError \\(\\epsilon\\): representa qu√© tan equivocados estamos con respecto al verdadero valor de \\(Y\\).\n\n\n\n2.1.1 Predicci√≥n\nEn muchas ocasiones existen un conjunto de variables \\(X\\) que est√°n listas para aprovecharse, sin embargo, puede que no se pueda obtener la variable \\(Y\\) de manera inmediata. En este sentido, podemos predecir la variable \\(Y\\) siguiendo la ecuaci√≥n:\n\\[\\hat{Y} = \\hat{f}(X)\\]\ndonde \\(\\hat{f}\\) representa nuestro estimador de \\(f\\) y \\(\\hat{Y}\\) es nuestra predicci√≥n de \\(Y\\). En este sentido \\(\\hat{f}\\) es una caja negra en el sentido en el que no nos preocupa cu√°l es la funci√≥n, sino que provee predicciones precisas para \\(Y\\).\nLa precisi√≥n de \\(\\hat{Y}\\) depende de dos cantidades:\n\nError reducible: En general, \\(\\hat{f}\\) no ser√° un estimador perfecto de \\(f\\) y esto introducir√° un error el cu√°l puede reducirse. Ejemplos: Introducir una estructura lineal cu√°ndo el problema tiene estructura cuadr√°tica, falta de variables explicativas, exceso de variables que no contribuyen a la predicci√≥n.\nError ireducible: La variable \\(Y\\) es una funci√≥n tambi√©n de \\(\\epsilon\\) y por definici√≥n nuestra predicci√≥n tendra un error inherente. Ejemplos: Predecir que comer√°n ma√±ana, determinar si llover√° o no, determinar cu√°ndo ocurrir√° un temblor, ¬øqui√©n ganar√° una elecci√≥n?.\n\n\\[ \\begin{align*}\n\\mathbb{E}[(Y-\\hat{Y})^2] &= \\mathbb{E}[(f(X) + \\epsilon -\\hat{f}(x))^2]\\\\\n&= \\underset{Reducible}{\\underbrace{\\mathbb{E}[(f(X) - \\hat{f}(x))^2]}} + \\underset{Irreducible}{\\underbrace{\\text{Var}(\\epsilon)}}\n\\end{align*}\\]\nEl objetivo del curso se enfoca en t√©cnicas para estimar \\(f\\) con el objectivo de minimizar el error reducible. Es importante tener en cuenta que el error irreducible siempre nos pondr√° una cota en la predicci√≥n de \\(Y\\).\n\n\n2.1.2 Inferencia\nExisten problemas en donde nos interesa m√°s entender la relaci√≥n intrinseca que existe entre \\(Y\\) y \\(X\\). En esta situaci√≥n nuestro objetivo no es hacer predicci√≥n, entonces \\(\\hat{f}\\) ya no puede ser tratada como una caja negra. En este tipo de enfoque se contestan preguntas c√≥mo:\n\n¬øCu√°les son los predictores que se asocian con la variable \\(Y\\)?: Muchas veces solo un subconjunto de los datos \\(X\\) son los que realmente est√°n relacionados con \\(Y\\).\n¬øCu√°l es la relaci√≥n entre \\(Y\\) y \\(X_i\\)?\n¬øLa relaci√≥n entre \\(Y\\) y \\(X_i\\) es lineal o m√°s compleja?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "02-principios.html#c√≥mo-estimar-f",
    "href": "02-principios.html#c√≥mo-estimar-f",
    "title": "2¬† Principios de aprendizaje supervisado",
    "section": "2.2 ¬øC√≥mo estimar \\(f\\)?",
    "text": "2.2 ¬øC√≥mo estimar \\(f\\)?\nAsumiremos que tenemos \\(n\\) datos diferentes estas observaciones ser√°n llamadas conjunto de entrenamiento. \\(x_{ij}\\) representa el valor del predictor \\(j\\) para la observaci√≥n \\(i\\), donde \\(i=1,2,...,n\\) y \\(j=1,2,...,p\\). \\(y_i\\) representa la variable respuesta de la observaci√≥n \\(i\\). Entonces nuestro conjunto de entrenamiento consiste en:\n\\[{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)}\\]\ndonde \\(x_i=(x_{i1}, x_{i2}, ..., x_{ip})^T\\).\nNuestro objetivo es aplicar un m√©todo de aprendizaje en el conjunto de datos para poder estimar una funci√≥n desconocida de \\(f\\). Nos encantar√≠a encontrar una funci√≥n \\(\\hat{f}\\) de forma tal que \\(Y\\simeq \\hat{f}(X)\\) para cualquier observaci√≥n \\((X, Y)\\). Muchos de estos enfoque se pueden caracterizar como m√©todos param√©tricos o no param√©tricos.\n\n2.2.1 M√©todos param√©tricos\nLos m√©todos param√©tricos involucran un enfoque de dos pasos:\n\nHacemos un supuesto de la forma funci√≥n de \\(f\\). Por ejemplo, la m√°s sencilla es que \\(f\\) es linear en \\(\\beta\\):\n\n\\[ f(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]\nUna vez haciendo haciendo el supuesto de linealidad el problema de estimar \\(f\\) es simplificado ya que en lugar de explorar el espacio funcional uno solo necesita estimar \\(p+1\\) coeficientes \\(\\beta_0, ..., \\beta_p\\).\n\nNecesitamos un proceso que utilice los datos de entrenamiento para ajustar u entrenar el modelo. El enfoque m√°s sencillo es el m√©todo de m√≠nimos cuadrados ordinarios (OLS):\n\n\\[\\underset{\\beta_0, \\beta_1, ..., \\beta_p}{min} \\sum_{i=1}^{N}(y_i - (\\beta_0 + \\beta_1 x_{i1} +\\beta_2 x_{i2} + ... + \\beta_p X_p))^2\\]\nEl enfoque basado en modelado se refiere a los modelos param√©tricos; reduce el problema de estimar \\(f\\) a estimar un conjunto de par√°metros. La desventaja potencial es que el modelo podr√≠a no ser igual a la verdadera \\(f\\) y tendremos malas estimaciones del valor de \\(y\\).\n\n\n2.2.2 M√©todos no param√©tricos",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios de aprendizaje supervisado</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html",
    "href": "03-regresion_lineal.html",
    "title": "3¬† Regresi√≥n lineal",
    "section": "",
    "text": "3.1 Regresi√≥n Lineal Simple\nComenzaremos con el caso m√°s sencillo: predecir una variable de resultado Y a partir de una √∫nica variable predictora X.\nEl modelo matem√°tico que queremos ajustar es una l√≠nea recta:\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\nDonde:\nNuestro objetivo üéØ es encontrar los mejores valores posibles para los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) usando los datos que tenemos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#regresi√≥n-lineal-simple",
    "href": "03-regresion_lineal.html#regresi√≥n-lineal-simple",
    "title": "3¬† Regresi√≥n lineal",
    "section": "",
    "text": "\\(Y\\): La variable dependiente (lo que queremos predecir).\n\\(X\\): La variable independiente (nuestro predictor).\n\\(\\beta_0\\): El intercepto (el valor de \\(Y\\) cuando \\(X=0\\)).\n\\(\\beta_1\\): La pendiente (cu√°nto cambia \\(Y\\) por cada unidad que aumenta \\(X\\)).\n\\(\\epsilon\\): El t√©rmino de error (la parte de \\(Y\\) que nuestro modelo no puede explicar).\n\n\n\n3.1.1 ¬øC√≥mo estimamos los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\)?\n‚ÄúMejor‚Äù para nosotros significa encontrar la l√≠nea que minimice la distancia vertical entre cada punto de dato y la propia l√≠nea. Espec√≠ficamente, minimizamos la Suma de los Errores al Cuadrado (SEC o Sum of Squared Errors, SSE).\nLa funci√≥n de costo (o p√©rdida) que queremos minimizar es:\n\\[J(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))^2\\]\nTenemos dos m√©todos principales para encontrar los \\(\\beta\\) que minimizan esta funci√≥n:\n\n3.1.1.1 M√©todo 1: Las Ecuaciones Normales (La soluci√≥n anal√≠tica üß†)\nEste m√©todo utiliza c√°lculo para encontrar el m√≠nimo exacto de la funci√≥n de costo. Para ello, tomamos las derivadas parciales de \\(J\\) con respecto a \\(\\beta_0\\) y \\(\\beta_1\\), las igualamos a cero y resolvemos para los coeficientes.\n\n\n\n\n\n\nDerivada parcial con respecto a \\(\\beta_0\\):\n\n\n\n\n\n\\[\\frac{\\partial J}{\\partial \\beta_0} = \\sum_{i=1}^{n} -2(y_i - \\beta_0 - \\beta_1 x_i) = 0\\] \\[\\sum y_i - n\\beta_0 - \\beta_1 \\sum x_i = 0\\] \\[\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\]\n\n\n\n\n\n\n\n\n\nDerivada parcial con respecto a \\(\\beta_1\\)\n\n\n\n\n\n\\[\\frac{\\partial J}{\\partial \\beta_1} = \\sum_{i=1}^{n} -2x_i(y_i - \\beta_0 - \\beta_1 x_i) = 0\\] Sustituyendo \\(\\beta_0\\) de la primera ecuaci√≥n y resolviendo, llegamos a: \\[\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\n\n\n\nEstas f√≥rmulas nos dan los valores √≥ptimos y exactos de los coeficientes directamente a partir de los datos.\n\n\n3.1.1.2 M√©todo 2: Descenso en Gradiente (La soluci√≥n iterativa ‚öôÔ∏è)\nEste es un m√©todo computacional que nos ‚Äúacerca‚Äù progresivamente a la soluci√≥n. Es especialmente √∫til cuando tenemos una cantidad masiva de datos y calcular la soluci√≥n anal√≠tica es muy costoso.\nLa intuici√≥n: Imagina que est√°s en una monta√±a (la funci√≥n de costo) y quieres llegar al valle (el costo m√≠nimo). El Descenso en Gradiente te dice que mires a tu alrededor y des un paso en la direcci√≥n m√°s inclinada hacia abajo. Repites esto hasta llegar al fondo.\nEl algoritmo funciona as√≠:\n\nInicializa los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) con valores aleatorios (o en ceros).\nCalcula el gradiente de la funci√≥n de costo. El gradiente es un vector que apunta en la direcci√≥n del m√°ximo ascenso. Nosotros iremos en la direcci√≥n opuesta.\n\n\\(\\frac{\\partial J}{\\partial \\beta_0} = -2 \\sum (y_i - (\\beta_0 + \\beta_1 x_i))\\)\n\\(\\frac{\\partial J}{\\partial \\beta_1} = -2 \\sum x_i(y_i - (\\beta_0 + \\beta_1 x_i))\\)\n\nActualiza los coeficientes usando una tasa de aprendizaje (\\(\\alpha\\)), que controla el tama√±o del paso que damos.\n\n\\(\\beta_0 := \\beta_0 - \\alpha \\frac{\\partial J}{\\partial \\beta_0}\\)\n\\(\\beta_1 := \\beta_1 - \\alpha \\frac{\\partial J}{\\partial \\beta_1}\\)\n\nRepite los pasos 2 y 3 durante un n√∫mero determinado de iteraciones o hasta que el cambio en el costo sea muy peque√±o (convergencia).\n\n\n\n\n\n\n\nExplicacion visual\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 ¬øCu√°les son los supuestos de la regresi√≥n? üßê\nPara que nuestro modelo sea confiable (es decir, para que los coeficientes y las predicciones tengan sentido), debemos cumplir con ciertos supuestos.\n\nLinealidad: La relaci√≥n entre \\(\\beta\\) y \\(Y\\) debe ser lineal.\n\n¬øPara qu√© sirve? Si la relaci√≥n no es lineal, nuestro modelo de l√≠nea recta ser√° intr√≠nsecamente incorrecto. Podemos verificar esto visualmente con un diagrama de dispersi√≥n.\n\nIndependencia de los errores: Los errores (residuos) no deben estar correlacionados entre s√≠.\n\n¬øPara qu√© sirve? Es crucial para datos de series temporales. Si los errores est√°n correlacionados, la informaci√≥n de un error nos da pistas sobre el siguiente, lo cual viola la idea de que cada observaci√≥n es independiente.\n\nHomocedasticidad (Varianza constante de los errores): La varianza de los errores debe ser constante para todos los niveles de \\(X\\).\n\n¬øPara qu√© sirve? Si la varianza cambia (heterocedasticidad), nuestras predicciones ser√°n mejores para algunas partes de los datos que para otras, y los intervalos de confianza para los coeficientes ser√°n poco fiables. Visualmente, en un gr√°fico de residuos vs.¬†valores predichos, no queremos ver una forma de cono o embudo.\n\nNormalidad de los errores: Los errores deben seguir una distribuci√≥n normal con media cero.\n\n¬øPara qu√© sirve? Este supuesto es fundamental para poder realizar pruebas de hip√≥tesis sobre los coeficientes (como los p-values) y construir intervalos de confianza. Podemos verificarlo con un histograma de los residuos o un gr√°fico Q-Q.\n\n\n\n\n\n3.1.3 ¬øC√≥mo evaluar la precisi√≥n del modelo? üìà\nUna vez que hemos ajustado el modelo, ¬øc√≥mo sabemos si es bueno?\n\n3.1.3.1 Coeficiente de Determinaci√≥n (\\(R^2\\))\nEl \\(R^2\\) mide la proporci√≥n de la varianza total en la variable dependiente (\\(Y\\)) que es explicada por nuestro modelo.\n\\[R^2 = 1 - \\frac{\\text{Suma de Errores al Cuadrado (SEC)}}{\\text{Suma Total de Cuadrados (STC)}} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\\]\n\n\\(R^2\\) var√≠a entre 0 y 1 (o 0% y 100%).\nUn \\(R^2\\) de 0.85 significa que el 85% de la variabilidad en \\(Y\\) puede ser explicada por \\(X\\).\nUn \\(R^2\\) m√°s alto generalmente indica un mejor ajuste del modelo.\n\n\n\n3.1.3.2 p-values (Valores p)\nEl p-value nos ayuda a determinar si nuestra variable predictora \\(X\\) es estad√≠sticamente significativa. Responde a la pregunta: ¬øEs probable que la relaci√≥n que observamos entre \\(X\\) y \\(Y\\) haya ocurrido por puro azar?\n\nHip√≥tesis Nula (\\(H_0\\)): No hay relaci√≥n entre \\(X\\) y \\(Y\\) (es decir, \\(\\beta_1 = 0\\)).\nHip√≥tesis Alternativa (\\(H_a\\)): S√≠ hay una relaci√≥n entre \\(X\\) y \\(Y\\) (es decir, \\(\\beta_1 \\neq 0\\)).\n\nUn p-value peque√±o (t√≠picamente &lt; 0.05) nos da evidencia para rechazar la hip√≥tesis nula. Esto sugiere que nuestra variable \\(X\\) es un predictor √∫til para \\(Y\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#parte-2-regresi√≥n-lineal-m√∫ltiple",
    "href": "03-regresion_lineal.html#parte-2-regresi√≥n-lineal-m√∫ltiple",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.2 Parte 2: Regresi√≥n Lineal M√∫ltiple",
    "text": "3.2 Parte 2: Regresi√≥n Lineal M√∫ltiple\nAhora, ¬øqu√© pasa si tenemos m√∫ltiples predictores (\\(X_1, X_2, ..., X_p\\))? El modelo se expande:\n\\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\epsilon\\]\nLa intuici√≥n es la misma, pero en lugar de ajustar una l√≠nea, estamos ajustando un hiperplano en un espacio multidimensional.\nPara manejar esto de forma elegante, usamos notaci√≥n matricial:\n\\[\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\]\nDonde: - \\(\\mathbf{y}\\) es el vector de observaciones. - \\(\\mathbf{X}\\) es la matriz de dise√±o (con una primera columna de unos para el intercepto). - \\(\\boldsymbol{\\beta}\\) es el vector de coeficientes. - \\(\\boldsymbol{\\epsilon}\\) es el vector de errores.\nLa funci√≥n de costo en forma matricial es: \\[J(\\boldsymbol{\\beta}) = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#transformaciones-comunes-en-modelos-lineales",
    "href": "03-regresion_lineal.html#transformaciones-comunes-en-modelos-lineales",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.3 Transformaciones Comunes en Modelos Lineales",
    "text": "3.3 Transformaciones Comunes en Modelos Lineales\nA veces, la relaci√≥n entre X e Y no es estrictamente lineal. Las transformaciones logar√≠tmicas nos permiten modelar relaciones no lineales y, adem√°s, ofrecen interpretaciones muy √∫tiles en t√©rminos de cambios porcentuales.\n\n3.3.1 Modelo Log-Nivel (Transformaci√≥n en Y)\nEste modelo se usa cuando el efecto de X sobre Y no es absoluto, sino porcentual. Por ejemplo, c√≥mo un a√±o m√°s de educaci√≥n afecta el porcentaje de aumento salarial.\n\nEcuaci√≥n: \\(\\ln(Y) = \\beta_0 + \\beta_1 X + \\epsilon\\)\nInterpretaci√≥n: Un incremento de una unidad en \\(X\\) est√° asociado con un cambio de \\((100 \\cdot \\beta_1)\\%\\) en \\(Y\\).\n\n\n\n\n\n\n\nExplicaci√≥n Matem√°tica de la Aproximaci√≥n\n\n\n\n\n\nLa clave est√° en la propiedad del logaritmo y el c√°lculo. La derivada de \\(\\ln(Y)\\) con respecto a \\(X\\) es \\(\\beta_1\\): \\[\\frac{d(\\ln(Y))}{dX} = \\beta_1\\] Sabemos que \\(d(\\ln(Y)) = \\frac{dY}{Y}\\). Por tanto: \\[\\frac{dY/Y}{dX} = \\beta_1\\] Para cambios peque√±os (o discretos, \\(\\Delta\\)), podemos aproximar los diferenciales: \\[\\beta_1 \\approx \\frac{\\Delta Y / Y}{\\Delta X}\\] Si consideramos un cambio unitario en X, \\(\\Delta X = 1\\), entonces: \\[\\beta_1 \\approx \\frac{\\Delta Y}{Y}\\] Esto significa que \\(\\beta_1\\) es la aproximaci√≥n del cambio porcentual en \\(Y\\) ante un cambio de una unidad en \\(X\\).\n\n\n\n\n\n3.3.2 Modelo Nivel-Log (Transformaci√≥n en X)\nEste modelo es √∫til cuando el efecto de X sobre Y se reduce a medida que X aumenta (rendimientos decrecientes). Por ejemplo, el efecto de a√±adir presupuesto de marketing sobre las ventas.\n\nEcuaci√≥n: \\(Y = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\\)\nInterpretaci√≥n: Un incremento del 1% en \\(X\\) est√° asociado con un cambio de \\((\\beta_1 / 100)\\) unidades en \\(Y\\).\n\n\n\n\n\n\n\nExplicaci√≥n Matem√°tica de la Aproximaci√≥n\n\n\n\n\n\nTomamos la derivada de \\(Y\\) con respecto a \\(\\ln(X)\\): \\[\\frac{dY}{d(\\ln(X))} = \\beta_1\\] Usando la regla de la cadena, sabemos que \\(d(\\ln(X)) = \\frac{dX}{X}\\). Sustituyendo: \\[\\frac{dY}{dX/X} = \\beta_1 \\implies dY = \\beta_1 \\frac{dX}{X}\\] Para cambios discretos, aproximamos: \\[\\Delta Y \\approx \\beta_1 \\frac{\\Delta X}{X}\\] Si consideramos un cambio del 1% en X, entonces \\(\\frac{\\Delta X}{X} = 0.01\\). La ecuaci√≥n se convierte en: \\[\\Delta Y \\approx \\beta_1 (0.01) = \\frac{\\beta_1}{100}\\] Esto significa que un cambio del 1% en \\(X\\) provoca un cambio de \\(\\beta_1/100\\) unidades en \\(Y\\).\n\n\n\n\n\n3.3.3 Modelo Log-Log (Transformaci√≥n en X e Y)\nEste modelo es muy com√∫n en econom√≠a y modela la elasticidad constante entre dos variables.\n\nEcuaci√≥n: \\(\\ln(Y) = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\\)\nInterpretaci√≥n: Un incremento del 1% en \\(X\\) est√° asociado con un cambio del \\(\\beta_1\\%\\) en \\(Y\\).\n\n\n\n\n\n\n\nExplicaci√≥n Matem√°tica de la Aproximaci√≥n\n\n\n\n\n\nEste caso combina los dos anteriores. \\(\\beta_1\\) es la derivada de \\(\\ln(Y)\\) con respecto a \\(\\ln(X)\\), que es la definici√≥n de elasticidad. \\[\\beta_1 = \\frac{d(\\ln(Y))}{d(\\ln(X))}\\] Usando las propiedades del c√°lculo que vimos antes: \\[\\beta_1 = \\frac{dY/Y}{dX/X}\\] Aproximando para cambios discretos: \\[\\beta_1 \\approx \\frac{\\Delta Y / Y}{\\Delta X / X}\\] Esta es la definici√≥n de elasticidad: el cambio porcentual en \\(Y\\) dividido por el cambio porcentual en \\(X\\). Por lo tanto, si \\(X\\) cambia en un 1% (\\(\\Delta X / X = 0.01\\)), el cambio porcentual en \\(Y\\) (\\(\\Delta Y / Y\\)) ser√° aproximadamente \\(\\beta_1 \\times 0.01\\), es decir, un \\(\\beta_1\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "03-regresion_lineal.html#parte-4-ejercicio-en-clase",
    "href": "03-regresion_lineal.html#parte-4-ejercicio-en-clase",
    "title": "3¬† Regresi√≥n lineal",
    "section": "3.4 Parte 4: Ejercicio en Clase",
    "text": "3.4 Parte 4: Ejercicio en Clase\nAhora es su turno. En grupos, vamos a derivar las soluciones para la Regresi√≥n Lineal M√∫ltiple.\n\n3.4.1 Tarea 1: Derivar las Ecuaciones Normales para el caso M√∫ltiple\nUsando la funci√≥n de costo matricial \\(J(\\boldsymbol{\\beta})\\), encuentren el vector de coeficientes \\(\\boldsymbol{\\beta}\\) que la minimiza.\nPista: La derivada de \\(J(\\boldsymbol{\\beta})\\) con respecto al vector \\(\\boldsymbol{\\beta}\\) es \\(\\nabla_{\\boldsymbol{\\beta}}J = -2\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\). Igualen esta derivada a cero y despejen \\(\\boldsymbol{\\beta}\\).\n\n\n\n\n\n\nVer la soluci√≥n\n\n\n\n\n\n\\[-2\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = 0\\] \\[\\mathbf{X}^T\\mathbf{y} - \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = 0\\] \\[\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^T\\mathbf{y}\\] \\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\\]\nEsta es la famosa soluci√≥n de M√≠nimos Cuadrados Ordinarios (MCO) en forma matricial.\n\n\n\n\n\n3.4.2 Tarea 2: Formular el Descenso en Gradiente para el caso M√∫ltiple\nBas√°ndose en el gradiente que se les dio en la pista anterior y el algoritmo que vimos para el caso simple, escriban la regla de actualizaci√≥n para el vector \\(\\boldsymbol{\\beta}\\) en el Descenso en Gradiente.\nPreguntas a responder: 1. ¬øCu√°l es el gradiente de la funci√≥n de costo? 2. ¬øC√≥mo se ve la regla de actualizaci√≥n para el vector \\(\\boldsymbol{\\beta}\\) completo?\n\n\n\n\n\n\nVer la soluci√≥n\n\n\n\n\n\n\nEl gradiente es: \\[\\nabla J(\\boldsymbol{\\beta}) = -2\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\]\nLa regla de actualizaci√≥n vectorial es: \\[\\boldsymbol{\\beta} := \\boldsymbol{\\beta} - \\alpha \\nabla J(\\boldsymbol{\\beta})\\] \\[\\boldsymbol{\\beta} := \\boldsymbol{\\beta} - \\alpha (-2\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}))\\] Simplificando (el 2 a menudo se absorbe en la tasa de aprendizaje \\(\\alpha\\)): \\[\\boldsymbol{\\beta} := \\boldsymbol{\\beta} + \\alpha \\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n lineal</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The\nElements of Statistical Learning. Springer Series in Statistics.\nSpringer New York Inc. https://hastie.su.domains/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, and\nJonathan Taylor. 2023. An Introduction to\nStatistical Learning: With Applications in Python. Springer\nTexts in Statistics. Cham: Springer. https://doi.org/10.1007/978-3-031-38747-0.",
    "crumbs": [
      "Referencias"
    ]
  }
]