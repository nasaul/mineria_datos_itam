<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Árboles de Decisión – Minería de Datos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./04-clasificacion.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-2453fe3dad938b07a2e5eff64ea8abce.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-c1367505ed6638c8d4e510e1459ae853.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-2453fe3dad938b07a2e5eff64ea8abce.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Árboles de Decisión – Minería de Datos">
<meta property="og:description" content="">
<meta property="og:image" content="05-arboles_files/figure-html/feature-importance-output-1.png">
<meta property="og:site_name" content="Minería de Datos">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./05-arboles.html"><span class="chapter-title">Árboles de Decisión</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Minería de Datos</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Alternar modo oscuro"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Temario</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-requerimientos-computacion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Requerimientos computacionales</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-introduccion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-principios.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Principios de aprendizaje supervisado</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Regresion lineal</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-regresion_lineal.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Regresión lineal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./violaciones_supuestos_regresion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Violaciones de los Supuestos de Regresión Lineal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./analisis_advertising_dataset.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Análisis de Regresión Lineal con el Dataset Advertising</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ejercicio_wine_quality.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Ejercicio: Análisis de Regresión con el Dataset Wine Quality</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-clasificacion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Clasificación</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-arboles.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Árboles de Decisión</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Ejemplos</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduccion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introducción a Python para Minería de Datos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regresion_lineal.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Descenso en gradiente con regresión lineal</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#introducción" id="toc-introducción" class="nav-link active" data-scroll-target="#introducción">Introducción</a>
  <ul class="collapse">
  <li><a href="#motivación-limitaciones-de-los-métodos-lineales" id="toc-motivación-limitaciones-de-los-métodos-lineales" class="nav-link" data-scroll-target="#motivación-limitaciones-de-los-métodos-lineales">Motivación: Limitaciones de los Métodos Lineales</a></li>
  <li><a href="#estructura-de-un-árbol-de-decisión" id="toc-estructura-de-un-árbol-de-decisión" class="nav-link" data-scroll-target="#estructura-de-un-árbol-de-decisión">Estructura de un Árbol de Decisión</a></li>
  <li><a href="#ejemplo-visual-simple" id="toc-ejemplo-visual-simple" class="nav-link" data-scroll-target="#ejemplo-visual-simple">Ejemplo Visual Simple</a></li>
  </ul></li>
  <li><a href="#construcción-de-árboles-de-decisión" id="toc-construcción-de-árboles-de-decisión" class="nav-link" data-scroll-target="#construcción-de-árboles-de-decisión">Construcción de Árboles de Decisión</a>
  <ul class="collapse">
  <li><a href="#particionamiento-recursivo-del-espacio" id="toc-particionamiento-recursivo-del-espacio" class="nav-link" data-scroll-target="#particionamiento-recursivo-del-espacio">Particionamiento Recursivo del Espacio</a></li>
  <li><a href="#criterios-de-impureza" id="toc-criterios-de-impureza" class="nav-link" data-scroll-target="#criterios-de-impureza">Criterios de Impureza</a></li>
  <li><a href="#comparación-visual-de-criterios-de-impureza" id="toc-comparación-visual-de-criterios-de-impureza" class="nav-link" data-scroll-target="#comparación-visual-de-criterios-de-impureza">Comparación Visual de Criterios de Impureza</a></li>
  <li><a href="#algoritmo-de-construcción-cart" id="toc-algoritmo-de-construcción-cart" class="nav-link" data-scroll-target="#algoritmo-de-construcción-cart">Algoritmo de Construcción CART</a></li>
  <li><a href="#ejemplo-construcción-paso-a-paso" id="toc-ejemplo-construcción-paso-a-paso" class="nav-link" data-scroll-target="#ejemplo-construcción-paso-a-paso">Ejemplo: Construcción Paso a Paso</a></li>
  </ul></li>
  <li><a href="#sobreajuste-y-control-de-complejidad" id="toc-sobreajuste-y-control-de-complejidad" class="nav-link" data-scroll-target="#sobreajuste-y-control-de-complejidad">Sobreajuste y Control de Complejidad</a>
  <ul class="collapse">
  <li><a href="#el-problema-del-sobreajuste" id="toc-el-problema-del-sobreajuste" class="nav-link" data-scroll-target="#el-problema-del-sobreajuste">El Problema del Sobreajuste</a></li>
  <li><a href="#estrategias-de-control-de-complejidad" id="toc-estrategias-de-control-de-complejidad" class="nav-link" data-scroll-target="#estrategias-de-control-de-complejidad">Estrategias de Control de Complejidad</a></li>
  </ul></li>
  <li><a href="#interpretabilidad-y-análisis" id="toc-interpretabilidad-y-análisis" class="nav-link" data-scroll-target="#interpretabilidad-y-análisis">Interpretabilidad y Análisis</a>
  <ul class="collapse">
  <li><a href="#importancia-de-variables" id="toc-importancia-de-variables" class="nav-link" data-scroll-target="#importancia-de-variables">Importancia de Variables</a></li>
  <li><a href="#extracción-de-reglas" id="toc-extracción-de-reglas" class="nav-link" data-scroll-target="#extracción-de-reglas">Extracción de Reglas</a></li>
  </ul></li>
  <li><a href="#ventajas-y-desventajas" id="toc-ventajas-y-desventajas" class="nav-link" data-scroll-target="#ventajas-y-desventajas">Ventajas y Desventajas</a>
  <ul class="collapse">
  <li><a href="#ventajas-de-los-árboles-de-decisión" id="toc-ventajas-de-los-árboles-de-decisión" class="nav-link" data-scroll-target="#ventajas-de-los-árboles-de-decisión">Ventajas de los Árboles de Decisión</a></li>
  <li><a href="#desventajas-de-los-árboles-de-decisión" id="toc-desventajas-de-los-árboles-de-decisión" class="nav-link" data-scroll-target="#desventajas-de-los-árboles-de-decisión">Desventajas de los Árboles de Decisión</a></li>
  <li><a href="#comparación-visual-árbol-vs-regresión-logística" id="toc-comparación-visual-árbol-vs-regresión-logística" class="nav-link" data-scroll-target="#comparación-visual-árbol-vs-regresión-logística">Comparación Visual: Árbol vs Regresión Logística</a></li>
  </ul></li>
  <li><a href="#aplicación-práctica-dataset-real" id="toc-aplicación-práctica-dataset-real" class="nav-link" data-scroll-target="#aplicación-práctica-dataset-real">Aplicación Práctica: Dataset Real</a></li>
  <li><a href="#conclusiones-y-mejores-prácticas" id="toc-conclusiones-y-mejores-prácticas" class="nav-link" data-scroll-target="#conclusiones-y-mejores-prácticas">Conclusiones y Mejores Prácticas</a>
  <ul class="collapse">
  <li><a href="#recomendaciones-para-usar-árboles-de-decisión" id="toc-recomendaciones-para-usar-árboles-de-decisión" class="nav-link" data-scroll-target="#recomendaciones-para-usar-árboles-de-decisión">Recomendaciones para Usar Árboles de Decisión</a></li>
  <li><a href="#cuándo-usar-árboles-de-decisión" id="toc-cuándo-usar-árboles-de-decisión" class="nav-link" data-scroll-target="#cuándo-usar-árboles-de-decisión">Cuándo Usar Árboles de Decisión</a></li>
  <li><a href="#próximos-pasos-métodos-ensemble" id="toc-próximos-pasos-métodos-ensemble" class="nav-link" data-scroll-target="#próximos-pasos-métodos-ensemble">Próximos Pasos: Métodos Ensemble</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Árboles de Decisión</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introducción" class="level2">
<h2 class="anchored" data-anchor-id="introducción">Introducción</h2>
<p>Los <strong>árboles de decisión</strong> son uno de los métodos más intuitivos y ampliamente utilizados en el aprendizaje supervisado. A diferencia de los métodos lineales como la regresión logística, los árboles pueden capturar relaciones no lineales complejas e interacciones entre variables de forma natural, produciendo modelos que son fáciles de interpretar y visualizar.</p>
<section id="motivación-limitaciones-de-los-métodos-lineales" class="level3">
<h3 class="anchored" data-anchor-id="motivación-limitaciones-de-los-métodos-lineales">Motivación: Limitaciones de los Métodos Lineales</h3>
<p>Consideremos un problema donde queremos predecir si un cliente comprará un producto basándonos en su edad y su ingreso. Los métodos lineales (como regresión logística) asumirían que existe una <strong>frontera de decisión lineal</strong>:</p>
<p><span class="math display">\[\beta_0 + \beta_1 \cdot \text{edad} + \beta_2 \cdot \text{ingreso} = 0\]</span></p>
<p>Sin embargo, la realidad puede ser más compleja: tal vez los clientes jóvenes con ingresos altos compran, los clientes mayores con cualquier ingreso compran, pero los clientes jóvenes con ingresos bajos no compran. Esta regla no es lineal y involucra <strong>interacciones</strong> entre variables.</p>
<p>Los árboles de decisión resuelven este problema al <strong>particionar el espacio de características</strong> en regiones rectangulares, donde cada región tiene su propia predicción.</p>
</section>
<section id="estructura-de-un-árbol-de-decisión" class="level3">
<h3 class="anchored" data-anchor-id="estructura-de-un-árbol-de-decisión">Estructura de un Árbol de Decisión</h3>
<p>Un árbol de decisión es una estructura jerárquica compuesta por:</p>
<ol type="1">
<li><strong>Nodo raíz (root node)</strong>: Contiene todos los datos de entrenamiento</li>
<li><strong>Nodos internos (internal nodes)</strong>: Representan decisiones basadas en características</li>
<li><strong>Ramas (branches)</strong>: Representan el resultado de una decisión</li>
<li><strong>Nodos hoja o terminales (leaf nodes)</strong>: Contienen las predicciones finales</li>
</ol>
<p>Cada nodo interno realiza una <strong>pregunta binaria</strong> sobre una característica:</p>
<ul>
<li>“¿Edad ≤ 30?”</li>
<li>“¿Ingreso &gt; $50,000?”</li>
<li>“¿Categoría = A o B?”</li>
</ul>
</section>
<section id="ejemplo-visual-simple" class="level3">
<h3 class="anchored" data-anchor-id="ejemplo-visual-simple">Ejemplo Visual Simple</h3>
<pre><code>                    [Edad ≤ 30?]
                    /           \
                  Sí             No
                 /                 \
        [Ingreso ≤ 40K?]        Compra = Sí
           /         \
         Sí          No
        /             \
   Compra = No    Compra = Sí</code></pre>
<p>Este árbol representa las siguientes reglas:</p>
<ul>
<li>Si edad &gt; 30 → Compra = Sí</li>
<li>Si edad ≤ 30 y ingreso &gt; 40K → Compra = Sí</li>
<li>Si edad ≤ 30 y ingreso ≤ 40K → Compra = No</li>
</ul>
</section>
</section>
<section id="construcción-de-árboles-de-decisión" class="level2">
<h2 class="anchored" data-anchor-id="construcción-de-árboles-de-decisión">Construcción de Árboles de Decisión</h2>
<section id="particionamiento-recursivo-del-espacio" class="level3">
<h3 class="anchored" data-anchor-id="particionamiento-recursivo-del-espacio">Particionamiento Recursivo del Espacio</h3>
<p>Los árboles de decisión construyen su estructura mediante <strong>particionamiento recursivo binario</strong> (recursive binary splitting). Este proceso:</p>
<ol type="1">
<li>Comienza con todos los datos en el nodo raíz</li>
<li>Encuentra la mejor división (variable y punto de corte)</li>
<li>Divide los datos en dos nodos hijos</li>
<li>Repite el proceso recursivamente para cada nodo hijo</li>
<li>Se detiene cuando se cumple un criterio de parada</li>
</ol>
<p>Matemáticamente, el espacio de características <span class="math inline">\(\mathbb{R}^p\)</span> se divide en <span class="math inline">\(M\)</span> regiones disjuntas <span class="math inline">\(R_1, R_2, ..., R_M\)</span> tales que:</p>
<p><span class="math display">\[\bigcup_{m=1}^{M} R_m = \mathbb{R}^p, \quad R_i \cap R_j = \emptyset \text{ para } i \neq j\]</span></p>
<p>Cada región <span class="math inline">\(R_m\)</span> es un <strong>hiperrectángulo</strong> paralelo a los ejes de coordenadas.</p>
</section>
<section id="criterios-de-impureza" class="level3">
<h3 class="anchored" data-anchor-id="criterios-de-impureza">Criterios de Impureza</h3>
<p>Para decidir cómo dividir un nodo, necesitamos medir la <strong>impureza</strong> o <strong>heterogeneidad</strong> de un nodo. Un nodo es “puro” si contiene mayormente ejemplos de una sola clase.</p>
<section id="índice-de-gini" class="level4">
<h4 class="anchored" data-anchor-id="índice-de-gini">1. Índice de Gini</h4>
<p>El <strong>índice de Gini</strong> mide la probabilidad de clasificar incorrectamente un elemento elegido aleatoriamente si se etiqueta aleatoriamente según la distribución de clases del nodo:</p>
<p><span class="math display">\[I_G(t) = \sum_{k=1}^{K} p_k(t) \cdot (1 - p_k(t)) = \sum_{k=1}^{K} p_k(t) - \sum_{k=1}^{K} p_k(t)^2 = 1 - \sum_{k=1}^{K} p_k(t)^2\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(K\)</span> es el número de clases</li>
<li><span class="math inline">\(p_k(t)\)</span> es la proporción de ejemplos de la clase <span class="math inline">\(k\)</span> en el nodo <span class="math inline">\(t\)</span></li>
</ul>
<p><strong>Propiedades del índice de Gini:</strong></p>
<ul>
<li><strong>Mínimo</strong> (<span class="math inline">\(I_G = 0\)</span>): Nodo puro (una sola clase)
<ul>
<li>Ejemplo: Si <span class="math inline">\(p_1 = 1, p_2 = 0\)</span> → <span class="math inline">\(I_G = 1 - (1^2 + 0^2) = 0\)</span></li>
</ul></li>
<li><strong>Máximo</strong> (cuando las clases están balanceadas):
<ul>
<li>Para 2 clases con <span class="math inline">\(p_1 = p_2 = 0.5\)</span> → <span class="math inline">\(I_G = 1 - (0.5^2 + 0.5^2) = 0.5\)</span></li>
<li>Para <span class="math inline">\(K\)</span> clases con <span class="math inline">\(p_k = 1/K\)</span> → <span class="math inline">\(I_G = 1 - K(1/K)^2 = (K-1)/K\)</span></li>
</ul></li>
</ul>
</section>
<section id="entropía" class="level4">
<h4 class="anchored" data-anchor-id="entropía">2. Entropía</h4>
<p>La <strong>entropía</strong> mide el desorden o incertidumbre en un nodo, basada en la teoría de la información:</p>
<p><span class="math display">\[H(t) = -\sum_{k=1}^{K} p_k(t) \log_2(p_k(t))\]</span></p>
<p>Por convención, <span class="math inline">\(0 \log(0) = 0\)</span>.</p>
<p><strong>Propiedades de la entropía:</strong></p>
<ul>
<li><strong>Mínimo</strong> (<span class="math inline">\(H = 0\)</span>): Nodo puro (certidumbre completa)</li>
<li><strong>Máximo</strong> (<span class="math inline">\(H = \log_2(K)\)</span>): Clases uniformemente distribuidas (máxima incertidumbre)
<ul>
<li>Para 2 clases: <span class="math inline">\(H_{\max} = 1\)</span> bit</li>
<li>Para 4 clases: <span class="math inline">\(H_{\max} = 2\)</span> bits</li>
</ul></li>
</ul>
<p><strong>Ganancia de Información (Information Gain):</strong></p>
<p>La ganancia de información mide la reducción en entropía al realizar una división:</p>
<p><span class="math display">\[IG = H(t_{\text{padre}}) - \sum_{i \in \{\text{izq, der}\}} \frac{n_i}{n} H(t_i)\]</span></p>
<p>Donde <span class="math inline">\(n_i\)</span> es el número de ejemplos en el nodo hijo <span class="math inline">\(i\)</span> y <span class="math inline">\(n\)</span> es el total en el nodo padre.</p>
</section>
<section id="error-de-clasificación" class="level4">
<h4 class="anchored" data-anchor-id="error-de-clasificación">3. Error de Clasificación</h4>
<p>El <strong>error de clasificación</strong> es la tasa de ejemplos que no pertenecen a la clase mayoritaria:</p>
<p><span class="math display">\[E(t) = 1 - \max_k p_k(t)\]</span></p>
<p>Este criterio es menos sensible a cambios en la distribución de clases y se usa menos en la práctica.</p>
</section>
</section>
<section id="comparación-visual-de-criterios-de-impureza" class="level3">
<h3 class="anchored" data-anchor-id="comparación-visual-de-criterios-de-impureza">Comparación Visual de Criterios de Impureza</h3>
<div id="cell-impurity-comparison" class="cell" data-fig-height="6" data-fig-width="10" data-execution_count="1">
<div class="cell-output cell-output-display">
<div id="impurity-comparison" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-arboles_files/figure-html/impurity-comparison-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Comparación de criterios de impureza para clasificación binaria</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Valores de impureza en puntos clave:
============================================================
Proporción p    Gini         Entropía     Error       
------------------------------------------------------------
0.0             0.0000       0.0000       0.0000      
0.1             0.1800       0.4690       0.1000      
0.3             0.4200       0.8813       0.3000      
0.5             0.5000       1.0000       0.5000      
0.7             0.4200       0.8813       0.3000      
0.9             0.1800       0.4690       0.1000      
1.0             0.0000       0.0000       0.0000      </code></pre>
</div>
</div>
<p><strong>Observaciones:</strong></p>
<ol type="1">
<li><strong>Gini y Entropía</strong> son muy similares en comportamiento y suelen dar resultados comparables</li>
<li><strong>Error de clasificación</strong> es menos sensible a cambios en las probabilidades</li>
<li>En la práctica, Gini es más común por ser más eficiente computacionalmente</li>
<li>Todas alcanzan su máximo cuando las clases están balanceadas (<span class="math inline">\(p = 0.5\)</span>)</li>
</ol>
</section>
<section id="algoritmo-de-construcción-cart" class="level3">
<h3 class="anchored" data-anchor-id="algoritmo-de-construcción-cart">Algoritmo de Construcción CART</h3>
<p>El algoritmo <strong>CART</strong> (Classification And Regression Trees) es el método más común para construir árboles de decisión:</p>
<p><strong>Algoritmo: Construcción Greedy de Árbol de Decisión</strong></p>
<pre><code>función CONSTRUIR_ARBOL(datos, profundidad_actual, max_profundidad):
    // Criterios de parada
    si profundidad_actual &gt;= max_profundidad O
       nodo es puro O
       número de muestras &lt; min_muestras:
        crear nodo hoja con predicción mayoritaria
        retornar

    // Encontrar mejor división
    mejor_ganancia = -infinito

    para cada característica j en {1, ..., p}:
        para cada posible punto de corte c:
            dividir datos en: {x_j ≤ c} y {x_j &gt; c}
            calcular impureza ponderada de los nodos hijos
            calcular ganancia = impureza_padre - impureza_hijos

            si ganancia &gt; mejor_ganancia:
                mejor_ganancia = ganancia
                mejor_característica = j
                mejor_corte = c

    // Crear división
    crear nodo interno con pregunta: "x[mejor_característica] ≤ mejor_corte?"
    datos_izq = datos donde x[mejor_característica] ≤ mejor_corte
    datos_der = datos donde x[mejor_característica] &gt; mejor_corte

    // Recursión
    hijo_izquierdo = CONSTRUIR_ARBOL(datos_izq, profundidad_actual + 1, max_profundidad)
    hijo_derecho = CONSTRUIR_ARBOL(datos_der, profundidad_actual + 1, max_profundidad)

    retornar nodo_actual</code></pre>
<p><strong>Características clave del algoritmo:</strong></p>
<ol type="1">
<li><strong>Greedy (Voraz)</strong>: En cada paso, elige la mejor división local sin considerar divisiones futuras</li>
<li><strong>Top-down</strong>: Construye desde la raíz hacia las hojas</li>
<li><strong>Recursivo</strong>: Aplica el mismo proceso a cada subárbol</li>
<li><strong>Binario</strong>: Cada división genera exactamente dos nodos hijos</li>
</ol>
</section>
<section id="ejemplo-construcción-paso-a-paso" class="level3">
<h3 class="anchored" data-anchor-id="ejemplo-construcción-paso-a-paso">Ejemplo: Construcción Paso a Paso</h3>
<div id="tree-construction-example" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar datos sintéticos simples (2D para visualización)</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    n_redundant<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    n_clusters_per_class<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    flip_y<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    class_sep<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear DataFrame para mejor visualización</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>[<span class="st">'X1'</span>, <span class="st">'X2'</span>])</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Clase'</span>] <span class="op">=</span> y</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Datos de ejemplo:"</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head(<span class="dv">10</span>))</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total de muestras: </span><span class="sc">{</span><span class="bu">len</span>(df)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Clases: </span><span class="sc">{</span>df[<span class="st">'Clase'</span>]<span class="sc">.</span>value_counts()<span class="sc">.</span>to_dict()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Datos de ejemplo:
============================================================
         X1        X2  Clase
0  1.122201 -3.621909      0
1  2.055968  3.471449      1
2  1.626547 -0.708767      0
3  2.238265  2.357568      1
4  1.010960  2.377681      1
5  0.095620  2.794548      1
6  0.700506  1.005135      1
7  1.873085  2.558868      1
8  1.076216  1.470596      1
9  2.176681  0.741384      1

Total de muestras: 200
Clases: {1: 101, 0: 99}</code></pre>
</div>
</div>
<div id="cell-tree-depths-comparison" class="cell" data-fig-height="10" data-fig-width="14" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar árboles con diferentes profundidades</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>profundidades <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>]</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.ravel()</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, depth <span class="kw">in</span> <span class="bu">enumerate</span>(profundidades):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Entrenar árbol</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    tree <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span>depth,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span><span class="st">'gini'</span>,</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    tree.fit(X, y)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualizar árbol</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    plot_tree(</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        tree,</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        ax<span class="op">=</span>axes[idx],</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        feature_names<span class="op">=</span>[<span class="st">'X1'</span>, <span class="st">'X2'</span>],</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        class_names<span class="op">=</span>[<span class="st">'Clase 0'</span>, <span class="st">'Clase 1'</span>],</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        filled<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        rounded<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">9</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcular accuracy en entrenamiento</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    train_accuracy <span class="op">=</span> tree.score(X, y)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    axes[idx].set_title(</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f'Profundidad = </span><span class="sc">{</span>depth<span class="sc">}</span><span class="ss"> | Accuracy = </span><span class="sc">{</span>train_accuracy<span class="sc">:.3f}</span><span class="ss">'</span>,</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        pad<span class="op">=</span><span class="dv">10</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar información detallada del árbol más complejo</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"INFORMACIÓN DEL ÁRBOL (Profundidad = 5)"</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>tree_detailed <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>tree_detailed.fit(X, y)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Número de nodos: </span><span class="sc">{</span>tree_detailed<span class="sc">.</span>tree_<span class="sc">.</span>node_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Número de hojas: </span><span class="sc">{</span>tree_detailed<span class="sc">.</span>get_n_leaves()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Profundidad real: </span><span class="sc">{</span>tree_detailed<span class="sc">.</span>get_depth()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy en entrenamiento: </span><span class="sc">{</span>tree_detailed<span class="sc">.</span>score(X, y)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="tree-depths-comparison" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-arboles_files/figure-html/tree-depths-comparison-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Comparación de árboles con diferentes profundidades</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
INFORMACIÓN DEL ÁRBOL (Profundidad = 5)
============================================================
Número de nodos: 41
Número de hojas: 21
Profundidad real: 5
Accuracy en entrenamiento: 0.950</code></pre>
</div>
</div>
<div id="cell-decision-boundaries" class="cell" data-fig-height="10" data-fig-width="14" data-execution_count="4">
<div class="cell-output cell-output-display">
<div id="decision-boundaries" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-arboles_files/figure-html/decision-boundaries-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Fronteras de decisión para diferentes profundidades de árbol</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Observaciones importantes:</strong></p>
<ol type="1">
<li><strong>Profundidad = 1</strong> (stump): Una sola división, frontera muy simple</li>
<li><strong>Profundidad = 2-3</strong>: Capturas las principales regiones de decisión</li>
<li><strong>Profundidad = 5</strong>: Frontera muy compleja, posible sobreajuste</li>
<li>Las fronteras son siempre <strong>paralelas a los ejes</strong> (particiones rectangulares)</li>
</ol>
</section>
</section>
<section id="sobreajuste-y-control-de-complejidad" class="level2">
<h2 class="anchored" data-anchor-id="sobreajuste-y-control-de-complejidad">Sobreajuste y Control de Complejidad</h2>
<section id="el-problema-del-sobreajuste" class="level3">
<h3 class="anchored" data-anchor-id="el-problema-del-sobreajuste">El Problema del Sobreajuste</h3>
<p>Los árboles de decisión tienen una tendencia natural al <strong>sobreajuste</strong> (overfitting). Sin restricciones, un árbol puede crecer hasta que cada nodo hoja contenga un solo ejemplo, logrando 100% de accuracy en entrenamiento pero generalizando muy mal.</p>
<p><strong>Causas del sobreajuste:</strong></p>
<ol type="1">
<li><strong>Alta varianza</strong>: Pequeños cambios en los datos pueden producir árboles muy diferentes</li>
<li><strong>Falta de regularización inherente</strong>: Sin restricciones, el árbol memoriza los datos</li>
<li><strong>Captura de ruido</strong>: El árbol aprende patrones específicos del conjunto de entrenamiento</li>
</ol>
</section>
<section id="estrategias-de-control-de-complejidad" class="level3">
<h3 class="anchored" data-anchor-id="estrategias-de-control-de-complejidad">Estrategias de Control de Complejidad</h3>
<section id="pre-poda-pre-pruning" class="level4">
<h4 class="anchored" data-anchor-id="pre-poda-pre-pruning">1. Pre-Poda (Pre-Pruning)</h4>
<p>La <strong>pre-poda</strong> detiene el crecimiento del árbol durante su construcción mediante criterios:</p>
<p><strong>Hiperparámetros comunes:</strong></p>
<ul>
<li><code>max_depth</code>: Profundidad máxima del árbol
<ul>
<li>Valores típicos: 3-10</li>
<li>Menor → Más sesgo, menos varianza</li>
</ul></li>
<li><code>min_samples_split</code>: Mínimo de muestras para dividir un nodo
<ul>
<li>Valores típicos: 2-20</li>
<li>Mayor → Árbol más pequeño</li>
</ul></li>
<li><code>min_samples_leaf</code>: Mínimo de muestras en una hoja
<ul>
<li>Valores típicos: 1-10</li>
<li>Mayor → Hojas más confiables</li>
</ul></li>
<li><code>max_features</code>: Número máximo de características a considerar por división
<ul>
<li><code>'sqrt'</code>: √p características (usado en Random Forest)</li>
<li><code>'log2'</code>: log₂(p) características</li>
<li><code>None</code>: Todas las características</li>
</ul></li>
<li><code>max_leaf_nodes</code>: Número máximo de nodos hoja
<ul>
<li>Controla directamente el tamaño del árbol</li>
</ul></li>
</ul>
</section>
<section id="post-poda-post-pruning" class="level4">
<h4 class="anchored" data-anchor-id="post-poda-post-pruning">2. Post-Poda (Post-Pruning)</h4>
<p>La <strong>post-poda</strong> construye un árbol completo y luego lo reduce eliminando nodos que no aportan suficiente mejora.</p>
<p><strong>Cost-Complexity Pruning (Poda por Costo-Complejidad):</strong></p>
<p>Define una función de costo que balancea error y complejidad:</p>
<p><span class="math display">\[C_\alpha(T) = \sum_{m=1}^{|T|} \sum_{i: x_i \in R_m} L(y_i, \hat{y}_m) + \alpha |T|\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(|T|\)</span> es el número de nodos hoja</li>
<li><span class="math inline">\(\alpha \geq 0\)</span> es el parámetro de complejidad</li>
<li><span class="math inline">\(L\)</span> es la función de pérdida</li>
<li><span class="math inline">\(\hat{y}_m\)</span> es la predicción en el nodo hoja <span class="math inline">\(m\)</span></li>
</ul>
<p><strong>Efecto de <span class="math inline">\(\alpha\)</span>:</strong></p>
<ul>
<li><span class="math inline">\(\alpha = 0\)</span>: Árbol completo (sin poda)</li>
<li><span class="math inline">\(\alpha\)</span> grande: Árbol muy pequeño (mayor regularización)</li>
</ul>
<div id="cell-pruning-demonstration" class="cell" data-fig-height="5" data-fig-width="14" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Dividir datos</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar árbol completo</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>tree_full <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>tree_full.fit(X_train, y_train)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtener camino de cost-complexity pruning</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> tree_full.cost_complexity_pruning_path(X_train, y_train)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>ccp_alphas <span class="op">=</span> path.ccp_alphas</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>impurities <span class="op">=</span> path.impurities</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cost-Complexity Pruning Path:"</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Número de valores de alpha: </span><span class="sc">{</span><span class="bu">len</span>(ccp_alphas)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Rango de alpha: [</span><span class="sc">{</span>ccp_alphas[<span class="dv">0</span>]<span class="sc">:.6f}</span><span class="ss">, </span><span class="sc">{</span>ccp_alphas[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.6f}</span><span class="ss">]"</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar árboles para diferentes valores de alpha</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>n_leaves <span class="op">=</span> []</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>depths <span class="op">=</span> []</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> ccp_alphas:</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    tree <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>, ccp_alpha<span class="op">=</span>alpha)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    tree.fit(X_train, y_train)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    train_scores.append(tree.score(X_train, y_train))</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    test_scores.append(tree.score(X_test, y_test))</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    n_leaves.append(tree.get_n_leaves())</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    depths.append(tree.get_depth())</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">4</span>))</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel 1: Accuracy vs Alpha</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(ccp_alphas, train_scores, label<span class="op">=</span><span class="st">'Entrenamiento'</span>,</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>             marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(ccp_alphas, test_scores, label<span class="op">=</span><span class="st">'Prueba'</span>,</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>             marker<span class="op">=</span><span class="st">'s'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Alpha (ccp_alpha)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Accuracy vs Alpha'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Encontrar mejor alpha</span></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>best_idx <span class="op">=</span> np.argmax(test_scores)</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>best_alpha <span class="op">=</span> ccp_alphas[best_idx]</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axvline(x<span class="op">=</span>best_alpha, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>,</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="ss">f'Mejor α = </span><span class="sc">{</span>best_alpha<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel 2: Número de hojas vs Alpha</span></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(ccp_alphas, n_leaves, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Alpha (ccp_alpha)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Número de Hojas'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Complejidad del Árbol vs Alpha'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axvline(x<span class="op">=</span>best_alpha, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel 3: Profundidad vs Alpha</span></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].plot(ccp_alphas, depths, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'purple'</span>)</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Alpha (ccp_alpha)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Profundidad del Árbol'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Profundidad vs Alpha'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].axvline(x<span class="op">=</span>best_alpha, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARACIÓN: Árbol sin poda vs Árbol podado"</span>)</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Árbol sin poda (α = 0):"</span>)</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Hojas: </span><span class="sc">{</span>n_leaves[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Profundidad: </span><span class="sc">{</span>depths[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Accuracy entrenamiento: </span><span class="sc">{</span>train_scores[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Accuracy prueba: </span><span class="sc">{</span>test_scores[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Árbol podado óptimo (α = </span><span class="sc">{</span>best_alpha<span class="sc">:.4f}</span><span class="ss">):"</span>)</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Hojas: </span><span class="sc">{</span>n_leaves[best_idx]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Profundidad: </span><span class="sc">{</span>depths[best_idx]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Accuracy entrenamiento: </span><span class="sc">{</span>train_scores[best_idx]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Accuracy prueba: </span><span class="sc">{</span>test_scores[best_idx]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cost-Complexity Pruning Path:
============================================================
Número de valores de alpha: 13
Rango de alpha: [0.000000, 0.309700]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="pruning-demonstration" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-arboles_files/figure-html/pruning-demonstration-output-2.png" class="img-fluid figure-img"></p>
<figcaption>Efecto de la poda en el desempeño del árbol</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
COMPARACIÓN: Árbol sin poda vs Árbol podado
============================================================

Árbol sin poda (α = 0):
  Hojas: 24
  Profundidad: 10
  Accuracy entrenamiento: 1.000
  Accuracy prueba: 0.850

Árbol podado óptimo (α = 0.0129):
  Hojas: 4
  Profundidad: 3
  Accuracy entrenamiento: 0.907
  Accuracy prueba: 0.883</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="interpretabilidad-y-análisis" class="level2">
<h2 class="anchored" data-anchor-id="interpretabilidad-y-análisis">Interpretabilidad y Análisis</h2>
<section id="importancia-de-variables" class="level3">
<h3 class="anchored" data-anchor-id="importancia-de-variables">Importancia de Variables</h3>
<p>Una de las grandes ventajas de los árboles es que podemos medir la <strong>importancia</strong> de cada variable basándonos en cuánto reduce la impureza:</p>
<p><span class="math display">\[\text{Importancia}(X_j) = \sum_{t: \text{usa } X_j} \frac{n_t}{n} \cdot \Delta I(t)\]</span></p>
<p>Donde: - <span class="math inline">\(n_t\)</span> es el número de muestras en el nodo <span class="math inline">\(t\)</span> - <span class="math inline">\(n\)</span> es el número total de muestras - <span class="math inline">\(\Delta I(t)\)</span> es la reducción en impureza por la división en el nodo <span class="math inline">\(t\)</span></p>
<div id="cell-feature-importance" class="cell" data-fig-height="5" data-fig-width="12" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar árbol en dataset con más características</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar datos con 10 características</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>X_multi, y_multi <span class="op">=</span> make_classification(</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    n_redundant<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    n_repeated<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Nombres de características</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> [<span class="ss">f'X</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar árbol</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>tree_multi <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>tree_multi.fit(X_multi, y_multi)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtener importancias</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>importances <span class="op">=</span> tree_multi.feature_importances_</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.argsort(importances)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel 1: Gráfico de barras</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].barh(<span class="bu">range</span>(<span class="dv">10</span>), importances[indices], color<span class="op">=</span><span class="st">'steelblue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_yticks(<span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_yticklabels([feature_names[i] <span class="cf">for</span> i <span class="kw">in</span> indices])</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Importancia'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Importancia de Variables (Reducción de Impureza)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Añadir valores</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (idx, imp) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(indices, importances[indices])):</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].text(imp <span class="op">+</span> <span class="fl">0.005</span>, i, <span class="ss">f'</span><span class="sc">{</span>imp<span class="sc">:.3f}</span><span class="ss">'</span>, va<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel 2: Importancia acumulada</span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>cumsum_importance <span class="op">=</span> np.cumsum(importances[indices])</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>), cumsum_importance, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>,</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>             markersize<span class="op">=</span><span class="dv">8</span>, color<span class="op">=</span><span class="st">'darkgreen'</span>)</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].fill_between(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>), cumsum_importance, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(y<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="st">'80</span><span class="sc">% d</span><span class="st">e importancia'</span>)</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(y<span class="op">=</span><span class="fl">0.95</span>, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="st">'95</span><span class="sc">% d</span><span class="st">e importancia'</span>)</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Número de Variables'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Importancia Acumulada'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Importancia Acumulada de Variables'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticks(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>))</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimir tabla de importancias</span></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Tabla de Importancias:"</span>)</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Variable'</span><span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Importancia'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Importancia Acum.'</span><span class="sc">:&lt;20}</span><span class="ss">"</span>)</span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>cumsum <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> indices:</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>    cumsum <span class="op">+=</span> importances[idx]</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature_names[idx]<span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span>importances[idx]<span class="sc">:&lt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>cumsum<span class="sc">:&lt;20.4f}</span><span class="ss">"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="feature-importance" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-arboles_files/figure-html/feature-importance-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Importancia de variables en árbol de decisión</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Tabla de Importancias:
============================================================
Variable     Importancia     Importancia Acum.   
------------------------------------------------------------
X1           0.3599          0.3599              
X6           0.1732          0.5331              
X8           0.1130          0.6462              
X2           0.0921          0.7383              
X5           0.0771          0.8154              
X10          0.0768          0.8921              
X9           0.0514          0.9436              
X4           0.0385          0.9821              
X7           0.0134          0.9955              
X3           0.0045          1.0000              </code></pre>
</div>
</div>
</section>
<section id="extracción-de-reglas" class="level3">
<h3 class="anchored" data-anchor-id="extracción-de-reglas">Extracción de Reglas</h3>
<p>Los árboles pueden convertirse en reglas IF-THEN interpretables:</p>
<div id="tree-rules" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> export_text</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar árbol simple para mejor interpretabilidad</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>tree_simple <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">3</span>, min_samples_leaf<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>tree_simple.fit(X[:, :<span class="dv">2</span>], y)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Exportar reglas como texto</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>tree_rules <span class="op">=</span> export_text(tree_simple, feature_names<span class="op">=</span>[<span class="st">'X1'</span>, <span class="st">'X2'</span>])</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"REGLAS DE DECISIÓN DEL ÁRBOL:"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tree_rules)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para extraer rutas de decisión</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_decision_path(tree, feature_names, sample):</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extrae la ruta de decisión para una muestra"""</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    node <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> []</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> tree.tree_.feature[node] <span class="op">!=</span> <span class="op">-</span><span class="dv">2</span>:  <span class="co"># -2 indica nodo hoja</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        feature_idx <span class="op">=</span> tree.tree_.feature[node]</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        threshold <span class="op">=</span> tree.tree_.threshold[node]</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sample[feature_idx] <span class="op">&lt;=</span> threshold:</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>            direction <span class="op">=</span> <span class="st">"&lt;="</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>            node <span class="op">=</span> tree.tree_.children_left[node]</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>            direction <span class="op">=</span> <span class="st">"&gt;"</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>            node <span class="op">=</span> tree.tree_.children_right[node]</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>        path.append(<span class="ss">f"</span><span class="sc">{</span>feature_names[feature_idx]<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>direction<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>threshold<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtener predicción</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    class_probs <span class="op">=</span> tree.tree_.value[node][<span class="dv">0</span>]</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    predicted_class <span class="op">=</span> np.argmax(class_probs)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> path, predicted_class, class_probs</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejemplo: explicar predicción para algunas muestras</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"EXPLICACIÓN DE PREDICCIONES"</span>)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> X[i, :<span class="dv">2</span>]</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    path, pred_class, probs <span class="op">=</span> get_decision_path(tree_simple, [<span class="st">'X1'</span>, <span class="st">'X2'</span>], sample)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Muestra </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: X1=</span><span class="sc">{</span>sample[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, X2=</span><span class="sc">{</span>sample[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Clase real: </span><span class="sc">{</span>y[i]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Predicción: </span><span class="sc">{</span>pred_class<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Probabilidades: Clase 0 = </span><span class="sc">{</span>probs[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, Clase 1 = </span><span class="sc">{</span>probs[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Ruta de decisión:"</span>)</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> step <span class="kw">in</span> path:</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  → </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>REGLAS DE DECISIÓN DEL ÁRBOL:
============================================================
|--- X2 &lt;= 0.31
|   |--- X1 &lt;= 1.07
|   |   |--- X2 &lt;= -0.96
|   |   |   |--- class: 0
|   |   |--- X2 &gt;  -0.96
|   |   |   |--- class: 0
|   |--- X1 &gt;  1.07
|   |   |--- X2 &lt;= -2.17
|   |   |   |--- class: 0
|   |   |--- X2 &gt;  -2.17
|   |   |   |--- class: 0
|--- X2 &gt;  0.31
|   |--- X1 &lt;= 1.07
|   |   |--- X2 &lt;= 1.20
|   |   |   |--- class: 1
|   |   |--- X2 &gt;  1.20
|   |   |   |--- class: 1
|   |--- X1 &gt;  1.07
|   |   |--- X2 &lt;= 0.82
|   |   |   |--- class: 1
|   |   |--- X2 &gt;  0.82
|   |   |   |--- class: 1


============================================================
EXPLICACIÓN DE PREDICCIONES
============================================================

Muestra 1: X1=1.122, X2=-3.622
Clase real: 0
Predicción: 0
Probabilidades: Clase 0 = 0.800, Clase 1 = 0.200
Ruta de decisión:
  → X2 &lt;= 0.315
  → X1 &gt; 1.072
  → X2 &lt;= -2.166

Muestra 2: X1=2.056, X2=3.471
Clase real: 1
Predicción: 1
Probabilidades: Clase 0 = 0.018, Clase 1 = 0.982
Ruta de decisión:
  → X2 &gt; 0.315
  → X1 &gt; 1.066
  → X2 &gt; 0.821

Muestra 3: X1=1.627, X2=-0.709
Clase real: 0
Predicción: 0
Probabilidades: Clase 0 = 0.961, Clase 1 = 0.039
Ruta de decisión:
  → X2 &lt;= 0.315
  → X1 &gt; 1.072
  → X2 &gt; -2.166</code></pre>
</div>
</div>
</section>
</section>
<section id="ventajas-y-desventajas" class="level2">
<h2 class="anchored" data-anchor-id="ventajas-y-desventajas">Ventajas y Desventajas</h2>
<section id="ventajas-de-los-árboles-de-decisión" class="level3">
<h3 class="anchored" data-anchor-id="ventajas-de-los-árboles-de-decisión">Ventajas de los Árboles de Decisión</h3>
<ol type="1">
<li><p><strong>Interpretabilidad</strong>: Fáciles de entender y explicar, incluso para no expertos</p>
<ul>
<li>Se pueden visualizar completamente</li>
<li>Generan reglas IF-THEN interpretables</li>
</ul></li>
<li><p><strong>Manejo de variables mixtas</strong>: Pueden manejar características numéricas y categóricas sin preprocesamiento</p></li>
<li><p><strong>No requieren normalización</strong>: Las decisiones son invariantes a transformaciones monótonas</p></li>
<li><p><strong>Capturan interacciones automáticamente</strong>: Detectan interacciones sin especificarlas explícitamente</p></li>
<li><p><strong>Robustos a outliers</strong>: Las divisiones son basadas en rankings, no en valores absolutos</p></li>
<li><p><strong>Selección implícita de características</strong>: Variables irrelevantes no se usan en las divisiones</p></li>
</ol>
</section>
<section id="desventajas-de-los-árboles-de-decisión" class="level3">
<h3 class="anchored" data-anchor-id="desventajas-de-los-árboles-de-decisión">Desventajas de los Árboles de Decisión</h3>
<ol type="1">
<li><p><strong>Alta varianza</strong>: Pequeños cambios en datos → árboles muy diferentes</p>
<ul>
<li>Solución: Métodos ensemble (Random Forest, Gradient Boosting)</li>
</ul></li>
<li><p><strong>Dificultad con relaciones lineales</strong>: Necesitan muchas divisiones para aproximar funciones lineales</p></li>
<li><p><strong>Fronteras de decisión restrictivas</strong>: Solo particiones rectangulares paralelas a los ejes</p></li>
<li><p><strong>Sesgo hacia variables con muchos valores</strong>: Tienden a seleccionar variables con más opciones de corte</p></li>
<li><p><strong>Inestabilidad</strong>: Pequeñas variaciones pueden cambiar completamente la estructura</p></li>
<li><p><strong>Sobreajuste natural</strong>: Sin restricciones, memorizan los datos de entrenamiento</p></li>
</ol>
</section>
<section id="comparación-visual-árbol-vs-regresión-logística" class="level3">
<h3 class="anchored" data-anchor-id="comparación-visual-árbol-vs-regresión-logística">Comparación Visual: Árbol vs Regresión Logística</h3>
<div id="cell-tree-vs-logistic" class="cell" data-fig-height="5" data-fig-width="14" data-execution_count="8">
<div class="cell-output cell-output-display">
<div id="tree-vs-logistic" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-arboles_files/figure-html/tree-vs-logistic-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Comparación de fronteras de decisión: Árbol vs Regresión Logística</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Observaciones:
============================================================
- Regresión logística captura mejor la relación lineal subyacente
- Árbol de decisión crea fronteras rectangulares que aproximan la línea
- Para relaciones lineales, la regresión logística es más eficiente
- Para relaciones no lineales, los árboles son más flexibles</code></pre>
</div>
</div>
</section>
</section>
<section id="aplicación-práctica-dataset-real" class="level2">
<h2 class="anchored" data-anchor-id="aplicación-práctica-dataset-real">Aplicación Práctica: Dataset Real</h2>
<div id="real-dataset-application" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score, GridSearchCV</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar dataset</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>cancer <span class="op">=</span> load_breast_cancer()</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>X_cancer <span class="op">=</span> cancer.data</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>y_cancer <span class="op">=</span> cancer.target</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"DATASET: Wisconsin Breast Cancer"</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Número de muestras: </span><span class="sc">{</span>X_cancer<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Número de características: </span><span class="sc">{</span>X_cancer<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Clases: </span><span class="sc">{</span>cancer<span class="sc">.</span>target_names<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distribución: </span><span class="sc">{</span>np<span class="sc">.</span>bincount(y_cancer)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Dividir datos</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>X_train_c, X_test_c, y_train_c, y_test_c <span class="op">=</span> train_test_split(</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    X_cancer, y_cancer, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_cancer</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Árbol sin regularización</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>tree_unreg <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>tree_unreg.fit(X_train_c, y_train_c)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. ÁRBOL SIN REGULARIZACIÓN"</span>)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Profundidad: </span><span class="sc">{</span>tree_unreg<span class="sc">.</span>get_depth()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Número de hojas: </span><span class="sc">{</span>tree_unreg<span class="sc">.</span>get_n_leaves()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy entrenamiento: </span><span class="sc">{</span>tree_unreg<span class="sc">.</span>score(X_train_c, y_train_c)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy prueba: </span><span class="sc">{</span>tree_unreg<span class="sc">.</span>score(X_test_c, y_test_c)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Búsqueda de hiperparámetros óptimos</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>, <span class="va">None</span>],</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>],</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">'criterion'</span>: [<span class="st">'gini'</span>, <span class="st">'entropy'</span>]</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. BÚSQUEDA DE HIPERPARÁMETROS (Grid Search)"</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Evaluando combinaciones de hiperparámetros con CV..."</span>)</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train_c, y_train_c)</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mejor combinación de parámetros:"</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param, value <span class="kw">in</span> grid_search.best_params_.items():</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>param<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Evaluar mejor modelo</span></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>best_tree <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. MEJOR ÁRBOL (después de optimización)"</span>)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Profundidad: </span><span class="sc">{</span>best_tree<span class="sc">.</span>get_depth()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Número de hojas: </span><span class="sc">{</span>best_tree<span class="sc">.</span>get_n_leaves()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy entrenamiento: </span><span class="sc">{</span>best_tree<span class="sc">.</span>score(X_train_c, y_train_c)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy prueba: </span><span class="sc">{</span>best_tree<span class="sc">.</span>score(X_test_c, y_test_c)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Validación cruzada</span></span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>cv_scores <span class="op">=</span> cross_val_score(best_tree, X_train_c, y_train_c, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Validación cruzada (5-fold):"</span>)</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Scores: </span><span class="sc">{</span>cv_scores<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Media: </span><span class="sc">{</span>cv_scores<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss"> (+/- </span><span class="sc">{</span>cv_scores<span class="sc">.</span>std()<span class="sc">:.3f}</span><span class="ss">)"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DATASET: Wisconsin Breast Cancer
============================================================
Número de muestras: 569
Número de características: 30
Clases: ['malignant' 'benign']
Distribución: [212 357]

1. ÁRBOL SIN REGULARIZACIÓN
------------------------------------------------------------
Profundidad: 6
Número de hojas: 16
Accuracy entrenamiento: 1.000
Accuracy prueba: 0.918

2. BÚSQUEDA DE HIPERPARÁMETROS (Grid Search)
------------------------------------------------------------
Evaluando combinaciones de hiperparámetros con CV...
Mejor combinación de parámetros:
  criterion: gini
  max_depth: 3
  min_samples_leaf: 2
  min_samples_split: 2

3. MEJOR ÁRBOL (después de optimización)
------------------------------------------------------------
Profundidad: 3
Número de hojas: 7
Accuracy entrenamiento: 0.980
Accuracy prueba: 0.924

Validación cruzada (5-fold):
  Scores: [0.9        0.95       0.9        0.97468354 1.        ]
  Media: 0.945 (+/- 0.040)</code></pre>
</div>
</div>
<div id="cell-cancer-feature-importance" class="cell" data-fig-height="6" data-fig-width="10" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importancia de características</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>importances_cancer <span class="op">=</span> best_tree.feature_importances_</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>indices_cancer <span class="op">=</span> np.argsort(importances_cancer)[::<span class="op">-</span><span class="dv">1</span>][:<span class="dv">10</span>]  <span class="co"># Top 10</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.barh(<span class="bu">range</span>(<span class="dv">10</span>), importances_cancer[indices_cancer], color<span class="op">=</span><span class="st">'coral'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="dv">10</span>), [cancer.feature_names[i] <span class="cf">for</span> i <span class="kw">in</span> indices_cancer])</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importancia (Reducción de Impureza)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 10 Características Más Importantes'</span>, fontsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Añadir valores</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, imp <span class="kw">in</span> <span class="bu">enumerate</span>(importances_cancer[indices_cancer]):</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    plt.text(imp <span class="op">+</span> <span class="fl">0.005</span>, i, <span class="ss">f'</span><span class="sc">{</span>imp<span class="sc">:.3f}</span><span class="ss">'</span>, va<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="cancer-feature-importance" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-arboles_files/figure-html/cancer-feature-importance-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Top 10 características más importantes para clasificar cáncer de mama</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="conclusiones-y-mejores-prácticas" class="level2">
<h2 class="anchored" data-anchor-id="conclusiones-y-mejores-prácticas">Conclusiones y Mejores Prácticas</h2>
<section id="recomendaciones-para-usar-árboles-de-decisión" class="level3">
<h3 class="anchored" data-anchor-id="recomendaciones-para-usar-árboles-de-decisión">Recomendaciones para Usar Árboles de Decisión</h3>
<ol type="1">
<li><p><strong>Comienza simple</strong>: Empieza con árboles poco profundos (max_depth=3-5)</p></li>
<li><p><strong>Usa validación cruzada</strong>: Para seleccionar hiperparámetros óptimos</p></li>
<li><p><strong>Considera la interpretabilidad</strong>: Si necesitas explicar decisiones, mantén árboles pequeños</p></li>
<li><p><strong>Combina con ensemble</strong>: Para producción, considera Random Forest o Gradient Boosting</p></li>
<li><p><strong>Analiza importancia de variables</strong>: Para entender qué características son relevantes</p></li>
<li><p><strong>Visualiza el árbol</strong>: Ayuda a detectar problemas y entender el modelo</p></li>
<li><p><strong>Compara con baselines</strong>: Árbol vs regresión logística en datos lineales</p></li>
</ol>
</section>
<section id="cuándo-usar-árboles-de-decisión" class="level3">
<h3 class="anchored" data-anchor-id="cuándo-usar-árboles-de-decisión">Cuándo Usar Árboles de Decisión</h3>
<p><strong>Usar árboles cuando:</strong> - Necesitas interpretabilidad - Tienes interacciones complejas entre variables - Variables numéricas y categóricas mezcladas - Outliers en los datos - Recursos computacionales limitados (árboles son rápidos)</p>
<p><strong>Evitar árboles individuales cuando:</strong> - Datos con relaciones predominantemente lineales - Necesitas el mejor desempeño predictivo (usar ensemble) - Tienes muy pocos datos (alta varianza) - Variables con muchas categorías (sesgo en selección)</p>
</section>
<section id="próximos-pasos-métodos-ensemble" class="level3">
<h3 class="anchored" data-anchor-id="próximos-pasos-métodos-ensemble">Próximos Pasos: Métodos Ensemble</h3>
<p>Los árboles individuales tienen limitaciones, pero combinándolos podemos crear modelos extremadamente poderosos:</p>
<ol type="1">
<li><strong>Bagging</strong>: Reduce varianza promediando múltiples árboles</li>
<li><strong>Random Forest</strong>: Bagging + aleatorización de características</li>
<li><strong>Gradient Boosting</strong>: Construye árboles secuencialmente para corregir errores</li>
<li><strong>XGBoost, LightGBM, CatBoost</strong>: Implementaciones optimizadas de boosting</li>
</ol>
<p>Estos métodos ensemble están entre los algoritmos más efectivos en machine learning y serán tema de capítulos futuros.</p>
<hr>
<p><strong>Referencias clave:</strong></p>
<ul>
<li>Breiman, L., Friedman, J., Stone, C. J., &amp; Olshen, R. A. (1984). <em>Classification and regression trees</em>. CRC press.</li>
<li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The elements of statistical learning</em> (2nd ed.). Springer.</li>
<li>James, G., Witten, D., Hastie, T., &amp; Tibshirani, R. (2013). <em>An introduction to statistical learning</em>. Springer.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./04-clasificacion.html" class="pagination-link" aria-label="Clasificación">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Clasificación</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Referencias">
        <span class="nav-page-text">Referencias</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>