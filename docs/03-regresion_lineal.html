<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Regresión lineal – Minería de Datos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./02-principios.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-2453fe3dad938b07a2e5eff64ea8abce.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-c1367505ed6638c8d4e510e1459ae853.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-2453fe3dad938b07a2e5eff64ea8abce.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="3&nbsp; Regresión lineal – Minería de Datos">
<meta property="og:description" content="">
<meta property="og:image" content="imgs/gradient_descent.gif">
<meta property="og:site_name" content="Minería de Datos">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./03-regresion_lineal.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regresión lineal</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Minería de Datos</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Alternar modo oscuro"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Temario</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-introduccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-principios.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principios de aprendizaje supervisado</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-regresion_lineal.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regresión lineal</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#regresión-lineal-simple" id="toc-regresión-lineal-simple" class="nav-link active" data-scroll-target="#regresión-lineal-simple"><span class="header-section-number">3.1</span> Regresión Lineal Simple</a>
  <ul class="collapse">
  <li><a href="#cómo-estimamos-los-coeficientes-beta_0-y-beta_1" id="toc-cómo-estimamos-los-coeficientes-beta_0-y-beta_1" class="nav-link" data-scroll-target="#cómo-estimamos-los-coeficientes-beta_0-y-beta_1"><span class="header-section-number">3.1.1</span> ¿Cómo estimamos los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>?</a></li>
  </ul></li>
  <li><a href="#cuáles-son-los-supuestos-de-la-regresión" id="toc-cuáles-son-los-supuestos-de-la-regresión" class="nav-link" data-scroll-target="#cuáles-son-los-supuestos-de-la-regresión"><span class="header-section-number">3.2</span> ¿Cuáles son los supuestos de la regresión? 🧐</a></li>
  <li><a href="#cómo-evaluar-la-precisión-del-modelo" id="toc-cómo-evaluar-la-precisión-del-modelo" class="nav-link" data-scroll-target="#cómo-evaluar-la-precisión-del-modelo"><span class="header-section-number">3.3</span> ¿Cómo evaluar la precisión del modelo? 📈</a>
  <ul class="collapse">
  <li><a href="#coeficiente-de-determinación-r2" id="toc-coeficiente-de-determinación-r2" class="nav-link" data-scroll-target="#coeficiente-de-determinación-r2"><span class="header-section-number">3.3.1</span> Coeficiente de Determinación (<span class="math inline">\(R^2\)</span>)</a></li>
  <li><a href="#p-values-valores-p" id="toc-p-values-valores-p" class="nav-link" data-scroll-target="#p-values-valores-p"><span class="header-section-number">3.3.2</span> p-values (Valores p)</a></li>
  </ul></li>
  <li><a href="#métricas-de-error-de-predicción" id="toc-métricas-de-error-de-predicción" class="nav-link" data-scroll-target="#métricas-de-error-de-predicción"><span class="header-section-number">3.4</span> Métricas de Error de Predicción</a>
  <ul class="collapse">
  <li><a href="#error-cuadrático-medio-mse" id="toc-error-cuadrático-medio-mse" class="nav-link" data-scroll-target="#error-cuadrático-medio-mse"><span class="header-section-number">3.4.1</span> Error Cuadrático Medio (MSE)</a></li>
  <li><a href="#raíz-del-error-cuadrático-medio-rmse" id="toc-raíz-del-error-cuadrático-medio-rmse" class="nav-link" data-scroll-target="#raíz-del-error-cuadrático-medio-rmse"><span class="header-section-number">3.4.2</span> Raíz del Error Cuadrático Medio (RMSE)</a></li>
  <li><a href="#error-absoluto-medio-mae" id="toc-error-absoluto-medio-mae" class="nav-link" data-scroll-target="#error-absoluto-medio-mae"><span class="header-section-number">3.4.3</span> Error Absoluto Medio (MAE)</a></li>
  <li><a href="#error-porcentual-absoluto-medio-mape" id="toc-error-porcentual-absoluto-medio-mape" class="nav-link" data-scroll-target="#error-porcentual-absoluto-medio-mape"><span class="header-section-number">3.4.4</span> Error Porcentual Absoluto Medio (MAPE)</a></li>
  <li><a href="#error-porcentual-absoluto-medio-simétrico-smape" id="toc-error-porcentual-absoluto-medio-simétrico-smape" class="nav-link" data-scroll-target="#error-porcentual-absoluto-medio-simétrico-smape"><span class="header-section-number">3.4.5</span> Error Porcentual Absoluto Medio Simétrico (SMAPE)</a></li>
  <li><a href="#error-logarítmico-cuadrático-medio-msle" id="toc-error-logarítmico-cuadrático-medio-msle" class="nav-link" data-scroll-target="#error-logarítmico-cuadrático-medio-msle"><span class="header-section-number">3.4.6</span> Error Logarítmico Cuadrático Medio (MSLE)</a></li>
  <li><a href="#r2-ajustado" id="toc-r2-ajustado" class="nav-link" data-scroll-target="#r2-ajustado"><span class="header-section-number">3.4.7</span> <span class="math inline">\(R^2\)</span> Ajustado</a></li>
  </ul></li>
  <li><a href="#regresión-lineal-múltiple" id="toc-regresión-lineal-múltiple" class="nav-link" data-scroll-target="#regresión-lineal-múltiple"><span class="header-section-number">3.5</span> Regresión Lineal Múltiple</a></li>
  <li><a href="#transformaciones-comunes-en-modelos-lineales" id="toc-transformaciones-comunes-en-modelos-lineales" class="nav-link" data-scroll-target="#transformaciones-comunes-en-modelos-lineales"><span class="header-section-number">3.6</span> Transformaciones Comunes en Modelos Lineales</a>
  <ul class="collapse">
  <li><a href="#modelo-log-nivel-transformación-en-y" id="toc-modelo-log-nivel-transformación-en-y" class="nav-link" data-scroll-target="#modelo-log-nivel-transformación-en-y"><span class="header-section-number">3.6.1</span> Modelo Log-Nivel (Transformación en Y)</a></li>
  <li><a href="#modelo-nivel-log-transformación-en-x" id="toc-modelo-nivel-log-transformación-en-x" class="nav-link" data-scroll-target="#modelo-nivel-log-transformación-en-x"><span class="header-section-number">3.6.2</span> Modelo Nivel-Log (Transformación en X)</a></li>
  <li><a href="#modelo-log-log-transformación-en-x-e-y" id="toc-modelo-log-log-transformación-en-x-e-y" class="nav-link" data-scroll-target="#modelo-log-log-transformación-en-x-e-y"><span class="header-section-number">3.6.3</span> Modelo Log-Log (Transformación en X e Y)</a></li>
  </ul></li>
  <li><a href="#regresión-regularizada-penalizada" id="toc-regresión-regularizada-penalizada" class="nav-link" data-scroll-target="#regresión-regularizada-penalizada"><span class="header-section-number">3.7</span> Regresión Regularizada (Penalizada) 🎯</a>
  <ul class="collapse">
  <li><a href="#por-qué-necesitamos-regularización" id="toc-por-qué-necesitamos-regularización" class="nav-link" data-scroll-target="#por-qué-necesitamos-regularización"><span class="header-section-number">3.7.1</span> ¿Por qué necesitamos regularización?</a></li>
  <li><a href="#ridge-regression-regresión-ridge" id="toc-ridge-regression-regresión-ridge" class="nav-link" data-scroll-target="#ridge-regression-regresión-ridge"><span class="header-section-number">3.7.2</span> Ridge Regression (Regresión Ridge) 🏔️</a></li>
  <li><a href="#lasso-regression-least-absolute-shrinkage-and-selection-operator" id="toc-lasso-regression-least-absolute-shrinkage-and-selection-operator" class="nav-link" data-scroll-target="#lasso-regression-least-absolute-shrinkage-and-selection-operator"><span class="header-section-number">3.7.3</span> Lasso Regression (Least Absolute Shrinkage and Selection Operator) ✂️</a></li>
  <li><a href="#elastic-net-lo-mejor-de-ambos-mundos" id="toc-elastic-net-lo-mejor-de-ambos-mundos" class="nav-link" data-scroll-target="#elastic-net-lo-mejor-de-ambos-mundos"><span class="header-section-number">3.7.4</span> Elastic Net: Lo Mejor de Ambos Mundos 🕸️</a></li>
  <li><a href="#comparación-visual-ridge-vs-lasso-vs-elastic-net" id="toc-comparación-visual-ridge-vs-lasso-vs-elastic-net" class="nav-link" data-scroll-target="#comparación-visual-ridge-vs-lasso-vs-elastic-net"><span class="header-section-number">3.7.5</span> Comparación Visual: Ridge vs Lasso vs Elastic Net</a></li>
  <li><a href="#cuándo-usar-cada-método" id="toc-cuándo-usar-cada-método" class="nav-link" data-scroll-target="#cuándo-usar-cada-método"><span class="header-section-number">3.7.6</span> ¿Cuándo usar cada método?</a></li>
  <li><a href="#validación-de-modelos-y-selección-de-hiperparámetros" id="toc-validación-de-modelos-y-selección-de-hiperparámetros" class="nav-link" data-scroll-target="#validación-de-modelos-y-selección-de-hiperparámetros"><span class="header-section-number">3.7.7</span> Validación de Modelos y Selección de Hiperparámetros</a></li>
  <li><a href="#ejercicio-práctico-comparando-los-tres-métodos" id="toc-ejercicio-práctico-comparando-los-tres-métodos" class="nav-link" data-scroll-target="#ejercicio-práctico-comparando-los-tres-métodos"><span class="header-section-number">3.7.8</span> Ejercicio Práctico: Comparando los Tres Métodos</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regresión lineal</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="regresión-lineal-simple" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="regresión-lineal-simple"><span class="header-section-number">3.1</span> Regresión Lineal Simple</h2>
<p>Comenzaremos con el caso más sencillo: predecir una variable de resultado <code>Y</code> a partir de una única variable predictora <code>X</code>.</p>
<p>El modelo matemático que queremos ajustar es una línea recta:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X + \epsilon\]</span></p>
<p>Donde:</p>
<ul>
<li><strong><span class="math inline">\(Y\)</span></strong>: La variable dependiente (lo que queremos predecir).</li>
<li><strong><span class="math inline">\(X\)</span></strong>: La variable independiente (nuestro predictor).</li>
<li><strong><span class="math inline">\(\beta_0\)</span></strong>: El intercepto (el valor de <span class="math inline">\(Y\)</span> cuando <span class="math inline">\(X=0\)</span>).</li>
<li><strong><span class="math inline">\(\beta_1\)</span></strong>: La pendiente (cuánto cambia <span class="math inline">\(Y\)</span> por cada unidad que aumenta <span class="math inline">\(X\)</span>).</li>
<li><strong><span class="math inline">\(\epsilon\)</span></strong>: El término de error (la parte de <span class="math inline">\(Y\)</span> que nuestro modelo no puede explicar).</li>
</ul>
<p>Nuestro objetivo 🎯 es encontrar los <strong>mejores valores posibles</strong> para los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> usando los datos que tenemos.</p>
<section id="cómo-estimamos-los-coeficientes-beta_0-y-beta_1" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="cómo-estimamos-los-coeficientes-beta_0-y-beta_1"><span class="header-section-number">3.1.1</span> ¿Cómo estimamos los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>?</h3>
<p>“Mejor” para nosotros significa encontrar la línea que minimice la distancia vertical entre cada punto de dato y la propia línea. Específicamente, minimizamos la <strong>Suma de los Errores al Cuadrado</strong> (SEC o <em>Sum of Squared Errors</em>, SSE).</p>
<p>La función de costo (o pérdida) que queremos minimizar es:</p>
<p><span class="math display">\[J(\beta_0, \beta_1) = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2\]</span></p>
<p>Tenemos dos métodos principales para encontrar los <span class="math inline">\(\beta\)</span> que minimizan esta función:</p>
<section id="método-1-las-ecuaciones-normales-la-solución-analítica" class="level4" data-number="3.1.1.1">
<h4 data-number="3.1.1.1" class="anchored" data-anchor-id="método-1-las-ecuaciones-normales-la-solución-analítica"><span class="header-section-number">3.1.1.1</span> Método 1: Las Ecuaciones Normales (La solución analítica 🧠)</h4>
<p>Este método utiliza cálculo para encontrar el mínimo exacto de la función de costo. Para ello, tomamos las derivadas parciales de <span class="math inline">\(J\)</span> con respecto a <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>, las igualamos a cero y resolvemos para los coeficientes.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Derivada parcial con respecto a <span class="math inline">\(\beta_0\)</span></strong>:
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\frac{\partial J}{\partial \beta_0} = \sum_{i=1}^{n} -2(y_i - \beta_0 - \beta_1 x_i) = 0\]</span> <span class="math display">\[\sum y_i - n\beta_0 - \beta_1 \sum x_i = 0\]</span> <span class="math display">\[\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Derivada parcial con respecto a <span class="math inline">\(\beta_1\)</span></strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\frac{\partial J}{\partial \beta_1} = \sum_{i=1}^{n} -2x_i(y_i - \beta_0 - \beta_1 x_i) = 0\]</span> Sustituyendo <span class="math inline">\(\beta_0\)</span> de la primera ecuación y resolviendo, llegamos a: <span class="math display">\[\hat{\beta}_1 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}\]</span></p>
</div>
</div>
</div>
<p>Estas fórmulas nos dan los valores óptimos y exactos de los coeficientes directamente a partir de los datos.</p>
</section>
<section id="método-2-descenso-en-gradiente-la-solución-iterativa" class="level4" data-number="3.1.1.2">
<h4 data-number="3.1.1.2" class="anchored" data-anchor-id="método-2-descenso-en-gradiente-la-solución-iterativa"><span class="header-section-number">3.1.1.2</span> Método 2: Descenso en Gradiente (La solución iterativa ⚙️)</h4>
<p>Este es un método computacional que nos “acerca” progresivamente a la solución. Es especialmente útil cuando tenemos una cantidad masiva de datos y calcular la solución analítica es muy costoso.</p>
<p><strong>La intuición:</strong> Imagina que estás en una montaña (la función de costo) y quieres llegar al valle (el costo mínimo). El Descenso en Gradiente te dice que mires a tu alrededor y des un paso en la dirección más inclinada hacia abajo. Repites esto hasta llegar al fondo.</p>
<p>El algoritmo funciona así:</p>
<ol type="1">
<li><strong>Inicializa</strong> los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> con valores aleatorios (o en ceros).</li>
<li><strong>Calcula el gradiente</strong> de la función de costo. El gradiente es un vector que apunta en la dirección del máximo ascenso. Nosotros iremos en la dirección opuesta.
<ul>
<li><span class="math inline">\(\frac{\partial J}{\partial \beta_0} = -2 \sum (y_i - (\beta_0 + \beta_1 x_i))\)</span></li>
<li><span class="math inline">\(\frac{\partial J}{\partial \beta_1} = -2 \sum x_i(y_i - (\beta_0 + \beta_1 x_i))\)</span></li>
</ul></li>
<li><strong>Actualiza</strong> los coeficientes usando una <strong>tasa de aprendizaje</strong> (<span class="math inline">\(\alpha\)</span>), que controla el tamaño del paso que damos.
<ul>
<li><span class="math inline">\(\beta_0 := \beta_0 - \alpha \frac{\partial J}{\partial \beta_0}\)</span></li>
<li><span class="math inline">\(\beta_1 := \beta_1 - \alpha \frac{\partial J}{\partial \beta_1}\)</span></li>
</ul></li>
<li><strong>Repite</strong> los pasos 2 y 3 durante un número determinado de iteraciones o hasta que el cambio en el costo sea muy pequeño (convergencia).</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicacion visual
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="imgs/gradient_descent.gif" class="img-fluid"></p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="cuáles-son-los-supuestos-de-la-regresión" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="cuáles-son-los-supuestos-de-la-regresión"><span class="header-section-number">3.2</span> ¿Cuáles son los supuestos de la regresión? 🧐</h2>
<p>Para que nuestro modelo sea confiable (es decir, para que los coeficientes y las predicciones tengan sentido), debemos cumplir con ciertos supuestos.</p>
<ol type="1">
<li><strong>Linealidad:</strong> La relación entre <span class="math inline">\(\beta\)</span> y <span class="math inline">\(Y\)</span> debe ser lineal.
<ul>
<li><strong>¿Para qué sirve?</strong> Si la relación no es lineal, nuestro modelo de línea recta será intrínsecamente incorrecto.</li>
</ul></li>
<li><strong>Independencia de los errores:</strong> Los errores (residuos) no deben estar correlacionados entre sí.
<ul>
<li><strong>¿Para qué sirve?</strong> Es crucial para datos de series temporales. Si los errores están correlacionados, la información de un error nos da pistas sobre el siguiente, lo cual viola la idea de que cada observación es independiente.</li>
</ul></li>
<li><strong>Homocedasticidad (Varianza constante de los errores):</strong> La varianza de los errores debe ser constante para todos los niveles de <span class="math inline">\(X\)</span>.
<ul>
<li><strong>¿Para qué sirve?</strong> Si la varianza cambia (heterocedasticidad), nuestras predicciones serán mejores para algunas partes de los datos que para otras, y los intervalos de confianza para los coeficientes serán poco fiables. Visualmente, en un gráfico de residuos vs.&nbsp;valores predichos, no queremos ver una forma de cono o embudo.</li>
</ul></li>
<li><strong>Normalidad de los errores:</strong> Los errores deben seguir una distribución normal con media cero.
<ul>
<li><strong>¿Para qué sirve?</strong> Este supuesto es fundamental para poder realizar pruebas de hipótesis sobre los coeficientes (como los p-values) y construir intervalos de confianza. Podemos verificarlo con un histograma de los residuos o un gráfico Q-Q.</li>
</ul></li>
</ol>
<hr>
</section>
<section id="cómo-evaluar-la-precisión-del-modelo" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="cómo-evaluar-la-precisión-del-modelo"><span class="header-section-number">3.3</span> ¿Cómo evaluar la precisión del modelo? 📈</h2>
<p>Una vez que hemos ajustado el modelo, ¿cómo sabemos si es bueno?</p>
<section id="coeficiente-de-determinación-r2" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="coeficiente-de-determinación-r2"><span class="header-section-number">3.3.1</span> Coeficiente de Determinación (<span class="math inline">\(R^2\)</span>)</h3>
<p>El <strong><span class="math inline">\(R^2\)</span></strong> mide la proporción de la varianza total en la variable dependiente (<span class="math inline">\(Y\)</span>) que es explicada por nuestro modelo.</p>
<p><span class="math display">\[R^2 = 1 - \frac{\text{Suma de Errores al Cuadrado (SEC)}}{\text{Suma Total de Cuadrados (STC)}} = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}\]</span></p>
<ul>
<li><span class="math inline">\(R^2\)</span> varía entre 0 y 1 (o 0% y 100%).</li>
<li>Un <span class="math inline">\(R^2\)</span> de 0.85 significa que el 85% de la variabilidad en <span class="math inline">\(Y\)</span> puede ser explicada por <span class="math inline">\(X\)</span>.</li>
<li>Un <span class="math inline">\(R^2\)</span> más alto generalmente indica un mejor ajuste del modelo.</li>
</ul>
</section>
<section id="p-values-valores-p" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="p-values-valores-p"><span class="header-section-number">3.3.2</span> p-values (Valores p)</h3>
<p>El <strong>p-value</strong> nos ayuda a determinar si nuestra variable predictora <span class="math inline">\(X\)</span> es <strong>estadísticamente significativa</strong>. Responde a la pregunta: ¿Es probable que la relación que observamos entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> haya ocurrido por puro azar?</p>
<ul>
<li><strong>Hipótesis Nula (<span class="math inline">\(H_0\)</span>):</strong> No hay relación entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> (es decir, <span class="math inline">\(\beta_1 = 0\)</span>).</li>
<li><strong>Hipótesis Alternativa (<span class="math inline">\(H_a\)</span>):</strong> Sí hay una relación entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> (es decir, <span class="math inline">\(\beta_1 \neq 0\)</span>).</li>
</ul>
<p>Un <strong>p-value pequeño</strong> (típicamente &lt; 0.05) nos da evidencia para rechazar la hipótesis nula. Esto sugiere que nuestra variable <span class="math inline">\(X\)</span> es un predictor útil para <span class="math inline">\(Y\)</span>.</p>
</section>
</section>
<section id="métricas-de-error-de-predicción" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="métricas-de-error-de-predicción"><span class="header-section-number">3.4</span> Métricas de Error de Predicción</h2>
<p>Además del <span class="math inline">\(R^2\)</span>, existen múltiples métricas para evaluar qué tan bien predice nuestro modelo. Cada una tiene sus ventajas y casos de uso específicos:</p>
<section id="error-cuadrático-medio-mse" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="error-cuadrático-medio-mse"><span class="header-section-number">3.4.1</span> Error Cuadrático Medio (MSE)</h3>
<p>El <strong>MSE</strong> mide el promedio de los errores al cuadrado:</p>
<p><span class="math display">\[MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Penaliza fuertemente errores grandes, diferenciable (útil para optimización)</li>
<li><strong>Desventajas:</strong> Sensible a valores atípicos, difícil de interpretar (unidades al cuadrado)</li>
<li><strong>Cuándo usar:</strong> Cuando errores grandes son especialmente costosos</li>
</ul>
</section>
<section id="raíz-del-error-cuadrático-medio-rmse" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="raíz-del-error-cuadrático-medio-rmse"><span class="header-section-number">3.4.2</span> Raíz del Error Cuadrático Medio (RMSE)</h3>
<p>El <strong>RMSE</strong> es la raíz cuadrada del MSE:</p>
<p><span class="math display">\[RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Mismas unidades que la variable objetivo, interpretable</li>
<li><strong>Desventajas:</strong> Aún sensible a valores atípicos</li>
<li><strong>Interpretación:</strong> “En promedio, nuestras predicciones se desvían X unidades del valor real”</li>
</ul>
</section>
<section id="error-absoluto-medio-mae" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="error-absoluto-medio-mae"><span class="header-section-number">3.4.3</span> Error Absoluto Medio (MAE)</h3>
<p>El <strong>MAE</strong> mide el promedio de los errores absolutos:</p>
<p><span class="math display">\[MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Robusto a valores atípicos, fácil de interpretar</li>
<li><strong>Desventajas:</strong> No diferenciable en cero, trata todos los errores por igual</li>
<li><strong>Cuándo usar:</strong> Cuando hay valores atípicos o todos los errores tienen igual importancia</li>
</ul>
</section>
<section id="error-porcentual-absoluto-medio-mape" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="error-porcentual-absoluto-medio-mape"><span class="header-section-number">3.4.4</span> Error Porcentual Absoluto Medio (MAPE)</h3>
<p>El <strong>MAPE</strong> expresa el error como porcentaje del valor real:</p>
<p><span class="math display">\[MAPE = \frac{100}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Interpretable (% de error), adimensional, útil para comparar modelos en diferentes escalas</li>
<li><strong>Desventajas:</strong> Indefinido cuando <span class="math inline">\(y_i = 0\)</span>, asimétrico (penaliza más las sobreestimaciones)</li>
<li><strong>Interpretación:</strong> “Nuestras predicciones se desvían en promedio X% del valor real”</li>
<li><strong>Cuándo usar:</strong> Para comparar precisión entre diferentes productos, regiones, o escalas</li>
</ul>
</section>
<section id="error-porcentual-absoluto-medio-simétrico-smape" class="level3" data-number="3.4.5">
<h3 data-number="3.4.5" class="anchored" data-anchor-id="error-porcentual-absoluto-medio-simétrico-smape"><span class="header-section-number">3.4.5</span> Error Porcentual Absoluto Medio Simétrico (SMAPE)</h3>
<p>El <strong>SMAPE</strong> es una versión simétrica del MAPE:</p>
<p><span class="math display">\[SMAPE = \frac{100}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Simétrico, acotado entre 0% y 200%</li>
<li><strong>Desventajas:</strong> Puede ser contraintuitivo, no tan estándar como MAPE</li>
<li><strong>Cuándo usar:</strong> Cuando queremos evitar el sesgo del MAPE hacia sobreestimaciones</li>
</ul>
</section>
<section id="error-logarítmico-cuadrático-medio-msle" class="level3" data-number="3.4.6">
<h3 data-number="3.4.6" class="anchored" data-anchor-id="error-logarítmico-cuadrático-medio-msle"><span class="header-section-number">3.4.6</span> Error Logarítmico Cuadrático Medio (MSLE)</h3>
<p>El <strong>MSLE</strong> usa transformación logarítmica:</p>
<p><span class="math display">\[MSLE = \frac{1}{n} \sum_{i=1}^{n} (\log(1 + y_i) - \log(1 + \hat{y}_i))^2\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Penaliza más las subestimaciones que las sobreestimaciones</li>
<li><strong>Desventajas:</strong> Solo para valores positivos, menos interpretable</li>
<li><strong>Cuándo usar:</strong> Cuando subestimar es más costoso que sobreestimar (ej: demanda de inventario)</li>
</ul>
</section>
<section id="r2-ajustado" class="level3" data-number="3.4.7">
<h3 data-number="3.4.7" class="anchored" data-anchor-id="r2-ajustado"><span class="header-section-number">3.4.7</span> <span class="math inline">\(R^2\)</span> Ajustado</h3>
<p>El <strong><span class="math inline">\(R^2\)</span> ajustado</strong> penaliza por el número de variables en el modelo:</p>
<p><span class="math display">\[R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-p-1}\]</span></p>
<p>Donde <span class="math inline">\(p\)</span> es el número de predictores.</p>
<ul>
<li><strong>Ventajas:</strong> No aumenta automáticamente al añadir variables</li>
<li><strong>Cuándo usar:</strong> Para comparar modelos con diferente número de variables</li>
<li><strong>Interpretación:</strong> Similar a <span class="math inline">\(R^2\)</span> pero más conservador</li>
</ul>
<section id="cuál-métrica-elegir" class="level4" data-number="3.4.7.1">
<h4 data-number="3.4.7.1" class="anchored" data-anchor-id="cuál-métrica-elegir"><span class="header-section-number">3.4.7.1</span> ¿Cuál métrica elegir?</h4>
<p>La elección de métrica depende del contexto del problema:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 33%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Métrica</strong></th>
<th><strong>Mejor para</strong></th>
<th><strong>Evitar cuando</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>RMSE</strong></td>
<td>Errores grandes son costosos</td>
<td>Hay muchos valores atípicos</td>
</tr>
<tr class="even">
<td><strong>MAE</strong></td>
<td>Errores tienen igual importancia</td>
<td>Necesitas diferenciabilidad</td>
</tr>
<tr class="odd">
<td><strong>MAPE</strong></td>
<td>Comparar diferentes escalas</td>
<td>Hay valores cercanos a cero</td>
</tr>
<tr class="even">
<td><strong>SMAPE</strong></td>
<td>Comparar con simetría</td>
<td>Interpretación debe ser simple</td>
</tr>
<tr class="odd">
<td><strong>R²</strong></td>
<td>Explicar variabilidad</td>
<td>Solo importa precisión de predicción</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Recomendación práctica</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Usa <strong>múltiples métricas</strong> para evaluar tu modelo. Una combinación típica sería: - <strong>RMSE</strong> para precisión general - <strong>MAPE</strong> para interpretabilidad de negocio<br>
- <strong>R²</strong> para explicación de variabilidad</p>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="regresión-lineal-múltiple" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="regresión-lineal-múltiple"><span class="header-section-number">3.5</span> Regresión Lineal Múltiple</h2>
<p>Ahora, ¿qué pasa si tenemos múltiples predictores (<span class="math inline">\(X_1, X_2, ..., X_p\)</span>)? El modelo se expande:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p + \epsilon\]</span></p>
<p>La intuición es la misma, pero en lugar de ajustar una línea, estamos ajustando un <strong>hiperplano</strong> en un espacio multidimensional.</p>
<p>Para manejar esto de forma elegante, usamos notación matricial:</p>
<p><span class="math display">\[\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}\]</span></p>
<p>Donde: - <span class="math inline">\(\mathbf{y}\)</span> es el vector de observaciones. - <span class="math inline">\(\mathbf{X}\)</span> es la matriz de diseño (con una primera columna de unos para el intercepto). - <span class="math inline">\(\boldsymbol{\beta}\)</span> es el vector de coeficientes. - <span class="math inline">\(\boldsymbol{\epsilon}\)</span> es el vector de errores.</p>
<p>La función de costo en forma matricial es: <span class="math display">\[J(\boldsymbol{\beta}) = (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})^T (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})\]</span></p>
<hr>
</section>
<section id="transformaciones-comunes-en-modelos-lineales" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="transformaciones-comunes-en-modelos-lineales"><span class="header-section-number">3.6</span> Transformaciones Comunes en Modelos Lineales</h2>
<p>A veces, la relación entre X e Y no es estrictamente lineal. Las transformaciones logarítmicas nos permiten modelar relaciones no lineales y, además, ofrecen interpretaciones muy útiles en términos de cambios porcentuales.</p>
<section id="modelo-log-nivel-transformación-en-y" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="modelo-log-nivel-transformación-en-y"><span class="header-section-number">3.6.1</span> Modelo Log-Nivel (Transformación en Y)</h3>
<p>Este modelo se usa cuando el efecto de X sobre Y no es absoluto, sino porcentual. Por ejemplo, cómo un año más de educación afecta el <em>porcentaje</em> de aumento salarial.</p>
<ul>
<li><strong>Ecuación:</strong> <span class="math inline">\(\ln(Y) = \beta_0 + \beta_1 X + \epsilon\)</span></li>
<li><strong>Interpretación:</strong> Un <strong>incremento de una unidad</strong> en <span class="math inline">\(X\)</span> está asociado con un cambio de <span class="math inline">\((100 \cdot \beta_1)\%\)</span> en <span class="math inline">\(Y\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicación Matemática de la Aproximación
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>La clave está en la propiedad del logaritmo y el cálculo. La derivada de <span class="math inline">\(\ln(Y)\)</span> con respecto a <span class="math inline">\(X\)</span> es <span class="math inline">\(\beta_1\)</span>: <span class="math display">\[\frac{d(\ln(Y))}{dX} = \beta_1\]</span> Sabemos que <span class="math inline">\(d(\ln(Y)) = \frac{dY}{Y}\)</span>. Por tanto: <span class="math display">\[\frac{dY/Y}{dX} = \beta_1\]</span> Para cambios pequeños (o discretos, <span class="math inline">\(\Delta\)</span>), podemos aproximar los diferenciales: <span class="math display">\[\beta_1 \approx \frac{\Delta Y / Y}{\Delta X}\]</span> Si consideramos un cambio unitario en X, <span class="math inline">\(\Delta X = 1\)</span>, entonces: <span class="math display">\[\beta_1 \approx \frac{\Delta Y}{Y}\]</span> Esto significa que <span class="math inline">\(\beta_1\)</span> es la aproximación del cambio porcentual en <span class="math inline">\(Y\)</span> ante un cambio de una unidad en <span class="math inline">\(X\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="modelo-nivel-log-transformación-en-x" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="modelo-nivel-log-transformación-en-x"><span class="header-section-number">3.6.2</span> Modelo Nivel-Log (Transformación en X)</h3>
<p>Este modelo es útil cuando el efecto de X sobre Y se reduce a medida que X aumenta (rendimientos decrecientes). Por ejemplo, el efecto de añadir presupuesto de marketing sobre las ventas.</p>
<ul>
<li><strong>Ecuación:</strong> <span class="math inline">\(Y = \beta_0 + \beta_1 \ln(X) + \epsilon\)</span></li>
<li><strong>Interpretación:</strong> Un <strong>incremento del 1%</strong> en <span class="math inline">\(X\)</span> está asociado con un cambio de <span class="math inline">\((\beta_1 / 100)\)</span> <strong>unidades</strong> en <span class="math inline">\(Y\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicación Matemática de la Aproximación
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Tomamos la derivada de <span class="math inline">\(Y\)</span> con respecto a <span class="math inline">\(\ln(X)\)</span>: <span class="math display">\[\frac{dY}{d(\ln(X))} = \beta_1\]</span> Usando la regla de la cadena, sabemos que <span class="math inline">\(d(\ln(X)) = \frac{dX}{X}\)</span>. Sustituyendo: <span class="math display">\[\frac{dY}{dX/X} = \beta_1 \implies dY = \beta_1 \frac{dX}{X}\]</span> Para cambios discretos, aproximamos: <span class="math display">\[\Delta Y \approx \beta_1 \frac{\Delta X}{X}\]</span> Si consideramos un cambio del 1% en X, entonces <span class="math inline">\(\frac{\Delta X}{X} = 0.01\)</span>. La ecuación se convierte en: <span class="math display">\[\Delta Y \approx \beta_1 (0.01) = \frac{\beta_1}{100}\]</span> Esto significa que un cambio del 1% en <span class="math inline">\(X\)</span> provoca un cambio de <span class="math inline">\(\beta_1/100\)</span> unidades en <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="modelo-log-log-transformación-en-x-e-y" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="modelo-log-log-transformación-en-x-e-y"><span class="header-section-number">3.6.3</span> Modelo Log-Log (Transformación en X e Y)</h3>
<p>Este modelo es muy común en economía y modela la <strong>elasticidad</strong> constante entre dos variables.</p>
<ul>
<li><strong>Ecuación:</strong> <span class="math inline">\(\ln(Y) = \beta_0 + \beta_1 \ln(X) + \epsilon\)</span></li>
<li><strong>Interpretación:</strong> Un <strong>incremento del 1%</strong> en <span class="math inline">\(X\)</span> está asociado con un cambio del <span class="math inline">\(\beta_1\%\)</span> en <span class="math inline">\(Y\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicación Matemática de la Aproximación
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Este caso combina los dos anteriores. <span class="math inline">\(\beta_1\)</span> es la derivada de <span class="math inline">\(\ln(Y)\)</span> con respecto a <span class="math inline">\(\ln(X)\)</span>, que es la definición de elasticidad. <span class="math display">\[\beta_1 = \frac{d(\ln(Y))}{d(\ln(X))}\]</span> Usando las propiedades del cálculo que vimos antes: <span class="math display">\[\beta_1 = \frac{dY/Y}{dX/X}\]</span> Aproximando para cambios discretos: <span class="math display">\[\beta_1 \approx \frac{\Delta Y / Y}{\Delta X / X}\]</span> Esta es la definición de elasticidad: el cambio porcentual en <span class="math inline">\(Y\)</span> dividido por el cambio porcentual en <span class="math inline">\(X\)</span>. Por lo tanto, si <span class="math inline">\(X\)</span> cambia en un 1% (<span class="math inline">\(\Delta X / X = 0.01\)</span>), el cambio porcentual en <span class="math inline">\(Y\)</span> (<span class="math inline">\(\Delta Y / Y\)</span>) será aproximadamente <span class="math inline">\(\beta_1 \times 0.01\)</span>, es decir, un <span class="math inline">\(\beta_1\%\)</span>.</p>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="regresión-regularizada-penalizada" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="regresión-regularizada-penalizada"><span class="header-section-number">3.7</span> Regresión Regularizada (Penalizada) 🎯</h2>
<p>Hasta ahora hemos visto la regresión lineal clásica, pero ¿qué pasa cuando tenemos <strong>muchas variables</strong> o cuando nuestro modelo sufre de <strong>sobreajuste</strong>? Aquí es donde entran las técnicas de <strong>regularización</strong>.</p>
<section id="por-qué-necesitamos-regularización" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="por-qué-necesitamos-regularización"><span class="header-section-number">3.7.1</span> ¿Por qué necesitamos regularización?</h3>
<p>La regresión lineal ordinaria (OLS) puede presentar varios problemas:</p>
<ol type="1">
<li><strong>Sobreajuste</strong>: Cuando tenemos muchas variables relativas al número de observaciones</li>
<li><strong>Multicolinealidad</strong>: Variables predictoras altamente correlacionadas</li>
<li><strong>Inestabilidad</strong>: Pequeños cambios en los datos causan grandes cambios en los coeficientes</li>
<li><strong>Interpretabilidad</strong>: Demasiadas variables hacen difícil entender el modelo</li>
</ol>
<p>La <strong>regularización</strong> añade una <strong>penalización</strong> a la función de costo para controlar la complejidad del modelo.</p>
<hr>
</section>
<section id="ridge-regression-regresión-ridge" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="ridge-regression-regresión-ridge"><span class="header-section-number">3.7.2</span> Ridge Regression (Regresión Ridge) 🏔️</h3>
<p>La <strong>regresión Ridge</strong> añade una penalización <strong>L2</strong> (suma de cuadrados) a los coeficientes:</p>
<p><span class="math display">\[J_{Ridge}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} \beta_j^2\]</span></p>
<p>Donde: - <span class="math inline">\(\lambda &gt; 0\)</span> es el <strong>parámetro de regularización</strong> - <span class="math inline">\(\sum_{j=1}^{p} \beta_j^2\)</span> es la <strong>penalización L2</strong></p>
<section id="características-de-ridge" class="level4" data-number="3.7.2.1">
<h4 data-number="3.7.2.1" class="anchored" data-anchor-id="características-de-ridge"><span class="header-section-number">3.7.2.1</span> Características de Ridge:</h4>
<p>✅ <strong>Ventajas:</strong> - Reduce el sobreajuste - Maneja bien la multicolinealidad - Siempre tiene solución única - Estabiliza los coeficientes</p>
<p>❌ <strong>Desventajas:</strong> - <strong>NO</strong> elimina variables (coeficientes nunca son exactamente cero) - Dificulta la interpretabilidad - Requiere estandarizar las variables</p>
</section>
<section id="solución-analítica" class="level4" data-number="3.7.2.2">
<h4 data-number="3.7.2.2" class="anchored" data-anchor-id="solución-analítica"><span class="header-section-number">3.7.2.2</span> Solución Analítica:</h4>
<p><span class="math display">\[\hat{\boldsymbol{\beta}}_{Ridge} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}\]</span></p>
<p>El término <span class="math inline">\(\lambda\mathbf{I}\)</span> hace que la matriz sea invertible incluso con multicolinealidad.</p>
</section>
<section id="cómo-elegir-λ" class="level4" data-number="3.7.2.3">
<h4 data-number="3.7.2.3" class="anchored" data-anchor-id="cómo-elegir-λ"><span class="header-section-number">3.7.2.3</span> ¿Cómo elegir λ?</h4>
<ul>
<li><strong>λ = 0</strong>: Regresión ordinaria (sin penalización)</li>
<li><strong>λ → ∞</strong>: Todos los coeficientes → 0</li>
<li><strong>λ óptimo</strong>: Se encuentra usando <strong>validación cruzada</strong></li>
</ul>
<hr>
</section>
</section>
<section id="lasso-regression-least-absolute-shrinkage-and-selection-operator" class="level3" data-number="3.7.3">
<h3 data-number="3.7.3" class="anchored" data-anchor-id="lasso-regression-least-absolute-shrinkage-and-selection-operator"><span class="header-section-number">3.7.3</span> Lasso Regression (Least Absolute Shrinkage and Selection Operator) ✂️</h3>
<p>La <strong>regresión Lasso</strong> usa penalización <strong>L1</strong> (suma de valores absolutos):</p>
<p><span class="math display">\[J_{Lasso}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} |\beta_j|\]</span></p>
<section id="características-de-lasso" class="level4" data-number="3.7.3.1">
<h4 data-number="3.7.3.1" class="anchored" data-anchor-id="características-de-lasso"><span class="header-section-number">3.7.3.1</span> Características de Lasso:</h4>
<p>✅ <strong>Ventajas:</strong> - <strong>Selección automática de variables</strong> (coeficientes = 0) - Modelos más interpretables y simples - Útil cuando muchas variables son irrelevantes</p>
<p>❌ <strong>Desventajas:</strong> - Puede ser inestable con grupos de variables correlacionadas - Selecciona arbitrariamente entre variables correlacionadas - No tiene solución analítica cerrada</p>
</section>
<section id="la-magia-de-l1-por-qué-produce-ceros-exactos" class="level4" data-number="3.7.3.2">
<h4 data-number="3.7.3.2" class="anchored" data-anchor-id="la-magia-de-l1-por-qué-produce-ceros-exactos"><span class="header-section-number">3.7.3.2</span> La “Magia” de L1: ¿Por qué produce ceros exactos?</h4>
<p>La penalización L1 crea una región factible con <strong>esquinas puntiagudas</strong>. La solución óptima tiende a ocurrir en estas esquinas, donde algunos coeficientes son exactamente cero.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Intuición Geométrica
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Imagina que estás minimizando una función bajo la restricción de que <span class="math inline">\(|\beta_1| + |\beta_2| \leq t\)</span>. Esta restricción forma un <strong>diamante</strong> en 2D. La función objetivo forma <strong>elipses</strong>. La solución está donde la elipse más pequeña toca el diamante, y esto frecuentemente ocurre en los vértices (donde <span class="math inline">\(\beta_1 = 0\)</span> o <span class="math inline">\(\beta_2 = 0\)</span>).</p>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="elastic-net-lo-mejor-de-ambos-mundos" class="level3" data-number="3.7.4">
<h3 data-number="3.7.4" class="anchored" data-anchor-id="elastic-net-lo-mejor-de-ambos-mundos"><span class="header-section-number">3.7.4</span> Elastic Net: Lo Mejor de Ambos Mundos 🕸️</h3>
<p><strong>Elastic Net</strong> combina las penalizaciones L1 y L2:</p>
<p><span class="math display">\[J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2\]</span></p>
<p>O equivalentemente, con un parámetro de mezcla <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \left[ \alpha \sum_{j=1}^{p} |\beta_j| + (1-\alpha) \sum_{j=1}^{p} \beta_j^2 \right]\]</span></p>
<p>Donde: - <span class="math inline">\(\alpha \in [0,1]\)</span> controla la mezcla entre L1 y L2 - <span class="math inline">\(\alpha = 0\)</span>: Pure Ridge - <span class="math inline">\(\alpha = 1\)</span>: Pure Lasso - <span class="math inline">\(\alpha = 0.5\)</span>: Igual peso a ambas penalizaciones</p>
<section id="características-de-elastic-net" class="level4" data-number="3.7.4.1">
<h4 data-number="3.7.4.1" class="anchored" data-anchor-id="características-de-elastic-net"><span class="header-section-number">3.7.4.1</span> Características de Elastic Net:</h4>
<p>✅ <strong>Ventajas:</strong> - <strong>Selección de variables</strong> como Lasso - <strong>Estabilidad</strong> como Ridge - Maneja bien <strong>grupos de variables correlacionadas</strong> - Más flexible que Ridge o Lasso por separado</p>
<p>❌ <strong>Desventajas:</strong> - Dos hiperparámetros para ajustar (<span class="math inline">\(\lambda\)</span> y <span class="math inline">\(\alpha\)</span>) - Más complejo computacionalmente</p>
<hr>
</section>
</section>
<section id="comparación-visual-ridge-vs-lasso-vs-elastic-net" class="level3" data-number="3.7.5">
<h3 data-number="3.7.5" class="anchored" data-anchor-id="comparación-visual-ridge-vs-lasso-vs-elastic-net"><span class="header-section-number">3.7.5</span> Comparación Visual: Ridge vs Lasso vs Elastic Net</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Aspecto</strong></th>
<th><strong>Ridge</strong></th>
<th><strong>Lasso</strong></th>
<th><strong>Elastic Net</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Penalización</strong></td>
<td>L2: <span class="math inline">\(\sum \beta_j^2\)</span></td>
<td>L1: <span class="math inline">\(\sum |\beta_j|\)</span></td>
<td>L1 + L2 combinadas</td>
</tr>
<tr class="even">
<td><strong>Selección de variables</strong></td>
<td>❌ No</td>
<td>✅ Sí</td>
<td>✅ Sí</td>
</tr>
<tr class="odd">
<td><strong>Coeficientes exactamente cero</strong></td>
<td>❌ No</td>
<td>✅ Sí</td>
<td>✅ Sí</td>
</tr>
<tr class="even">
<td><strong>Manejo de multicolinealidad</strong></td>
<td>✅ Excelente</td>
<td>⚠️ Problemático</td>
<td>✅ Muy bueno</td>
</tr>
<tr class="odd">
<td><strong>Estabilidad</strong></td>
<td>✅ Alta</td>
<td>⚠️ Media</td>
<td>✅ Alta</td>
</tr>
<tr class="even">
<td><strong>Interpretabilidad</strong></td>
<td>⚠️ Media</td>
<td>✅ Alta</td>
<td>✅ Alta</td>
</tr>
<tr class="odd">
<td><strong>Cuando usar</strong></td>
<td>Todas las variables importan</td>
<td>Pocas variables importantes</td>
<td>Situaciones mixtas</td>
</tr>
</tbody>
</table>
</section>
<section id="cuándo-usar-cada-método" class="level3" data-number="3.7.6">
<h3 data-number="3.7.6" class="anchored" data-anchor-id="cuándo-usar-cada-método"><span class="header-section-number">3.7.6</span> ¿Cuándo usar cada método?</h3>
<section id="usa-ridge-cuando" class="level4" data-number="3.7.6.1">
<h4 data-number="3.7.6.1" class="anchored" data-anchor-id="usa-ridge-cuando"><span class="header-section-number">3.7.6.1</span> Usa <strong>Ridge</strong> cuando:</h4>
<ul>
<li>Crees que <strong>todas las variables</strong> contribuyen al modelo</li>
<li>Tienes <strong>multicolinealidad</strong> severa</li>
<li>Quieres <strong>estabilizar</strong> coeficientes sin eliminar variables</li>
<li>El número de observaciones es <strong>pequeño</strong> relativo a variables</li>
</ul>
</section>
<section id="usa-lasso-cuando" class="level4" data-number="3.7.6.2">
<h4 data-number="3.7.6.2" class="anchored" data-anchor-id="usa-lasso-cuando"><span class="header-section-number">3.7.6.2</span> Usa <strong>Lasso</strong> cuando:</h4>
<ul>
<li>Crees que <strong>pocas variables</strong> son realmente importantes</li>
<li>Quieres un modelo <strong>simple e interpretable</strong></li>
<li>Necesitas <strong>selección automática</strong> de variables</li>
<li>Tienes muchas variables <strong>irrelevantes</strong></li>
</ul>
</section>
<section id="usa-elastic-net-cuando" class="level4" data-number="3.7.6.3">
<h4 data-number="3.7.6.3" class="anchored" data-anchor-id="usa-elastic-net-cuando"><span class="header-section-number">3.7.6.3</span> Usa <strong>Elastic Net</strong> cuando:</h4>
<ul>
<li>No estás seguro de cuántas variables son importantes</li>
<li>Tienes <strong>grupos de variables correlacionadas</strong></li>
<li>Quieres balancear <strong>selección</strong> y <strong>estabilidad</strong></li>
<li>Es tu <strong>primera opción</strong> cuando no conoces la estructura de los datos</li>
</ul>
<hr>
</section>
</section>
<section id="validación-de-modelos-y-selección-de-hiperparámetros" class="level3" data-number="3.7.7">
<h3 data-number="3.7.7" class="anchored" data-anchor-id="validación-de-modelos-y-selección-de-hiperparámetros"><span class="header-section-number">3.7.7</span> Validación de Modelos y Selección de Hiperparámetros</h3>
<section id="por-qué-necesitamos-dividir-nuestros-datos" class="level4" data-number="3.7.7.1">
<h4 data-number="3.7.7.1" class="anchored" data-anchor-id="por-qué-necesitamos-dividir-nuestros-datos"><span class="header-section-number">3.7.7.1</span> ¿Por qué necesitamos dividir nuestros datos?</h4>
<p>Cuando construimos modelos de machine learning, enfrentamos un dilema fundamental: <strong>¿cómo sabemos si nuestro modelo funcionará bien con datos nuevos?</strong></p>
<section id="el-problema-del-sobreajuste" class="level5" data-number="3.7.7.1.1">
<h5 data-number="3.7.7.1.1" class="anchored" data-anchor-id="el-problema-del-sobreajuste"><span class="header-section-number">3.7.7.1.1</span> El Problema del Sobreajuste</h5>
<p>Imagina que estás preparándote para un examen. Si solo estudias las preguntas exactas que aparecerán en el examen, podrías obtener una calificación perfecta. Pero si las preguntas cambian ligeramente, tu rendimiento se desplomaría. Esto es <strong>sobreajuste</strong>: el modelo memoriza los datos de entrenamiento pero no generaliza.</p>
</section>
</section>
<section id="división-típica-de-datos-entrenamientovalidaciónprueba" class="level4" data-number="3.7.7.2">
<h4 data-number="3.7.7.2" class="anchored" data-anchor-id="división-típica-de-datos-entrenamientovalidaciónprueba"><span class="header-section-number">3.7.7.2</span> División Típica de Datos: Entrenamiento/Validación/Prueba</h4>
<p>La estrategia estándar es dividir nuestros datos en <strong>tres conjuntos</strong>:</p>
<pre><code>📊 Dataset Completo (100%)
├── 🏋️ Entrenamiento (60%) - Para ajustar coeficientes
├── 🎯 Validación (20%)     - Para seleccionar hiperparámetros  
└── 🧪 Prueba (20%)         - Para evaluación final</code></pre>
<section id="conjunto-de-entrenamiento-60" class="level5" data-number="3.7.7.2.1">
<h5 data-number="3.7.7.2.1" class="anchored" data-anchor-id="conjunto-de-entrenamiento-60"><span class="header-section-number">3.7.7.2.1</span> Conjunto de Entrenamiento (60%)</h5>
<ul>
<li><strong>Propósito</strong>: Ajustar los coeficientes <span class="math inline">\(\beta\)</span> del modelo</li>
<li><strong>Analogía</strong>: Los ejercicios que haces para aprender</li>
</ul>
</section>
<section id="conjunto-de-validación-20" class="level5" data-number="3.7.7.2.2">
<h5 data-number="3.7.7.2.2" class="anchored" data-anchor-id="conjunto-de-validación-20"><span class="header-section-number">3.7.7.2.2</span> Conjunto de Validación (20%)</h5>
<ul>
<li><strong>Propósito</strong>: Comparar diferentes hiperparámetros (como <span class="math inline">\(\lambda\)</span> en Ridge/Lasso)</li>
<li><strong>Analogía</strong>: Exámenes de práctica para decidir qué estrategia de estudio funciona mejor</li>
</ul>
</section>
<section id="conjunto-de-prueba-20" class="level5" data-number="3.7.7.2.3">
<h5 data-number="3.7.7.2.3" class="anchored" data-anchor-id="conjunto-de-prueba-20"><span class="header-section-number">3.7.7.2.3</span> Conjunto de Prueba (20%)</h5>
<ul>
<li><strong>Propósito</strong>: Evaluación final y honesta del modelo</li>
<li><strong>Analogía</strong>: El examen final real</li>
<li><strong>⚠️ Regla de Oro</strong>: ¡Solo se usa UNA vez al final!</li>
</ul>
</section>
</section>
<section id="qué-pasa-si-tenemos-pocos-datos" class="level4" data-number="3.7.7.3">
<h4 data-number="3.7.7.3" class="anchored" data-anchor-id="qué-pasa-si-tenemos-pocos-datos"><span class="header-section-number">3.7.7.3</span> ¿Qué pasa si tenemos pocos datos?</h4>
<p>Cuando nuestro dataset es pequeño (&lt; 1000 observaciones), dividir en tres partes puede ser problemático:</p>
<p>❌ <strong>Problemas con datasets pequeños:</strong> - Conjunto de entrenamiento muy pequeño → modelo pobre - Conjunto de validación pequeño → selección inestable de hiperparámetros - Conjunto de prueba pequeño → evaluación poco confiable</p>
<p><strong>Solución</strong>: ¡Validación Cruzada!</p>
<hr>
</section>
<section id="validación-cruzada-cross-validation" class="level4" data-number="3.7.7.4">
<h4 data-number="3.7.7.4" class="anchored" data-anchor-id="validación-cruzada-cross-validation"><span class="header-section-number">3.7.7.4</span> Validación Cruzada (Cross-Validation)</h4>
<p>La <strong>validación cruzada</strong> es una técnica que maximiza el uso de nuestros datos limitados. En lugar de usar una sola división, usamos <strong>múltiples divisiones</strong>.</p>
<section id="validación-cruzada-k-fold" class="level5" data-number="3.7.7.4.1">
<h5 data-number="3.7.7.4.1" class="anchored" data-anchor-id="validación-cruzada-k-fold"><span class="header-section-number">3.7.7.4.1</span> Validación Cruzada k-fold</h5>
<p>El método más común es <strong>k-fold cross-validation</strong>:</p>
<ol type="1">
<li><strong>Dividir</strong> el dataset en <span class="math inline">\(k\)</span> “pliegues” (folds) de igual tamaño</li>
<li><strong>Repetir</strong> <span class="math inline">\(k\)</span> veces:
<ul>
<li>Usar <span class="math inline">\(k-1\)</span> pliegues para entrenamiento</li>
<li>Usar 1 pliegue para validación</li>
</ul></li>
<li><strong>Promediar</strong> los resultados de las <span class="math inline">\(k\)</span> evaluaciones</li>
</ol>
<div id="cell-cv-visualization" class="cell" data-fig-height="8" data-fig-width="12" data-execution_count="1">
<div class="cell-output cell-output-display">
<div id="cv-visualization" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-regresion_lineal_files/figure-html/cv-visualization-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Visualización de 5-Fold Cross Validation mostrando cómo se dividen los datos en cada iteración</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="ventajas-de-la-validación-cruzada" class="level5" data-number="3.7.7.4.2">
<h5 data-number="3.7.7.4.2" class="anchored" data-anchor-id="ventajas-de-la-validación-cruzada"><span class="header-section-number">3.7.7.4.2</span> Ventajas de la Validación Cruzada</h5>
<p>✅ <strong>Maximiza el uso de datos</strong>: Cada observación se usa tanto para entrenamiento como validación</p>
<p>✅ <strong>Estimación más robusta</strong>: Promedia múltiples evaluaciones independientes</p>
<p>✅ <strong>Reduce la varianza</strong>: Menos dependiente de una división particular</p>
<p>✅ <strong>Detecta inestabilidad</strong>: Si los resultados varían mucho entre folds, el modelo es inestable</p>
</section>
</section>
<section id="validación-cruzada-para-selección-de-hiperparámetros" class="level4" data-number="3.7.7.5">
<h4 data-number="3.7.7.5" class="anchored" data-anchor-id="validación-cruzada-para-selección-de-hiperparámetros"><span class="header-section-number">3.7.7.5</span> Validación Cruzada para Selección de Hiperparámetros</h4>
<p>En regresión regularizada, usamos CV para encontrar el mejor <span class="math inline">\(\lambda\)</span>:</p>
<div id="cell-validation-curve" class="cell" data-fig-height="6" data-fig-width="12" data-execution_count="2">
<div class="cell-output cell-output-stdout">
<pre><code>🎯 SELECCIÓN DE HIPERPARÁMETROS CON VALIDACIÓN CRUZADA
============================================================
Para cada valor de λ:
  1. Aplicar 5-fold CV
  2. Calcular error promedio
  3. Seleccionar λ con menor error</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="validation-curve" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-regresion_lineal_files/figure-html/validation-curve-output-2.png" class="img-fluid figure-img"></p>
<figcaption>Curva de validación mostrando cómo seleccionar el hiperparámetro óptimo λ usando validación cruzada</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
📈 Resultado: λ óptimo = 0.1274
📉 Error de CV mínimo = 0.4776</code></pre>
</div>
</div>
</section>
<section id="proceso-completo-de-validación" class="level4" data-number="3.7.7.6">
<h4 data-number="3.7.7.6" class="anchored" data-anchor-id="proceso-completo-de-validación"><span class="header-section-number">3.7.7.6</span> Proceso Completo de Validación</h4>
<p>El flujo completo para modelos regularizados es:</p>
<pre><code>1. 📊 Dividir datos originales
   └── 80% para desarrollo (entrenamiento + validación)
   └── 20% para prueba final (¡NO TOCAR hasta el final!)

2. 🔄 En el conjunto de desarrollo:
   └── Para cada λ candidato:
       ├── Aplicar k-fold CV
       ├── Calcular error promedio
       └── Guardar resultado

3. 🎯 Seleccionar λ con menor error de CV

4. 🏗️ Entrenar modelo final con λ óptimo en TODO el conjunto de desarrollo

5. 🧪 Evaluación final en conjunto de prueba</code></pre>
</section>
<section id="variantes-de-validación-cruzada" class="level4" data-number="3.7.7.7">
<h4 data-number="3.7.7.7" class="anchored" data-anchor-id="variantes-de-validación-cruzada"><span class="header-section-number">3.7.7.7</span> Variantes de Validación Cruzada</h4>
<section id="leave-one-out-cv-loocv" class="level5" data-number="3.7.7.7.1">
<h5 data-number="3.7.7.7.1" class="anchored" data-anchor-id="leave-one-out-cv-loocv"><span class="header-section-number">3.7.7.7.1</span> Leave-One-Out CV (LOOCV)</h5>
<ul>
<li><strong>k = n</strong> (número de observaciones)</li>
<li><strong>Ventaja</strong>: Máximo uso de datos para entrenamiento</li>
<li><strong>Desventaja</strong>: Computacionalmente costoso, alta varianza</li>
</ul>
</section>
<section id="stratified-cv" class="level5" data-number="3.7.7.7.2">
<h5 data-number="3.7.7.7.2" class="anchored" data-anchor-id="stratified-cv"><span class="header-section-number">3.7.7.7.2</span> Stratified CV</h5>
<ul>
<li><strong>Para problemas de clasificación</strong></li>
<li>Mantiene la proporción de clases en cada fold</li>
</ul>
</section>
<section id="time-series-cv" class="level5" data-number="3.7.7.7.3">
<h5 data-number="3.7.7.7.3" class="anchored" data-anchor-id="time-series-cv"><span class="header-section-number">3.7.7.7.3</span> Time Series CV</h5>
<ul>
<li><strong>Para datos temporales</strong></li>
<li>Respeta el orden temporal (no mezcla futuro con pasado)</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>⚠️ Errores Comunes</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Data Leakage</strong>: Usar información del conjunto de prueba durante el desarrollo</li>
<li><strong>Múltiples evaluaciones</strong>: Evaluar repetidamente en el conjunto de prueba</li>
<li><strong>Selección de modelo sesgada</strong>: Elegir el modelo basándose en el conjunto de prueba</li>
<li><strong>CV incorrecto</strong>: Aplicar transformaciones antes de la división de CV</li>
</ol>
</div>
</div>
</section>
</section>
<section id="cuándo-usar-cada-enfoque" class="level4" data-number="3.7.7.8">
<h4 data-number="3.7.7.8" class="anchored" data-anchor-id="cuándo-usar-cada-enfoque"><span class="header-section-number">3.7.7.8</span> ¿Cuándo usar cada enfoque?</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 40%">
<col style="width: 40%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Tamaño del Dataset</strong></th>
<th><strong>Enfoque Recomendado</strong></th>
<th><strong>Razón</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Grande (&gt;10,000)</strong></td>
<td>Train/Validation/Test</td>
<td>Suficientes datos para división estable</td>
</tr>
<tr class="even">
<td><strong>Mediano (1,000-10,000)</strong></td>
<td>Train/Test + CV</td>
<td>CV para hiperparámetros, test para evaluación final</td>
</tr>
<tr class="odd">
<td><strong>Pequeño (&lt;1,000)</strong></td>
<td>Solo CV (sin test separado)</td>
<td>Maximizar datos disponibles</td>
</tr>
<tr class="even">
<td><strong>Muy pequeño (&lt;100)</strong></td>
<td>LOOCV o Bootstrap</td>
<td>Cada observación es valiosa</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Consejo Práctico</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Empieza siempre con <strong>Elastic Net</strong> con <span class="math inline">\(\alpha = 0.5\)</span>. Si el modelo selecciona muchas variables, prueba valores de <span class="math inline">\(\alpha\)</span> más cercanos a 1 (más Lasso). Si elimina variables importantes, prueba valores cercanos a 0 (más Ridge).</p>
</div>
</div>
<hr>
</section>
</section>
<section id="ejercicio-práctico-comparando-los-tres-métodos" class="level3" data-number="3.7.8">
<h3 data-number="3.7.8" class="anchored" data-anchor-id="ejercicio-práctico-comparando-los-tres-métodos"><span class="header-section-number">3.7.8</span> Ejercicio Práctico: Comparando los Tres Métodos</h3>
<p>En el notebook correspondiente, implementaremos:</p>
<ol type="1">
<li><strong>Generación de datos</strong> con diferentes estructuras de correlación</li>
<li><strong>Comparación visual</strong> de los caminos de regularización</li>
<li><strong>Validación cruzada</strong> para selección de hiperparámetros</li>
<li><strong>Evaluación</strong> del rendimiento en datos de prueba</li>
<li><strong>Interpretación</strong> de los coeficientes seleccionados</li>
</ol>
<p><strong>Pregunta de reflexión:</strong> ¿En qué situaciones esperarías que Ridge supere a Lasso, y viceversa?</p>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-principios.html" class="pagination-link" aria-label="Principios de aprendizaje supervisado">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principios de aprendizaje supervisado</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Referencias">
        <span class="nav-page-text">Referencias</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>