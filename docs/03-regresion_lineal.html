<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Regresi√≥n lineal ‚Äì Miner√≠a de Datos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./02-principios.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-2453fe3dad938b07a2e5eff64ea8abce.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-c1367505ed6638c8d4e510e1459ae853.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-2453fe3dad938b07a2e5eff64ea8abce.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la b√∫squeda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="3&nbsp; Regresi√≥n lineal ‚Äì Miner√≠a de Datos">
<meta property="og:description" content="">
<meta property="og:image" content="imgs/gradient_descent.gif">
<meta property="og:site_name" content="Miner√≠a de Datos">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./03-regresion_lineal.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regresi√≥n lineal</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Miner√≠a de Datos</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Alternar modo oscuro"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Temario</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-introduccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducci√≥n</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-principios.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principios de aprendizaje supervisado</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-regresion_lineal.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regresi√≥n lineal</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#regresi√≥n-lineal-simple" id="toc-regresi√≥n-lineal-simple" class="nav-link active" data-scroll-target="#regresi√≥n-lineal-simple"><span class="header-section-number">3.1</span> Regresi√≥n Lineal Simple</a>
  <ul class="collapse">
  <li><a href="#c√≥mo-estimamos-los-coeficientes-beta_0-y-beta_1" id="toc-c√≥mo-estimamos-los-coeficientes-beta_0-y-beta_1" class="nav-link" data-scroll-target="#c√≥mo-estimamos-los-coeficientes-beta_0-y-beta_1"><span class="header-section-number">3.1.1</span> ¬øC√≥mo estimamos los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>?</a></li>
  </ul></li>
  <li><a href="#cu√°les-son-los-supuestos-de-la-regresi√≥n" id="toc-cu√°les-son-los-supuestos-de-la-regresi√≥n" class="nav-link" data-scroll-target="#cu√°les-son-los-supuestos-de-la-regresi√≥n"><span class="header-section-number">3.2</span> ¬øCu√°les son los supuestos de la regresi√≥n? üßê</a></li>
  <li><a href="#c√≥mo-evaluar-la-precisi√≥n-del-modelo" id="toc-c√≥mo-evaluar-la-precisi√≥n-del-modelo" class="nav-link" data-scroll-target="#c√≥mo-evaluar-la-precisi√≥n-del-modelo"><span class="header-section-number">3.3</span> ¬øC√≥mo evaluar la precisi√≥n del modelo? üìà</a>
  <ul class="collapse">
  <li><a href="#coeficiente-de-determinaci√≥n-r2" id="toc-coeficiente-de-determinaci√≥n-r2" class="nav-link" data-scroll-target="#coeficiente-de-determinaci√≥n-r2"><span class="header-section-number">3.3.1</span> Coeficiente de Determinaci√≥n (<span class="math inline">\(R^2\)</span>)</a></li>
  <li><a href="#p-values-valores-p" id="toc-p-values-valores-p" class="nav-link" data-scroll-target="#p-values-valores-p"><span class="header-section-number">3.3.2</span> p-values (Valores p)</a></li>
  </ul></li>
  <li><a href="#m√©tricas-de-error-de-predicci√≥n" id="toc-m√©tricas-de-error-de-predicci√≥n" class="nav-link" data-scroll-target="#m√©tricas-de-error-de-predicci√≥n"><span class="header-section-number">3.4</span> M√©tricas de Error de Predicci√≥n</a>
  <ul class="collapse">
  <li><a href="#error-cuadr√°tico-medio-mse" id="toc-error-cuadr√°tico-medio-mse" class="nav-link" data-scroll-target="#error-cuadr√°tico-medio-mse"><span class="header-section-number">3.4.1</span> Error Cuadr√°tico Medio (MSE)</a></li>
  <li><a href="#ra√≠z-del-error-cuadr√°tico-medio-rmse" id="toc-ra√≠z-del-error-cuadr√°tico-medio-rmse" class="nav-link" data-scroll-target="#ra√≠z-del-error-cuadr√°tico-medio-rmse"><span class="header-section-number">3.4.2</span> Ra√≠z del Error Cuadr√°tico Medio (RMSE)</a></li>
  <li><a href="#error-absoluto-medio-mae" id="toc-error-absoluto-medio-mae" class="nav-link" data-scroll-target="#error-absoluto-medio-mae"><span class="header-section-number">3.4.3</span> Error Absoluto Medio (MAE)</a></li>
  <li><a href="#error-porcentual-absoluto-medio-mape" id="toc-error-porcentual-absoluto-medio-mape" class="nav-link" data-scroll-target="#error-porcentual-absoluto-medio-mape"><span class="header-section-number">3.4.4</span> Error Porcentual Absoluto Medio (MAPE)</a></li>
  <li><a href="#error-porcentual-absoluto-medio-sim√©trico-smape" id="toc-error-porcentual-absoluto-medio-sim√©trico-smape" class="nav-link" data-scroll-target="#error-porcentual-absoluto-medio-sim√©trico-smape"><span class="header-section-number">3.4.5</span> Error Porcentual Absoluto Medio Sim√©trico (SMAPE)</a></li>
  <li><a href="#error-logar√≠tmico-cuadr√°tico-medio-msle" id="toc-error-logar√≠tmico-cuadr√°tico-medio-msle" class="nav-link" data-scroll-target="#error-logar√≠tmico-cuadr√°tico-medio-msle"><span class="header-section-number">3.4.6</span> Error Logar√≠tmico Cuadr√°tico Medio (MSLE)</a></li>
  <li><a href="#r2-ajustado" id="toc-r2-ajustado" class="nav-link" data-scroll-target="#r2-ajustado"><span class="header-section-number">3.4.7</span> <span class="math inline">\(R^2\)</span> Ajustado</a></li>
  </ul></li>
  <li><a href="#regresi√≥n-lineal-m√∫ltiple" id="toc-regresi√≥n-lineal-m√∫ltiple" class="nav-link" data-scroll-target="#regresi√≥n-lineal-m√∫ltiple"><span class="header-section-number">3.5</span> Regresi√≥n Lineal M√∫ltiple</a></li>
  <li><a href="#transformaciones-comunes-en-modelos-lineales" id="toc-transformaciones-comunes-en-modelos-lineales" class="nav-link" data-scroll-target="#transformaciones-comunes-en-modelos-lineales"><span class="header-section-number">3.6</span> Transformaciones Comunes en Modelos Lineales</a>
  <ul class="collapse">
  <li><a href="#modelo-log-nivel-transformaci√≥n-en-y" id="toc-modelo-log-nivel-transformaci√≥n-en-y" class="nav-link" data-scroll-target="#modelo-log-nivel-transformaci√≥n-en-y"><span class="header-section-number">3.6.1</span> Modelo Log-Nivel (Transformaci√≥n en Y)</a></li>
  <li><a href="#modelo-nivel-log-transformaci√≥n-en-x" id="toc-modelo-nivel-log-transformaci√≥n-en-x" class="nav-link" data-scroll-target="#modelo-nivel-log-transformaci√≥n-en-x"><span class="header-section-number">3.6.2</span> Modelo Nivel-Log (Transformaci√≥n en X)</a></li>
  <li><a href="#modelo-log-log-transformaci√≥n-en-x-e-y" id="toc-modelo-log-log-transformaci√≥n-en-x-e-y" class="nav-link" data-scroll-target="#modelo-log-log-transformaci√≥n-en-x-e-y"><span class="header-section-number">3.6.3</span> Modelo Log-Log (Transformaci√≥n en X e Y)</a></li>
  </ul></li>
  <li><a href="#regresi√≥n-regularizada-penalizada" id="toc-regresi√≥n-regularizada-penalizada" class="nav-link" data-scroll-target="#regresi√≥n-regularizada-penalizada"><span class="header-section-number">3.7</span> Regresi√≥n Regularizada (Penalizada) üéØ</a>
  <ul class="collapse">
  <li><a href="#por-qu√©-necesitamos-regularizaci√≥n" id="toc-por-qu√©-necesitamos-regularizaci√≥n" class="nav-link" data-scroll-target="#por-qu√©-necesitamos-regularizaci√≥n"><span class="header-section-number">3.7.1</span> ¬øPor qu√© necesitamos regularizaci√≥n?</a></li>
  <li><a href="#ridge-regression-regresi√≥n-ridge" id="toc-ridge-regression-regresi√≥n-ridge" class="nav-link" data-scroll-target="#ridge-regression-regresi√≥n-ridge"><span class="header-section-number">3.7.2</span> Ridge Regression (Regresi√≥n Ridge) üèîÔ∏è</a></li>
  <li><a href="#lasso-regression-least-absolute-shrinkage-and-selection-operator" id="toc-lasso-regression-least-absolute-shrinkage-and-selection-operator" class="nav-link" data-scroll-target="#lasso-regression-least-absolute-shrinkage-and-selection-operator"><span class="header-section-number">3.7.3</span> Lasso Regression (Least Absolute Shrinkage and Selection Operator) ‚úÇÔ∏è</a></li>
  <li><a href="#elastic-net-lo-mejor-de-ambos-mundos" id="toc-elastic-net-lo-mejor-de-ambos-mundos" class="nav-link" data-scroll-target="#elastic-net-lo-mejor-de-ambos-mundos"><span class="header-section-number">3.7.4</span> Elastic Net: Lo Mejor de Ambos Mundos üï∏Ô∏è</a></li>
  <li><a href="#comparaci√≥n-visual-ridge-vs-lasso-vs-elastic-net" id="toc-comparaci√≥n-visual-ridge-vs-lasso-vs-elastic-net" class="nav-link" data-scroll-target="#comparaci√≥n-visual-ridge-vs-lasso-vs-elastic-net"><span class="header-section-number">3.7.5</span> Comparaci√≥n Visual: Ridge vs Lasso vs Elastic Net</a></li>
  <li><a href="#cu√°ndo-usar-cada-m√©todo" id="toc-cu√°ndo-usar-cada-m√©todo" class="nav-link" data-scroll-target="#cu√°ndo-usar-cada-m√©todo"><span class="header-section-number">3.7.6</span> ¬øCu√°ndo usar cada m√©todo?</a></li>
  <li><a href="#validaci√≥n-de-modelos-y-selecci√≥n-de-hiperpar√°metros" id="toc-validaci√≥n-de-modelos-y-selecci√≥n-de-hiperpar√°metros" class="nav-link" data-scroll-target="#validaci√≥n-de-modelos-y-selecci√≥n-de-hiperpar√°metros"><span class="header-section-number">3.7.7</span> Validaci√≥n de Modelos y Selecci√≥n de Hiperpar√°metros</a></li>
  <li><a href="#ejercicio-pr√°ctico-comparando-los-tres-m√©todos" id="toc-ejercicio-pr√°ctico-comparando-los-tres-m√©todos" class="nav-link" data-scroll-target="#ejercicio-pr√°ctico-comparando-los-tres-m√©todos"><span class="header-section-number">3.7.8</span> Ejercicio Pr√°ctico: Comparando los Tres M√©todos</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regresi√≥n lineal</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="regresi√≥n-lineal-simple" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="regresi√≥n-lineal-simple"><span class="header-section-number">3.1</span> Regresi√≥n Lineal Simple</h2>
<p>Comenzaremos con el caso m√°s sencillo: predecir una variable de resultado <code>Y</code> a partir de una √∫nica variable predictora <code>X</code>.</p>
<p>El modelo matem√°tico que queremos ajustar es una l√≠nea recta:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X + \epsilon\]</span></p>
<p>Donde:</p>
<ul>
<li><strong><span class="math inline">\(Y\)</span></strong>: La variable dependiente (lo que queremos predecir).</li>
<li><strong><span class="math inline">\(X\)</span></strong>: La variable independiente (nuestro predictor).</li>
<li><strong><span class="math inline">\(\beta_0\)</span></strong>: El intercepto (el valor de <span class="math inline">\(Y\)</span> cuando <span class="math inline">\(X=0\)</span>).</li>
<li><strong><span class="math inline">\(\beta_1\)</span></strong>: La pendiente (cu√°nto cambia <span class="math inline">\(Y\)</span> por cada unidad que aumenta <span class="math inline">\(X\)</span>).</li>
<li><strong><span class="math inline">\(\epsilon\)</span></strong>: El t√©rmino de error (la parte de <span class="math inline">\(Y\)</span> que nuestro modelo no puede explicar).</li>
</ul>
<p>Nuestro objetivo üéØ es encontrar los <strong>mejores valores posibles</strong> para los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> usando los datos que tenemos.</p>
<section id="c√≥mo-estimamos-los-coeficientes-beta_0-y-beta_1" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="c√≥mo-estimamos-los-coeficientes-beta_0-y-beta_1"><span class="header-section-number">3.1.1</span> ¬øC√≥mo estimamos los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>?</h3>
<p>‚ÄúMejor‚Äù para nosotros significa encontrar la l√≠nea que minimice la distancia vertical entre cada punto de dato y la propia l√≠nea. Espec√≠ficamente, minimizamos la <strong>Suma de los Errores al Cuadrado</strong> (SEC o <em>Sum of Squared Errors</em>, SSE).</p>
<p>La funci√≥n de costo (o p√©rdida) que queremos minimizar es:</p>
<p><span class="math display">\[J(\beta_0, \beta_1) = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2\]</span></p>
<p>Tenemos dos m√©todos principales para encontrar los <span class="math inline">\(\beta\)</span> que minimizan esta funci√≥n:</p>
<section id="m√©todo-1-las-ecuaciones-normales-la-soluci√≥n-anal√≠tica" class="level4" data-number="3.1.1.1">
<h4 data-number="3.1.1.1" class="anchored" data-anchor-id="m√©todo-1-las-ecuaciones-normales-la-soluci√≥n-anal√≠tica"><span class="header-section-number">3.1.1.1</span> M√©todo 1: Las Ecuaciones Normales (La soluci√≥n anal√≠tica üß†)</h4>
<p>Este m√©todo utiliza c√°lculo para encontrar el m√≠nimo exacto de la funci√≥n de costo. Para ello, tomamos las derivadas parciales de <span class="math inline">\(J\)</span> con respecto a <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>, las igualamos a cero y resolvemos para los coeficientes.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Derivada parcial con respecto a <span class="math inline">\(\beta_0\)</span></strong>:
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\frac{\partial J}{\partial \beta_0} = \sum_{i=1}^{n} -2(y_i - \beta_0 - \beta_1 x_i) = 0\]</span> <span class="math display">\[\sum y_i - n\beta_0 - \beta_1 \sum x_i = 0\]</span> <span class="math display">\[\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Derivada parcial con respecto a <span class="math inline">\(\beta_1\)</span></strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\frac{\partial J}{\partial \beta_1} = \sum_{i=1}^{n} -2x_i(y_i - \beta_0 - \beta_1 x_i) = 0\]</span> Sustituyendo <span class="math inline">\(\beta_0\)</span> de la primera ecuaci√≥n y resolviendo, llegamos a: <span class="math display">\[\hat{\beta}_1 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}\]</span></p>
</div>
</div>
</div>
<p>Estas f√≥rmulas nos dan los valores √≥ptimos y exactos de los coeficientes directamente a partir de los datos.</p>
</section>
<section id="m√©todo-2-descenso-en-gradiente-la-soluci√≥n-iterativa" class="level4" data-number="3.1.1.2">
<h4 data-number="3.1.1.2" class="anchored" data-anchor-id="m√©todo-2-descenso-en-gradiente-la-soluci√≥n-iterativa"><span class="header-section-number">3.1.1.2</span> M√©todo 2: Descenso en Gradiente (La soluci√≥n iterativa ‚öôÔ∏è)</h4>
<p>Este es un m√©todo computacional que nos ‚Äúacerca‚Äù progresivamente a la soluci√≥n. Es especialmente √∫til cuando tenemos una cantidad masiva de datos y calcular la soluci√≥n anal√≠tica es muy costoso.</p>
<p><strong>La intuici√≥n:</strong> Imagina que est√°s en una monta√±a (la funci√≥n de costo) y quieres llegar al valle (el costo m√≠nimo). El Descenso en Gradiente te dice que mires a tu alrededor y des un paso en la direcci√≥n m√°s inclinada hacia abajo. Repites esto hasta llegar al fondo.</p>
<p>El algoritmo funciona as√≠:</p>
<ol type="1">
<li><strong>Inicializa</strong> los coeficientes <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> con valores aleatorios (o en ceros).</li>
<li><strong>Calcula el gradiente</strong> de la funci√≥n de costo. El gradiente es un vector que apunta en la direcci√≥n del m√°ximo ascenso. Nosotros iremos en la direcci√≥n opuesta.
<ul>
<li><span class="math inline">\(\frac{\partial J}{\partial \beta_0} = -2 \sum (y_i - (\beta_0 + \beta_1 x_i))\)</span></li>
<li><span class="math inline">\(\frac{\partial J}{\partial \beta_1} = -2 \sum x_i(y_i - (\beta_0 + \beta_1 x_i))\)</span></li>
</ul></li>
<li><strong>Actualiza</strong> los coeficientes usando una <strong>tasa de aprendizaje</strong> (<span class="math inline">\(\alpha\)</span>), que controla el tama√±o del paso que damos.
<ul>
<li><span class="math inline">\(\beta_0 := \beta_0 - \alpha \frac{\partial J}{\partial \beta_0}\)</span></li>
<li><span class="math inline">\(\beta_1 := \beta_1 - \alpha \frac{\partial J}{\partial \beta_1}\)</span></li>
</ul></li>
<li><strong>Repite</strong> los pasos 2 y 3 durante un n√∫mero determinado de iteraciones o hasta que el cambio en el costo sea muy peque√±o (convergencia).</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicacion visual
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="imgs/gradient_descent.gif" class="img-fluid"></p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="cu√°les-son-los-supuestos-de-la-regresi√≥n" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="cu√°les-son-los-supuestos-de-la-regresi√≥n"><span class="header-section-number">3.2</span> ¬øCu√°les son los supuestos de la regresi√≥n? üßê</h2>
<p>Para que nuestro modelo sea confiable (es decir, para que los coeficientes y las predicciones tengan sentido), debemos cumplir con ciertos supuestos.</p>
<ol type="1">
<li><strong>Linealidad:</strong> La relaci√≥n entre <span class="math inline">\(\beta\)</span> y <span class="math inline">\(Y\)</span> debe ser lineal.
<ul>
<li><strong>¬øPara qu√© sirve?</strong> Si la relaci√≥n no es lineal, nuestro modelo de l√≠nea recta ser√° intr√≠nsecamente incorrecto.</li>
</ul></li>
<li><strong>Independencia de los errores:</strong> Los errores (residuos) no deben estar correlacionados entre s√≠.
<ul>
<li><strong>¬øPara qu√© sirve?</strong> Es crucial para datos de series temporales. Si los errores est√°n correlacionados, la informaci√≥n de un error nos da pistas sobre el siguiente, lo cual viola la idea de que cada observaci√≥n es independiente.</li>
</ul></li>
<li><strong>Homocedasticidad (Varianza constante de los errores):</strong> La varianza de los errores debe ser constante para todos los niveles de <span class="math inline">\(X\)</span>.
<ul>
<li><strong>¬øPara qu√© sirve?</strong> Si la varianza cambia (heterocedasticidad), nuestras predicciones ser√°n mejores para algunas partes de los datos que para otras, y los intervalos de confianza para los coeficientes ser√°n poco fiables. Visualmente, en un gr√°fico de residuos vs.&nbsp;valores predichos, no queremos ver una forma de cono o embudo.</li>
</ul></li>
<li><strong>Normalidad de los errores:</strong> Los errores deben seguir una distribuci√≥n normal con media cero.
<ul>
<li><strong>¬øPara qu√© sirve?</strong> Este supuesto es fundamental para poder realizar pruebas de hip√≥tesis sobre los coeficientes (como los p-values) y construir intervalos de confianza. Podemos verificarlo con un histograma de los residuos o un gr√°fico Q-Q.</li>
</ul></li>
</ol>
<hr>
</section>
<section id="c√≥mo-evaluar-la-precisi√≥n-del-modelo" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="c√≥mo-evaluar-la-precisi√≥n-del-modelo"><span class="header-section-number">3.3</span> ¬øC√≥mo evaluar la precisi√≥n del modelo? üìà</h2>
<p>Una vez que hemos ajustado el modelo, ¬øc√≥mo sabemos si es bueno?</p>
<section id="coeficiente-de-determinaci√≥n-r2" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="coeficiente-de-determinaci√≥n-r2"><span class="header-section-number">3.3.1</span> Coeficiente de Determinaci√≥n (<span class="math inline">\(R^2\)</span>)</h3>
<p>El <strong><span class="math inline">\(R^2\)</span></strong> mide la proporci√≥n de la varianza total en la variable dependiente (<span class="math inline">\(Y\)</span>) que es explicada por nuestro modelo.</p>
<p><span class="math display">\[R^2 = 1 - \frac{\text{Suma de Errores al Cuadrado (SEC)}}{\text{Suma Total de Cuadrados (STC)}} = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}\]</span></p>
<ul>
<li><span class="math inline">\(R^2\)</span> var√≠a entre 0 y 1 (o 0% y 100%).</li>
<li>Un <span class="math inline">\(R^2\)</span> de 0.85 significa que el 85% de la variabilidad en <span class="math inline">\(Y\)</span> puede ser explicada por <span class="math inline">\(X\)</span>.</li>
<li>Un <span class="math inline">\(R^2\)</span> m√°s alto generalmente indica un mejor ajuste del modelo.</li>
</ul>
</section>
<section id="p-values-valores-p" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="p-values-valores-p"><span class="header-section-number">3.3.2</span> p-values (Valores p)</h3>
<p>El <strong>p-value</strong> nos ayuda a determinar si nuestra variable predictora <span class="math inline">\(X\)</span> es <strong>estad√≠sticamente significativa</strong>. Responde a la pregunta: ¬øEs probable que la relaci√≥n que observamos entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> haya ocurrido por puro azar?</p>
<ul>
<li><strong>Hip√≥tesis Nula (<span class="math inline">\(H_0\)</span>):</strong> No hay relaci√≥n entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> (es decir, <span class="math inline">\(\beta_1 = 0\)</span>).</li>
<li><strong>Hip√≥tesis Alternativa (<span class="math inline">\(H_a\)</span>):</strong> S√≠ hay una relaci√≥n entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> (es decir, <span class="math inline">\(\beta_1 \neq 0\)</span>).</li>
</ul>
<p>Un <strong>p-value peque√±o</strong> (t√≠picamente &lt; 0.05) nos da evidencia para rechazar la hip√≥tesis nula. Esto sugiere que nuestra variable <span class="math inline">\(X\)</span> es un predictor √∫til para <span class="math inline">\(Y\)</span>.</p>
</section>
</section>
<section id="m√©tricas-de-error-de-predicci√≥n" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="m√©tricas-de-error-de-predicci√≥n"><span class="header-section-number">3.4</span> M√©tricas de Error de Predicci√≥n</h2>
<p>Adem√°s del <span class="math inline">\(R^2\)</span>, existen m√∫ltiples m√©tricas para evaluar qu√© tan bien predice nuestro modelo. Cada una tiene sus ventajas y casos de uso espec√≠ficos:</p>
<section id="error-cuadr√°tico-medio-mse" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="error-cuadr√°tico-medio-mse"><span class="header-section-number">3.4.1</span> Error Cuadr√°tico Medio (MSE)</h3>
<p>El <strong>MSE</strong> mide el promedio de los errores al cuadrado:</p>
<p><span class="math display">\[MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Penaliza fuertemente errores grandes, diferenciable (√∫til para optimizaci√≥n)</li>
<li><strong>Desventajas:</strong> Sensible a valores at√≠picos, dif√≠cil de interpretar (unidades al cuadrado)</li>
<li><strong>Cu√°ndo usar:</strong> Cuando errores grandes son especialmente costosos</li>
</ul>
</section>
<section id="ra√≠z-del-error-cuadr√°tico-medio-rmse" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="ra√≠z-del-error-cuadr√°tico-medio-rmse"><span class="header-section-number">3.4.2</span> Ra√≠z del Error Cuadr√°tico Medio (RMSE)</h3>
<p>El <strong>RMSE</strong> es la ra√≠z cuadrada del MSE:</p>
<p><span class="math display">\[RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Mismas unidades que la variable objetivo, interpretable</li>
<li><strong>Desventajas:</strong> A√∫n sensible a valores at√≠picos</li>
<li><strong>Interpretaci√≥n:</strong> ‚ÄúEn promedio, nuestras predicciones se desv√≠an X unidades del valor real‚Äù</li>
</ul>
</section>
<section id="error-absoluto-medio-mae" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="error-absoluto-medio-mae"><span class="header-section-number">3.4.3</span> Error Absoluto Medio (MAE)</h3>
<p>El <strong>MAE</strong> mide el promedio de los errores absolutos:</p>
<p><span class="math display">\[MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Robusto a valores at√≠picos, f√°cil de interpretar</li>
<li><strong>Desventajas:</strong> No diferenciable en cero, trata todos los errores por igual</li>
<li><strong>Cu√°ndo usar:</strong> Cuando hay valores at√≠picos o todos los errores tienen igual importancia</li>
</ul>
</section>
<section id="error-porcentual-absoluto-medio-mape" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="error-porcentual-absoluto-medio-mape"><span class="header-section-number">3.4.4</span> Error Porcentual Absoluto Medio (MAPE)</h3>
<p>El <strong>MAPE</strong> expresa el error como porcentaje del valor real:</p>
<p><span class="math display">\[MAPE = \frac{100}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Interpretable (% de error), adimensional, √∫til para comparar modelos en diferentes escalas</li>
<li><strong>Desventajas:</strong> Indefinido cuando <span class="math inline">\(y_i = 0\)</span>, asim√©trico (penaliza m√°s las sobreestimaciones)</li>
<li><strong>Interpretaci√≥n:</strong> ‚ÄúNuestras predicciones se desv√≠an en promedio X% del valor real‚Äù</li>
<li><strong>Cu√°ndo usar:</strong> Para comparar precisi√≥n entre diferentes productos, regiones, o escalas</li>
</ul>
</section>
<section id="error-porcentual-absoluto-medio-sim√©trico-smape" class="level3" data-number="3.4.5">
<h3 data-number="3.4.5" class="anchored" data-anchor-id="error-porcentual-absoluto-medio-sim√©trico-smape"><span class="header-section-number">3.4.5</span> Error Porcentual Absoluto Medio Sim√©trico (SMAPE)</h3>
<p>El <strong>SMAPE</strong> es una versi√≥n sim√©trica del MAPE:</p>
<p><span class="math display">\[SMAPE = \frac{100}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Sim√©trico, acotado entre 0% y 200%</li>
<li><strong>Desventajas:</strong> Puede ser contraintuitivo, no tan est√°ndar como MAPE</li>
<li><strong>Cu√°ndo usar:</strong> Cuando queremos evitar el sesgo del MAPE hacia sobreestimaciones</li>
</ul>
</section>
<section id="error-logar√≠tmico-cuadr√°tico-medio-msle" class="level3" data-number="3.4.6">
<h3 data-number="3.4.6" class="anchored" data-anchor-id="error-logar√≠tmico-cuadr√°tico-medio-msle"><span class="header-section-number">3.4.6</span> Error Logar√≠tmico Cuadr√°tico Medio (MSLE)</h3>
<p>El <strong>MSLE</strong> usa transformaci√≥n logar√≠tmica:</p>
<p><span class="math display">\[MSLE = \frac{1}{n} \sum_{i=1}^{n} (\log(1 + y_i) - \log(1 + \hat{y}_i))^2\]</span></p>
<ul>
<li><strong>Ventajas:</strong> Penaliza m√°s las subestimaciones que las sobreestimaciones</li>
<li><strong>Desventajas:</strong> Solo para valores positivos, menos interpretable</li>
<li><strong>Cu√°ndo usar:</strong> Cuando subestimar es m√°s costoso que sobreestimar (ej: demanda de inventario)</li>
</ul>
</section>
<section id="r2-ajustado" class="level3" data-number="3.4.7">
<h3 data-number="3.4.7" class="anchored" data-anchor-id="r2-ajustado"><span class="header-section-number">3.4.7</span> <span class="math inline">\(R^2\)</span> Ajustado</h3>
<p>El <strong><span class="math inline">\(R^2\)</span> ajustado</strong> penaliza por el n√∫mero de variables en el modelo:</p>
<p><span class="math display">\[R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-p-1}\]</span></p>
<p>Donde <span class="math inline">\(p\)</span> es el n√∫mero de predictores.</p>
<ul>
<li><strong>Ventajas:</strong> No aumenta autom√°ticamente al a√±adir variables</li>
<li><strong>Cu√°ndo usar:</strong> Para comparar modelos con diferente n√∫mero de variables</li>
<li><strong>Interpretaci√≥n:</strong> Similar a <span class="math inline">\(R^2\)</span> pero m√°s conservador</li>
</ul>
<section id="cu√°l-m√©trica-elegir" class="level4" data-number="3.4.7.1">
<h4 data-number="3.4.7.1" class="anchored" data-anchor-id="cu√°l-m√©trica-elegir"><span class="header-section-number">3.4.7.1</span> ¬øCu√°l m√©trica elegir?</h4>
<p>La elecci√≥n de m√©trica depende del contexto del problema:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 33%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th><strong>M√©trica</strong></th>
<th><strong>Mejor para</strong></th>
<th><strong>Evitar cuando</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>RMSE</strong></td>
<td>Errores grandes son costosos</td>
<td>Hay muchos valores at√≠picos</td>
</tr>
<tr class="even">
<td><strong>MAE</strong></td>
<td>Errores tienen igual importancia</td>
<td>Necesitas diferenciabilidad</td>
</tr>
<tr class="odd">
<td><strong>MAPE</strong></td>
<td>Comparar diferentes escalas</td>
<td>Hay valores cercanos a cero</td>
</tr>
<tr class="even">
<td><strong>SMAPE</strong></td>
<td>Comparar con simetr√≠a</td>
<td>Interpretaci√≥n debe ser simple</td>
</tr>
<tr class="odd">
<td><strong>R¬≤</strong></td>
<td>Explicar variabilidad</td>
<td>Solo importa precisi√≥n de predicci√≥n</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Recomendaci√≥n pr√°ctica</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Usa <strong>m√∫ltiples m√©tricas</strong> para evaluar tu modelo. Una combinaci√≥n t√≠pica ser√≠a: - <strong>RMSE</strong> para precisi√≥n general - <strong>MAPE</strong> para interpretabilidad de negocio<br>
- <strong>R¬≤</strong> para explicaci√≥n de variabilidad</p>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="regresi√≥n-lineal-m√∫ltiple" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="regresi√≥n-lineal-m√∫ltiple"><span class="header-section-number">3.5</span> Regresi√≥n Lineal M√∫ltiple</h2>
<p>Ahora, ¬øqu√© pasa si tenemos m√∫ltiples predictores (<span class="math inline">\(X_1, X_2, ..., X_p\)</span>)? El modelo se expande:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p + \epsilon\]</span></p>
<p>La intuici√≥n es la misma, pero en lugar de ajustar una l√≠nea, estamos ajustando un <strong>hiperplano</strong> en un espacio multidimensional.</p>
<p>Para manejar esto de forma elegante, usamos notaci√≥n matricial:</p>
<p><span class="math display">\[\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}\]</span></p>
<p>Donde: - <span class="math inline">\(\mathbf{y}\)</span> es el vector de observaciones. - <span class="math inline">\(\mathbf{X}\)</span> es la matriz de dise√±o (con una primera columna de unos para el intercepto). - <span class="math inline">\(\boldsymbol{\beta}\)</span> es el vector de coeficientes. - <span class="math inline">\(\boldsymbol{\epsilon}\)</span> es el vector de errores.</p>
<p>La funci√≥n de costo en forma matricial es: <span class="math display">\[J(\boldsymbol{\beta}) = (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})^T (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})\]</span></p>
<hr>
</section>
<section id="transformaciones-comunes-en-modelos-lineales" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="transformaciones-comunes-en-modelos-lineales"><span class="header-section-number">3.6</span> Transformaciones Comunes en Modelos Lineales</h2>
<p>A veces, la relaci√≥n entre X e Y no es estrictamente lineal. Las transformaciones logar√≠tmicas nos permiten modelar relaciones no lineales y, adem√°s, ofrecen interpretaciones muy √∫tiles en t√©rminos de cambios porcentuales.</p>
<section id="modelo-log-nivel-transformaci√≥n-en-y" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="modelo-log-nivel-transformaci√≥n-en-y"><span class="header-section-number">3.6.1</span> Modelo Log-Nivel (Transformaci√≥n en Y)</h3>
<p>Este modelo se usa cuando el efecto de X sobre Y no es absoluto, sino porcentual. Por ejemplo, c√≥mo un a√±o m√°s de educaci√≥n afecta el <em>porcentaje</em> de aumento salarial.</p>
<ul>
<li><strong>Ecuaci√≥n:</strong> <span class="math inline">\(\ln(Y) = \beta_0 + \beta_1 X + \epsilon\)</span></li>
<li><strong>Interpretaci√≥n:</strong> Un <strong>incremento de una unidad</strong> en <span class="math inline">\(X\)</span> est√° asociado con un cambio de <span class="math inline">\((100 \cdot \beta_1)\%\)</span> en <span class="math inline">\(Y\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicaci√≥n Matem√°tica de la Aproximaci√≥n
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>La clave est√° en la propiedad del logaritmo y el c√°lculo. La derivada de <span class="math inline">\(\ln(Y)\)</span> con respecto a <span class="math inline">\(X\)</span> es <span class="math inline">\(\beta_1\)</span>: <span class="math display">\[\frac{d(\ln(Y))}{dX} = \beta_1\]</span> Sabemos que <span class="math inline">\(d(\ln(Y)) = \frac{dY}{Y}\)</span>. Por tanto: <span class="math display">\[\frac{dY/Y}{dX} = \beta_1\]</span> Para cambios peque√±os (o discretos, <span class="math inline">\(\Delta\)</span>), podemos aproximar los diferenciales: <span class="math display">\[\beta_1 \approx \frac{\Delta Y / Y}{\Delta X}\]</span> Si consideramos un cambio unitario en X, <span class="math inline">\(\Delta X = 1\)</span>, entonces: <span class="math display">\[\beta_1 \approx \frac{\Delta Y}{Y}\]</span> Esto significa que <span class="math inline">\(\beta_1\)</span> es la aproximaci√≥n del cambio porcentual en <span class="math inline">\(Y\)</span> ante un cambio de una unidad en <span class="math inline">\(X\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="modelo-nivel-log-transformaci√≥n-en-x" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="modelo-nivel-log-transformaci√≥n-en-x"><span class="header-section-number">3.6.2</span> Modelo Nivel-Log (Transformaci√≥n en X)</h3>
<p>Este modelo es √∫til cuando el efecto de X sobre Y se reduce a medida que X aumenta (rendimientos decrecientes). Por ejemplo, el efecto de a√±adir presupuesto de marketing sobre las ventas.</p>
<ul>
<li><strong>Ecuaci√≥n:</strong> <span class="math inline">\(Y = \beta_0 + \beta_1 \ln(X) + \epsilon\)</span></li>
<li><strong>Interpretaci√≥n:</strong> Un <strong>incremento del 1%</strong> en <span class="math inline">\(X\)</span> est√° asociado con un cambio de <span class="math inline">\((\beta_1 / 100)\)</span> <strong>unidades</strong> en <span class="math inline">\(Y\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicaci√≥n Matem√°tica de la Aproximaci√≥n
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Tomamos la derivada de <span class="math inline">\(Y\)</span> con respecto a <span class="math inline">\(\ln(X)\)</span>: <span class="math display">\[\frac{dY}{d(\ln(X))} = \beta_1\]</span> Usando la regla de la cadena, sabemos que <span class="math inline">\(d(\ln(X)) = \frac{dX}{X}\)</span>. Sustituyendo: <span class="math display">\[\frac{dY}{dX/X} = \beta_1 \implies dY = \beta_1 \frac{dX}{X}\]</span> Para cambios discretos, aproximamos: <span class="math display">\[\Delta Y \approx \beta_1 \frac{\Delta X}{X}\]</span> Si consideramos un cambio del 1% en X, entonces <span class="math inline">\(\frac{\Delta X}{X} = 0.01\)</span>. La ecuaci√≥n se convierte en: <span class="math display">\[\Delta Y \approx \beta_1 (0.01) = \frac{\beta_1}{100}\]</span> Esto significa que un cambio del 1% en <span class="math inline">\(X\)</span> provoca un cambio de <span class="math inline">\(\beta_1/100\)</span> unidades en <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="modelo-log-log-transformaci√≥n-en-x-e-y" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="modelo-log-log-transformaci√≥n-en-x-e-y"><span class="header-section-number">3.6.3</span> Modelo Log-Log (Transformaci√≥n en X e Y)</h3>
<p>Este modelo es muy com√∫n en econom√≠a y modela la <strong>elasticidad</strong> constante entre dos variables.</p>
<ul>
<li><strong>Ecuaci√≥n:</strong> <span class="math inline">\(\ln(Y) = \beta_0 + \beta_1 \ln(X) + \epsilon\)</span></li>
<li><strong>Interpretaci√≥n:</strong> Un <strong>incremento del 1%</strong> en <span class="math inline">\(X\)</span> est√° asociado con un cambio del <span class="math inline">\(\beta_1\%\)</span> en <span class="math inline">\(Y\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explicaci√≥n Matem√°tica de la Aproximaci√≥n
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Este caso combina los dos anteriores. <span class="math inline">\(\beta_1\)</span> es la derivada de <span class="math inline">\(\ln(Y)\)</span> con respecto a <span class="math inline">\(\ln(X)\)</span>, que es la definici√≥n de elasticidad. <span class="math display">\[\beta_1 = \frac{d(\ln(Y))}{d(\ln(X))}\]</span> Usando las propiedades del c√°lculo que vimos antes: <span class="math display">\[\beta_1 = \frac{dY/Y}{dX/X}\]</span> Aproximando para cambios discretos: <span class="math display">\[\beta_1 \approx \frac{\Delta Y / Y}{\Delta X / X}\]</span> Esta es la definici√≥n de elasticidad: el cambio porcentual en <span class="math inline">\(Y\)</span> dividido por el cambio porcentual en <span class="math inline">\(X\)</span>. Por lo tanto, si <span class="math inline">\(X\)</span> cambia en un 1% (<span class="math inline">\(\Delta X / X = 0.01\)</span>), el cambio porcentual en <span class="math inline">\(Y\)</span> (<span class="math inline">\(\Delta Y / Y\)</span>) ser√° aproximadamente <span class="math inline">\(\beta_1 \times 0.01\)</span>, es decir, un <span class="math inline">\(\beta_1\%\)</span>.</p>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="regresi√≥n-regularizada-penalizada" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="regresi√≥n-regularizada-penalizada"><span class="header-section-number">3.7</span> Regresi√≥n Regularizada (Penalizada) üéØ</h2>
<p>Hasta ahora hemos visto la regresi√≥n lineal cl√°sica, pero ¬øqu√© pasa cuando tenemos <strong>muchas variables</strong> o cuando nuestro modelo sufre de <strong>sobreajuste</strong>? Aqu√≠ es donde entran las t√©cnicas de <strong>regularizaci√≥n</strong>.</p>
<section id="por-qu√©-necesitamos-regularizaci√≥n" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="por-qu√©-necesitamos-regularizaci√≥n"><span class="header-section-number">3.7.1</span> ¬øPor qu√© necesitamos regularizaci√≥n?</h3>
<p>La regresi√≥n lineal ordinaria (OLS) puede presentar varios problemas:</p>
<ol type="1">
<li><strong>Sobreajuste</strong>: Cuando tenemos muchas variables relativas al n√∫mero de observaciones</li>
<li><strong>Multicolinealidad</strong>: Variables predictoras altamente correlacionadas</li>
<li><strong>Inestabilidad</strong>: Peque√±os cambios en los datos causan grandes cambios en los coeficientes</li>
<li><strong>Interpretabilidad</strong>: Demasiadas variables hacen dif√≠cil entender el modelo</li>
</ol>
<p>La <strong>regularizaci√≥n</strong> a√±ade una <strong>penalizaci√≥n</strong> a la funci√≥n de costo para controlar la complejidad del modelo.</p>
<hr>
</section>
<section id="ridge-regression-regresi√≥n-ridge" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="ridge-regression-regresi√≥n-ridge"><span class="header-section-number">3.7.2</span> Ridge Regression (Regresi√≥n Ridge) üèîÔ∏è</h3>
<p>La <strong>regresi√≥n Ridge</strong> a√±ade una penalizaci√≥n <strong>L2</strong> (suma de cuadrados) a los coeficientes:</p>
<p><span class="math display">\[J_{Ridge}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} \beta_j^2\]</span></p>
<p>Donde: - <span class="math inline">\(\lambda &gt; 0\)</span> es el <strong>par√°metro de regularizaci√≥n</strong> - <span class="math inline">\(\sum_{j=1}^{p} \beta_j^2\)</span> es la <strong>penalizaci√≥n L2</strong></p>
<section id="caracter√≠sticas-de-ridge" class="level4" data-number="3.7.2.1">
<h4 data-number="3.7.2.1" class="anchored" data-anchor-id="caracter√≠sticas-de-ridge"><span class="header-section-number">3.7.2.1</span> Caracter√≠sticas de Ridge:</h4>
<p>‚úÖ <strong>Ventajas:</strong> - Reduce el sobreajuste - Maneja bien la multicolinealidad - Siempre tiene soluci√≥n √∫nica - Estabiliza los coeficientes</p>
<p>‚ùå <strong>Desventajas:</strong> - <strong>NO</strong> elimina variables (coeficientes nunca son exactamente cero) - Dificulta la interpretabilidad - Requiere estandarizar las variables</p>
</section>
<section id="soluci√≥n-anal√≠tica" class="level4" data-number="3.7.2.2">
<h4 data-number="3.7.2.2" class="anchored" data-anchor-id="soluci√≥n-anal√≠tica"><span class="header-section-number">3.7.2.2</span> Soluci√≥n Anal√≠tica:</h4>
<p><span class="math display">\[\hat{\boldsymbol{\beta}}_{Ridge} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}\]</span></p>
<p>El t√©rmino <span class="math inline">\(\lambda\mathbf{I}\)</span> hace que la matriz sea invertible incluso con multicolinealidad.</p>
</section>
<section id="c√≥mo-elegir-Œª" class="level4" data-number="3.7.2.3">
<h4 data-number="3.7.2.3" class="anchored" data-anchor-id="c√≥mo-elegir-Œª"><span class="header-section-number">3.7.2.3</span> ¬øC√≥mo elegir Œª?</h4>
<ul>
<li><strong>Œª = 0</strong>: Regresi√≥n ordinaria (sin penalizaci√≥n)</li>
<li><strong>Œª ‚Üí ‚àû</strong>: Todos los coeficientes ‚Üí 0</li>
<li><strong>Œª √≥ptimo</strong>: Se encuentra usando <strong>validaci√≥n cruzada</strong></li>
</ul>
<hr>
</section>
</section>
<section id="lasso-regression-least-absolute-shrinkage-and-selection-operator" class="level3" data-number="3.7.3">
<h3 data-number="3.7.3" class="anchored" data-anchor-id="lasso-regression-least-absolute-shrinkage-and-selection-operator"><span class="header-section-number">3.7.3</span> Lasso Regression (Least Absolute Shrinkage and Selection Operator) ‚úÇÔ∏è</h3>
<p>La <strong>regresi√≥n Lasso</strong> usa penalizaci√≥n <strong>L1</strong> (suma de valores absolutos):</p>
<p><span class="math display">\[J_{Lasso}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} |\beta_j|\]</span></p>
<section id="caracter√≠sticas-de-lasso" class="level4" data-number="3.7.3.1">
<h4 data-number="3.7.3.1" class="anchored" data-anchor-id="caracter√≠sticas-de-lasso"><span class="header-section-number">3.7.3.1</span> Caracter√≠sticas de Lasso:</h4>
<p>‚úÖ <strong>Ventajas:</strong> - <strong>Selecci√≥n autom√°tica de variables</strong> (coeficientes = 0) - Modelos m√°s interpretables y simples - √ötil cuando muchas variables son irrelevantes</p>
<p>‚ùå <strong>Desventajas:</strong> - Puede ser inestable con grupos de variables correlacionadas - Selecciona arbitrariamente entre variables correlacionadas - No tiene soluci√≥n anal√≠tica cerrada</p>
</section>
<section id="la-magia-de-l1-por-qu√©-produce-ceros-exactos" class="level4" data-number="3.7.3.2">
<h4 data-number="3.7.3.2" class="anchored" data-anchor-id="la-magia-de-l1-por-qu√©-produce-ceros-exactos"><span class="header-section-number">3.7.3.2</span> La ‚ÄúMagia‚Äù de L1: ¬øPor qu√© produce ceros exactos?</h4>
<p>La penalizaci√≥n L1 crea una regi√≥n factible con <strong>esquinas puntiagudas</strong>. La soluci√≥n √≥ptima tiende a ocurrir en estas esquinas, donde algunos coeficientes son exactamente cero.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Intuici√≥n Geom√©trica
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Imagina que est√°s minimizando una funci√≥n bajo la restricci√≥n de que <span class="math inline">\(|\beta_1| + |\beta_2| \leq t\)</span>. Esta restricci√≥n forma un <strong>diamante</strong> en 2D. La funci√≥n objetivo forma <strong>elipses</strong>. La soluci√≥n est√° donde la elipse m√°s peque√±a toca el diamante, y esto frecuentemente ocurre en los v√©rtices (donde <span class="math inline">\(\beta_1 = 0\)</span> o <span class="math inline">\(\beta_2 = 0\)</span>).</p>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="elastic-net-lo-mejor-de-ambos-mundos" class="level3" data-number="3.7.4">
<h3 data-number="3.7.4" class="anchored" data-anchor-id="elastic-net-lo-mejor-de-ambos-mundos"><span class="header-section-number">3.7.4</span> Elastic Net: Lo Mejor de Ambos Mundos üï∏Ô∏è</h3>
<p><strong>Elastic Net</strong> combina las penalizaciones L1 y L2:</p>
<p><span class="math display">\[J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2\]</span></p>
<p>O equivalentemente, con un par√°metro de mezcla <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[J_{ElasticNet}(\boldsymbol{\beta}) = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2 + \lambda \left[ \alpha \sum_{j=1}^{p} |\beta_j| + (1-\alpha) \sum_{j=1}^{p} \beta_j^2 \right]\]</span></p>
<p>Donde: - <span class="math inline">\(\alpha \in [0,1]\)</span> controla la mezcla entre L1 y L2 - <span class="math inline">\(\alpha = 0\)</span>: Pure Ridge - <span class="math inline">\(\alpha = 1\)</span>: Pure Lasso - <span class="math inline">\(\alpha = 0.5\)</span>: Igual peso a ambas penalizaciones</p>
<section id="caracter√≠sticas-de-elastic-net" class="level4" data-number="3.7.4.1">
<h4 data-number="3.7.4.1" class="anchored" data-anchor-id="caracter√≠sticas-de-elastic-net"><span class="header-section-number">3.7.4.1</span> Caracter√≠sticas de Elastic Net:</h4>
<p>‚úÖ <strong>Ventajas:</strong> - <strong>Selecci√≥n de variables</strong> como Lasso - <strong>Estabilidad</strong> como Ridge - Maneja bien <strong>grupos de variables correlacionadas</strong> - M√°s flexible que Ridge o Lasso por separado</p>
<p>‚ùå <strong>Desventajas:</strong> - Dos hiperpar√°metros para ajustar (<span class="math inline">\(\lambda\)</span> y <span class="math inline">\(\alpha\)</span>) - M√°s complejo computacionalmente</p>
<hr>
</section>
</section>
<section id="comparaci√≥n-visual-ridge-vs-lasso-vs-elastic-net" class="level3" data-number="3.7.5">
<h3 data-number="3.7.5" class="anchored" data-anchor-id="comparaci√≥n-visual-ridge-vs-lasso-vs-elastic-net"><span class="header-section-number">3.7.5</span> Comparaci√≥n Visual: Ridge vs Lasso vs Elastic Net</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Aspecto</strong></th>
<th><strong>Ridge</strong></th>
<th><strong>Lasso</strong></th>
<th><strong>Elastic Net</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Penalizaci√≥n</strong></td>
<td>L2: <span class="math inline">\(\sum \beta_j^2\)</span></td>
<td>L1: <span class="math inline">\(\sum |\beta_j|\)</span></td>
<td>L1 + L2 combinadas</td>
</tr>
<tr class="even">
<td><strong>Selecci√≥n de variables</strong></td>
<td>‚ùå No</td>
<td>‚úÖ S√≠</td>
<td>‚úÖ S√≠</td>
</tr>
<tr class="odd">
<td><strong>Coeficientes exactamente cero</strong></td>
<td>‚ùå No</td>
<td>‚úÖ S√≠</td>
<td>‚úÖ S√≠</td>
</tr>
<tr class="even">
<td><strong>Manejo de multicolinealidad</strong></td>
<td>‚úÖ Excelente</td>
<td>‚ö†Ô∏è Problem√°tico</td>
<td>‚úÖ Muy bueno</td>
</tr>
<tr class="odd">
<td><strong>Estabilidad</strong></td>
<td>‚úÖ Alta</td>
<td>‚ö†Ô∏è Media</td>
<td>‚úÖ Alta</td>
</tr>
<tr class="even">
<td><strong>Interpretabilidad</strong></td>
<td>‚ö†Ô∏è Media</td>
<td>‚úÖ Alta</td>
<td>‚úÖ Alta</td>
</tr>
<tr class="odd">
<td><strong>Cuando usar</strong></td>
<td>Todas las variables importan</td>
<td>Pocas variables importantes</td>
<td>Situaciones mixtas</td>
</tr>
</tbody>
</table>
</section>
<section id="cu√°ndo-usar-cada-m√©todo" class="level3" data-number="3.7.6">
<h3 data-number="3.7.6" class="anchored" data-anchor-id="cu√°ndo-usar-cada-m√©todo"><span class="header-section-number">3.7.6</span> ¬øCu√°ndo usar cada m√©todo?</h3>
<section id="usa-ridge-cuando" class="level4" data-number="3.7.6.1">
<h4 data-number="3.7.6.1" class="anchored" data-anchor-id="usa-ridge-cuando"><span class="header-section-number">3.7.6.1</span> Usa <strong>Ridge</strong> cuando:</h4>
<ul>
<li>Crees que <strong>todas las variables</strong> contribuyen al modelo</li>
<li>Tienes <strong>multicolinealidad</strong> severa</li>
<li>Quieres <strong>estabilizar</strong> coeficientes sin eliminar variables</li>
<li>El n√∫mero de observaciones es <strong>peque√±o</strong> relativo a variables</li>
</ul>
</section>
<section id="usa-lasso-cuando" class="level4" data-number="3.7.6.2">
<h4 data-number="3.7.6.2" class="anchored" data-anchor-id="usa-lasso-cuando"><span class="header-section-number">3.7.6.2</span> Usa <strong>Lasso</strong> cuando:</h4>
<ul>
<li>Crees que <strong>pocas variables</strong> son realmente importantes</li>
<li>Quieres un modelo <strong>simple e interpretable</strong></li>
<li>Necesitas <strong>selecci√≥n autom√°tica</strong> de variables</li>
<li>Tienes muchas variables <strong>irrelevantes</strong></li>
</ul>
</section>
<section id="usa-elastic-net-cuando" class="level4" data-number="3.7.6.3">
<h4 data-number="3.7.6.3" class="anchored" data-anchor-id="usa-elastic-net-cuando"><span class="header-section-number">3.7.6.3</span> Usa <strong>Elastic Net</strong> cuando:</h4>
<ul>
<li>No est√°s seguro de cu√°ntas variables son importantes</li>
<li>Tienes <strong>grupos de variables correlacionadas</strong></li>
<li>Quieres balancear <strong>selecci√≥n</strong> y <strong>estabilidad</strong></li>
<li>Es tu <strong>primera opci√≥n</strong> cuando no conoces la estructura de los datos</li>
</ul>
<hr>
</section>
</section>
<section id="validaci√≥n-de-modelos-y-selecci√≥n-de-hiperpar√°metros" class="level3" data-number="3.7.7">
<h3 data-number="3.7.7" class="anchored" data-anchor-id="validaci√≥n-de-modelos-y-selecci√≥n-de-hiperpar√°metros"><span class="header-section-number">3.7.7</span> Validaci√≥n de Modelos y Selecci√≥n de Hiperpar√°metros</h3>
<section id="por-qu√©-necesitamos-dividir-nuestros-datos" class="level4" data-number="3.7.7.1">
<h4 data-number="3.7.7.1" class="anchored" data-anchor-id="por-qu√©-necesitamos-dividir-nuestros-datos"><span class="header-section-number">3.7.7.1</span> ¬øPor qu√© necesitamos dividir nuestros datos?</h4>
<p>Cuando construimos modelos de machine learning, enfrentamos un dilema fundamental: <strong>¬øc√≥mo sabemos si nuestro modelo funcionar√° bien con datos nuevos?</strong></p>
<section id="el-problema-del-sobreajuste" class="level5" data-number="3.7.7.1.1">
<h5 data-number="3.7.7.1.1" class="anchored" data-anchor-id="el-problema-del-sobreajuste"><span class="header-section-number">3.7.7.1.1</span> El Problema del Sobreajuste</h5>
<p>Imagina que est√°s prepar√°ndote para un examen. Si solo estudias las preguntas exactas que aparecer√°n en el examen, podr√≠as obtener una calificaci√≥n perfecta. Pero si las preguntas cambian ligeramente, tu rendimiento se desplomar√≠a. Esto es <strong>sobreajuste</strong>: el modelo memoriza los datos de entrenamiento pero no generaliza.</p>
</section>
</section>
<section id="divisi√≥n-t√≠pica-de-datos-entrenamientovalidaci√≥nprueba" class="level4" data-number="3.7.7.2">
<h4 data-number="3.7.7.2" class="anchored" data-anchor-id="divisi√≥n-t√≠pica-de-datos-entrenamientovalidaci√≥nprueba"><span class="header-section-number">3.7.7.2</span> Divisi√≥n T√≠pica de Datos: Entrenamiento/Validaci√≥n/Prueba</h4>
<p>La estrategia est√°ndar es dividir nuestros datos en <strong>tres conjuntos</strong>:</p>
<pre><code>üìä Dataset Completo (100%)
‚îú‚îÄ‚îÄ üèãÔ∏è Entrenamiento (60%) - Para ajustar coeficientes
‚îú‚îÄ‚îÄ üéØ Validaci√≥n (20%)     - Para seleccionar hiperpar√°metros  
‚îî‚îÄ‚îÄ üß™ Prueba (20%)         - Para evaluaci√≥n final</code></pre>
<section id="conjunto-de-entrenamiento-60" class="level5" data-number="3.7.7.2.1">
<h5 data-number="3.7.7.2.1" class="anchored" data-anchor-id="conjunto-de-entrenamiento-60"><span class="header-section-number">3.7.7.2.1</span> Conjunto de Entrenamiento (60%)</h5>
<ul>
<li><strong>Prop√≥sito</strong>: Ajustar los coeficientes <span class="math inline">\(\beta\)</span> del modelo</li>
<li><strong>Analog√≠a</strong>: Los ejercicios que haces para aprender</li>
</ul>
</section>
<section id="conjunto-de-validaci√≥n-20" class="level5" data-number="3.7.7.2.2">
<h5 data-number="3.7.7.2.2" class="anchored" data-anchor-id="conjunto-de-validaci√≥n-20"><span class="header-section-number">3.7.7.2.2</span> Conjunto de Validaci√≥n (20%)</h5>
<ul>
<li><strong>Prop√≥sito</strong>: Comparar diferentes hiperpar√°metros (como <span class="math inline">\(\lambda\)</span> en Ridge/Lasso)</li>
<li><strong>Analog√≠a</strong>: Ex√°menes de pr√°ctica para decidir qu√© estrategia de estudio funciona mejor</li>
</ul>
</section>
<section id="conjunto-de-prueba-20" class="level5" data-number="3.7.7.2.3">
<h5 data-number="3.7.7.2.3" class="anchored" data-anchor-id="conjunto-de-prueba-20"><span class="header-section-number">3.7.7.2.3</span> Conjunto de Prueba (20%)</h5>
<ul>
<li><strong>Prop√≥sito</strong>: Evaluaci√≥n final y honesta del modelo</li>
<li><strong>Analog√≠a</strong>: El examen final real</li>
<li><strong>‚ö†Ô∏è Regla de Oro</strong>: ¬°Solo se usa UNA vez al final!</li>
</ul>
</section>
</section>
<section id="qu√©-pasa-si-tenemos-pocos-datos" class="level4" data-number="3.7.7.3">
<h4 data-number="3.7.7.3" class="anchored" data-anchor-id="qu√©-pasa-si-tenemos-pocos-datos"><span class="header-section-number">3.7.7.3</span> ¬øQu√© pasa si tenemos pocos datos?</h4>
<p>Cuando nuestro dataset es peque√±o (&lt; 1000 observaciones), dividir en tres partes puede ser problem√°tico:</p>
<p>‚ùå <strong>Problemas con datasets peque√±os:</strong> - Conjunto de entrenamiento muy peque√±o ‚Üí modelo pobre - Conjunto de validaci√≥n peque√±o ‚Üí selecci√≥n inestable de hiperpar√°metros - Conjunto de prueba peque√±o ‚Üí evaluaci√≥n poco confiable</p>
<p><strong>Soluci√≥n</strong>: ¬°Validaci√≥n Cruzada!</p>
<hr>
</section>
<section id="validaci√≥n-cruzada-cross-validation" class="level4" data-number="3.7.7.4">
<h4 data-number="3.7.7.4" class="anchored" data-anchor-id="validaci√≥n-cruzada-cross-validation"><span class="header-section-number">3.7.7.4</span> Validaci√≥n Cruzada (Cross-Validation)</h4>
<p>La <strong>validaci√≥n cruzada</strong> es una t√©cnica que maximiza el uso de nuestros datos limitados. En lugar de usar una sola divisi√≥n, usamos <strong>m√∫ltiples divisiones</strong>.</p>
<section id="validaci√≥n-cruzada-k-fold" class="level5" data-number="3.7.7.4.1">
<h5 data-number="3.7.7.4.1" class="anchored" data-anchor-id="validaci√≥n-cruzada-k-fold"><span class="header-section-number">3.7.7.4.1</span> Validaci√≥n Cruzada k-fold</h5>
<p>El m√©todo m√°s com√∫n es <strong>k-fold cross-validation</strong>:</p>
<ol type="1">
<li><strong>Dividir</strong> el dataset en <span class="math inline">\(k\)</span> ‚Äúpliegues‚Äù (folds) de igual tama√±o</li>
<li><strong>Repetir</strong> <span class="math inline">\(k\)</span> veces:
<ul>
<li>Usar <span class="math inline">\(k-1\)</span> pliegues para entrenamiento</li>
<li>Usar 1 pliegue para validaci√≥n</li>
</ul></li>
<li><strong>Promediar</strong> los resultados de las <span class="math inline">\(k\)</span> evaluaciones</li>
</ol>
<div id="cell-cv-visualization" class="cell" data-fig-height="8" data-fig-width="12" data-execution_count="1">
<div class="cell-output cell-output-display">
<div id="cv-visualization" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-regresion_lineal_files/figure-html/cv-visualization-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Visualizaci√≥n de 5-Fold Cross Validation mostrando c√≥mo se dividen los datos en cada iteraci√≥n</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="ventajas-de-la-validaci√≥n-cruzada" class="level5" data-number="3.7.7.4.2">
<h5 data-number="3.7.7.4.2" class="anchored" data-anchor-id="ventajas-de-la-validaci√≥n-cruzada"><span class="header-section-number">3.7.7.4.2</span> Ventajas de la Validaci√≥n Cruzada</h5>
<p>‚úÖ <strong>Maximiza el uso de datos</strong>: Cada observaci√≥n se usa tanto para entrenamiento como validaci√≥n</p>
<p>‚úÖ <strong>Estimaci√≥n m√°s robusta</strong>: Promedia m√∫ltiples evaluaciones independientes</p>
<p>‚úÖ <strong>Reduce la varianza</strong>: Menos dependiente de una divisi√≥n particular</p>
<p>‚úÖ <strong>Detecta inestabilidad</strong>: Si los resultados var√≠an mucho entre folds, el modelo es inestable</p>
</section>
</section>
<section id="validaci√≥n-cruzada-para-selecci√≥n-de-hiperpar√°metros" class="level4" data-number="3.7.7.5">
<h4 data-number="3.7.7.5" class="anchored" data-anchor-id="validaci√≥n-cruzada-para-selecci√≥n-de-hiperpar√°metros"><span class="header-section-number">3.7.7.5</span> Validaci√≥n Cruzada para Selecci√≥n de Hiperpar√°metros</h4>
<p>En regresi√≥n regularizada, usamos CV para encontrar el mejor <span class="math inline">\(\lambda\)</span>:</p>
<div id="cell-validation-curve" class="cell" data-fig-height="6" data-fig-width="12" data-execution_count="2">
<div class="cell-output cell-output-stdout">
<pre><code>üéØ SELECCI√ìN DE HIPERPAR√ÅMETROS CON VALIDACI√ìN CRUZADA
============================================================
Para cada valor de Œª:
  1. Aplicar 5-fold CV
  2. Calcular error promedio
  3. Seleccionar Œª con menor error</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="validation-curve" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-regresion_lineal_files/figure-html/validation-curve-output-2.png" class="img-fluid figure-img"></p>
<figcaption>Curva de validaci√≥n mostrando c√≥mo seleccionar el hiperpar√°metro √≥ptimo Œª usando validaci√≥n cruzada</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
üìà Resultado: Œª √≥ptimo = 0.1274
üìâ Error de CV m√≠nimo = 0.4776</code></pre>
</div>
</div>
</section>
<section id="proceso-completo-de-validaci√≥n" class="level4" data-number="3.7.7.6">
<h4 data-number="3.7.7.6" class="anchored" data-anchor-id="proceso-completo-de-validaci√≥n"><span class="header-section-number">3.7.7.6</span> Proceso Completo de Validaci√≥n</h4>
<p>El flujo completo para modelos regularizados es:</p>
<pre><code>1. üìä Dividir datos originales
   ‚îî‚îÄ‚îÄ 80% para desarrollo (entrenamiento + validaci√≥n)
   ‚îî‚îÄ‚îÄ 20% para prueba final (¬°NO TOCAR hasta el final!)

2. üîÑ En el conjunto de desarrollo:
   ‚îî‚îÄ‚îÄ Para cada Œª candidato:
       ‚îú‚îÄ‚îÄ Aplicar k-fold CV
       ‚îú‚îÄ‚îÄ Calcular error promedio
       ‚îî‚îÄ‚îÄ Guardar resultado

3. üéØ Seleccionar Œª con menor error de CV

4. üèóÔ∏è Entrenar modelo final con Œª √≥ptimo en TODO el conjunto de desarrollo

5. üß™ Evaluaci√≥n final en conjunto de prueba</code></pre>
</section>
<section id="variantes-de-validaci√≥n-cruzada" class="level4" data-number="3.7.7.7">
<h4 data-number="3.7.7.7" class="anchored" data-anchor-id="variantes-de-validaci√≥n-cruzada"><span class="header-section-number">3.7.7.7</span> Variantes de Validaci√≥n Cruzada</h4>
<section id="leave-one-out-cv-loocv" class="level5" data-number="3.7.7.7.1">
<h5 data-number="3.7.7.7.1" class="anchored" data-anchor-id="leave-one-out-cv-loocv"><span class="header-section-number">3.7.7.7.1</span> Leave-One-Out CV (LOOCV)</h5>
<ul>
<li><strong>k = n</strong> (n√∫mero de observaciones)</li>
<li><strong>Ventaja</strong>: M√°ximo uso de datos para entrenamiento</li>
<li><strong>Desventaja</strong>: Computacionalmente costoso, alta varianza</li>
</ul>
</section>
<section id="stratified-cv" class="level5" data-number="3.7.7.7.2">
<h5 data-number="3.7.7.7.2" class="anchored" data-anchor-id="stratified-cv"><span class="header-section-number">3.7.7.7.2</span> Stratified CV</h5>
<ul>
<li><strong>Para problemas de clasificaci√≥n</strong></li>
<li>Mantiene la proporci√≥n de clases en cada fold</li>
</ul>
</section>
<section id="time-series-cv" class="level5" data-number="3.7.7.7.3">
<h5 data-number="3.7.7.7.3" class="anchored" data-anchor-id="time-series-cv"><span class="header-section-number">3.7.7.7.3</span> Time Series CV</h5>
<ul>
<li><strong>Para datos temporales</strong></li>
<li>Respeta el orden temporal (no mezcla futuro con pasado)</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>‚ö†Ô∏è Errores Comunes</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Data Leakage</strong>: Usar informaci√≥n del conjunto de prueba durante el desarrollo</li>
<li><strong>M√∫ltiples evaluaciones</strong>: Evaluar repetidamente en el conjunto de prueba</li>
<li><strong>Selecci√≥n de modelo sesgada</strong>: Elegir el modelo bas√°ndose en el conjunto de prueba</li>
<li><strong>CV incorrecto</strong>: Aplicar transformaciones antes de la divisi√≥n de CV</li>
</ol>
</div>
</div>
</section>
</section>
<section id="cu√°ndo-usar-cada-enfoque" class="level4" data-number="3.7.7.8">
<h4 data-number="3.7.7.8" class="anchored" data-anchor-id="cu√°ndo-usar-cada-enfoque"><span class="header-section-number">3.7.7.8</span> ¬øCu√°ndo usar cada enfoque?</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 40%">
<col style="width: 40%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Tama√±o del Dataset</strong></th>
<th><strong>Enfoque Recomendado</strong></th>
<th><strong>Raz√≥n</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Grande (&gt;10,000)</strong></td>
<td>Train/Validation/Test</td>
<td>Suficientes datos para divisi√≥n estable</td>
</tr>
<tr class="even">
<td><strong>Mediano (1,000-10,000)</strong></td>
<td>Train/Test + CV</td>
<td>CV para hiperpar√°metros, test para evaluaci√≥n final</td>
</tr>
<tr class="odd">
<td><strong>Peque√±o (&lt;1,000)</strong></td>
<td>Solo CV (sin test separado)</td>
<td>Maximizar datos disponibles</td>
</tr>
<tr class="even">
<td><strong>Muy peque√±o (&lt;100)</strong></td>
<td>LOOCV o Bootstrap</td>
<td>Cada observaci√≥n es valiosa</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Consejo Pr√°ctico</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Empieza siempre con <strong>Elastic Net</strong> con <span class="math inline">\(\alpha = 0.5\)</span>. Si el modelo selecciona muchas variables, prueba valores de <span class="math inline">\(\alpha\)</span> m√°s cercanos a 1 (m√°s Lasso). Si elimina variables importantes, prueba valores cercanos a 0 (m√°s Ridge).</p>
</div>
</div>
<hr>
</section>
</section>
<section id="ejercicio-pr√°ctico-comparando-los-tres-m√©todos" class="level3" data-number="3.7.8">
<h3 data-number="3.7.8" class="anchored" data-anchor-id="ejercicio-pr√°ctico-comparando-los-tres-m√©todos"><span class="header-section-number">3.7.8</span> Ejercicio Pr√°ctico: Comparando los Tres M√©todos</h3>
<p>En el notebook correspondiente, implementaremos:</p>
<ol type="1">
<li><strong>Generaci√≥n de datos</strong> con diferentes estructuras de correlaci√≥n</li>
<li><strong>Comparaci√≥n visual</strong> de los caminos de regularizaci√≥n</li>
<li><strong>Validaci√≥n cruzada</strong> para selecci√≥n de hiperpar√°metros</li>
<li><strong>Evaluaci√≥n</strong> del rendimiento en datos de prueba</li>
<li><strong>Interpretaci√≥n</strong> de los coeficientes seleccionados</li>
</ol>
<p><strong>Pregunta de reflexi√≥n:</strong> ¬øEn qu√© situaciones esperar√≠as que Ridge supere a Lasso, y viceversa?</p>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-principios.html" class="pagination-link" aria-label="Principios de aprendizaje supervisado">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principios de aprendizaje supervisado</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Referencias">
        <span class="nav-page-text">Referencias</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>