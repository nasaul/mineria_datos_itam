{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4851f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configurar seed para reproducibilidad\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0489351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado exitosamente!\n",
      "Dimensiones del dataset: (1599, 12)\n",
      "\n",
      "Columnas del dataset:\n",
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset de vinos tintos\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "print(\"Dataset cargado exitosamente!\")\n",
    "print(f\"Dimensiones del dataset: {wine_data.shape}\")\n",
    "print(f\"\\nColumnas del dataset:\")\n",
    "print(wine_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577062dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "--------------------------------------------------\n",
      "Estadísticas descriptivas del dataset:\n",
      "                       count       mean        std      min      25%  \\\n",
      "fixed acidity         1599.0   8.319637   1.741096  4.60000   7.1000   \n",
      "volatile acidity      1599.0   0.527821   0.179060  0.12000   0.3900   \n",
      "citric acid           1599.0   0.270976   0.194801  0.00000   0.0900   \n",
      "residual sugar        1599.0   2.538806   1.409928  0.90000   1.9000   \n",
      "chlorides             1599.0   0.087467   0.047065  0.01200   0.0700   \n",
      "free sulfur dioxide   1599.0  15.874922  10.460157  1.00000   7.0000   \n",
      "total sulfur dioxide  1599.0  46.467792  32.895324  6.00000  22.0000   \n",
      "density               1599.0   0.996747   0.001887  0.99007   0.9956   \n",
      "pH                    1599.0   3.311113   0.154386  2.74000   3.2100   \n",
      "sulphates             1599.0   0.658149   0.169507  0.33000   0.5500   \n",
      "alcohol               1599.0  10.422983   1.065668  8.40000   9.5000   \n",
      "quality               1599.0   5.636023   0.807569  3.00000   5.0000   \n",
      "\n",
      "                           50%        75%        max  \n",
      "fixed acidity          7.90000   9.200000   15.90000  \n",
      "volatile acidity       0.52000   0.640000    1.58000  \n",
      "citric acid            0.26000   0.420000    1.00000  \n",
      "residual sugar         2.20000   2.600000   15.50000  \n",
      "chlorides              0.07900   0.090000    0.61100  \n",
      "free sulfur dioxide   14.00000  21.000000   72.00000  \n",
      "total sulfur dioxide  38.00000  62.000000  289.00000  \n",
      "density                0.99675   0.997835    1.00369  \n",
      "pH                     3.31000   3.400000    4.01000  \n",
      "sulphates              0.62000   0.730000    2.00000  \n",
      "alcohol               10.20000  11.100000   14.90000  \n",
      "quality                6.00000   6.000000    8.00000  \n",
      "--------------------------------------------------\n",
      "Valores nulos por columna:\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataset\n",
    "wine_data.head()\n",
    "\n",
    "# TODO: Muestra la información general del dataset (tipos de datos, valores no nulos)\n",
    "print(\"Información general del dataset:\")\n",
    "wine_data.info()\n",
    "print(\"-\" * 50)\n",
    "# TODO: Calcula y muestra las estadísticas descriptivas del dataset\n",
    "print(\"Estadísticas descriptivas del dataset:\")\n",
    "print(wine_data.describe().T)\n",
    "print(\"-\" * 50)\n",
    "# TODO: Verifica si hay valores nulos en el dataset\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(wine_data.isnull().sum())\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar la distribución de la calidad del vino\n",
    "plt.figure(figsize=(10, 6))\n",
    "wine_data['quality'].value_counts().sort_index().plot(kind='bar', color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Calidad del Vino', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.title('Distribución de la Calidad del Vino', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Agregar estadísticas\n",
    "mean_quality = wine_data['quality'].mean()\n",
    "median_quality = wine_data['quality'].median()\n",
    "plt.axhline(y=wine_data['quality'].value_counts().mean(), color='red', \n",
    "            linestyle='--', label=f'Media de frecuencia')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Estadísticas de la calidad del vino:\")\n",
    "print(f\"Media: {mean_quality:.2f}\")\n",
    "print(f\"Mediana: {median_quality:.2f}\")\n",
    "print(f\"Desviación estándar: {wine_data['quality'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7656eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula la matriz de correlación y visualízala con un heatmap\n",
    "# Pista: Usa sns.heatmap() con annot=True para mostrar los valores\n",
    "matriz_corr = wine_data.corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "# Completa el código para crear el heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", \n",
    "            linewidths=.5, cbar_kws={'label': 'Coeficiente de Correlación'})\n",
    "plt.title('Matriz de Correlación del Dataset de Vinos', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# TODO: Identifica y muestra las 5 variables más correlacionadas con 'quality'\n",
    "print(\"-\" * 50)\n",
    "print(\"Variables más correlacionadas con la calidad (quality):\")\n",
    "print(correlation_matrix['quality'].sort_values(ascending=False).head(6)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las 4 variables más correlacionadas con quality\n",
    "top_features = ['alcohol', 'volatile acidity', 'citric acid', 'sulphates']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Relación entre Variables Principales y Calidad del Vino', fontsize=16)\n",
    "\n",
    "for idx, (ax, feature) in enumerate(zip(axes.flat, top_features)):\n",
    "    # TODO: Crea un scatter plot para cada variable vs quality\n",
    "    sns.scatterplot(x=wine_data[feature], y=wine_data['quality'], ax=ax, alpha=0.6, color='b')\n",
    "    # Agrega una línea de tendencia\n",
    "    sns.regplot(x=wine_data[feature], y=wine_data['quality'], ax=ax, scatter=False, color='red', line_kws={'linestyle': '--'})\n",
    "    ax.set_title(f'Calidad vs. {feature.replace(\"_\", \" \").capitalize()}', fontsize=12)\n",
    "    ax.set_xlabel(feature.replace(\"_\", \" \").capitalize(), fontsize=10)\n",
    "    ax.set_ylabel('Calidad del Vino', fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    pass\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características (X) y variable objetivo (y)\n",
    "X = wine_data.drop('quality', axis=1)\n",
    "y = wine_data['quality']\n",
    "\n",
    "print(f\"Forma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "print(f\"\\nCaracterísticas: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d290a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide los datos en conjuntos de entrenamiento y prueba\n",
    "# Usa test_size=0.2 y random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nDivisión de los datos:\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba (X_test): {X_test.shape}\")\n",
    "print(f\"Tamaño de las etiquetas de entrenamiento (y_train): {y_train.shape}\")\n",
    "print(f\"Tamaño de las etiquetas de prueba (y_test): {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28900f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Estandariza las características\n",
    "# Recuerda: ajusta el scaler solo con los datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Estandarización de características completada.\")\n",
    "print(f\"Forma del conjunto de entrenamiento escalado: {X_train_scaled.shape}\")\n",
    "print(f\"Forma del conjunto de prueba escalado: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Validación cruzada manual para Ridge\n",
    "def manual_cross_validation(X, y, alpha, n_folds=5):\n",
    "    \"\"\"\n",
    "    Implementa validación cruzada manualmente para Ridge regression\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        # Dividir datos\n",
    "        X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "        y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Estandarizar\n",
    "        scaler_cv = StandardScaler()\n",
    "        X_train_cv_scaled = scaler_cv.fit_transform(X_train_cv)\n",
    "        X_val_cv_scaled = scaler_cv.transform(X_val_cv)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_train_cv_scaled, y_train_cv)\n",
    "        \n",
    "        # Evaluar\n",
    "        y_pred = model.predict(X_val_cv_scaled)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val_cv, y_pred))\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Probar diferentes valores de alpha\n",
    "alphas_to_test = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "cv_results_manual = []\n",
    "\n",
    "print(\"Validación Cruzada Manual para Ridge Regression:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for alpha in alphas_to_test:\n",
    "    mean_rmse, std_rmse = manual_cross_validation(X_train.values, y_train, alpha)\n",
    "    cv_results_manual.append({'alpha': alpha, 'mean_rmse': mean_rmse, 'std_rmse': std_rmse})\n",
    "    print(f\"Alpha: {alpha:7.3f} | RMSE: {mean_rmse:.4f} (+/- {std_rmse:.4f})\")\n",
    "\n",
    "# TODO: Identifica el mejor alpha basado en el RMSE medio más bajo\n",
    "if cv_results_manual:\n",
    "    best_alpha_manual = min(cv_results_manual, key=lambda x: x['mean_rmse'])\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Resultados de la validación cruzada manual:\")\n",
    "    print(pd.DataFrame(cv_results_manual).sort_values(by='mean_rmse'))\n",
    "    print(f\"\\nEl mejor valor de alpha encontrado manualmente es: {best_alpha_manual['alpha']:.3f} (RMSE: {best_alpha_manual['mean_rmse']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b56218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Usa RidgeCV para encontrar automáticamente el mejor alpha\n",
    "# Pista: RidgeCV tiene un parámetro 'alphas' y 'cv'\n",
    "\n",
    "alphas = np.logspace(-3, 3, 100)  # 100 valores entre 0.001 y 1000\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5, scoring='neg_root_mean_squared_error')\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Mejor alpha encontrado por RidgeCV: {ridge_cv.alpha_:.4f}\")\n",
    "print(f\"RMSE (Validación Cruzada) para el mejor alpha: {np.sqrt(-ridge_cv.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo completo con GridSearchCV para Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir parámetros a buscar\n",
    "param_grid_ridge = {\n",
    "    'alpha': np.logspace(-3, 3, 20)  # 20 valores entre 0.001 y 1000\n",
    "}\n",
    "\n",
    "# Crear modelo base\n",
    "ridge_base = Ridge(random_state=42)\n",
    "\n",
    "grid_search_ridge = GridSearchCV(\n",
    "    estimator=ridge_base,\n",
    "    param_grid=param_grid_ridge,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_ridge.fit(X_train_scaled, y_train)\n",
    "best_rmse = np.sqrt(-grid_search_ridge.best_score_)\n",
    "\n",
    "print(\"\\nBúsqueda con GridSearchCV completada.\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Mejor alpha: {grid_search_ridge.best_params_['alpha']:.4f}\")\n",
    "print(f\"Mejor score (RMSE): {best_rmse:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Resultados completos de la validación cruzada:\")\n",
    "\n",
    "results_df = pd.DataFrame(grid_search_ridge.cv_results_)[['param_alpha', 'mean_test_score', 'std_test_score']]\n",
    "results_df['mean_rmse'] = np.sqrt(-results_df['mean_test_score'])\n",
    "print(results_df.sort_values(by='mean_rmse').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualiza los resultados de la validación cruzada\n",
    "# Crea un gráfico que muestre cómo cambia el RMSE con diferentes valores de alpha\n",
    "results_df = pd.DataFrame(grid_search_ridge.cv_results_)\n",
    "results_df['mean_rmse'] = np.sqrt(-results_df['mean_test_score'])\n",
    "results_df['std_rmse'] = results_df['std_test_score'] / (2 * np.sqrt(len(y_train))) # Cálculo del error estándar del RMSE\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(\n",
    "    results_df['param_alpha'],\n",
    "    results_df['mean_rmse'],\n",
    "    yerr=results_df['std_rmse'],\n",
    "    fmt='-o',\n",
    "    capsize=3,\n",
    "    elinewidth=1,\n",
    "    label='RMSE Promedio (+/- error estándar)',\n",
    "    color='steelblue'\n",
    ")\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (parámetro de regularización)', fontsize=12)\n",
    "plt.ylabel('RMSE de Validación Cruzada', fontsize=12)\n",
    "plt.title('RMSE de Validación Cruzada vs. Alpha para Ridge Regression', fontsize=14)\n",
    "plt.axvline(x=grid_search_ridge.best_params_['alpha'], color='red', linestyle='--', label=f\"Mejor Alpha: {grid_search_ridge.best_params_['alpha']:.3f}\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95aace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa y entrena un modelo de regresión lineal\n",
    "# Tu código aquí\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_lr_train = lr_model.predict(X_train_scaled)\n",
    "y_pred_lr_test = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_lr_train = np.sqrt(mean_squared_error(y_train, y_pred_lr_train))\n",
    "rmse_lr_test = np.sqrt(mean_squared_error(y_test, y_pred_lr_test))\n",
    "r2_lr_train = r2_score(y_train, y_pred_lr_train)\n",
    "r2_lr_test = r2_score(y_test, y_pred_lr_test)\n",
    "\n",
    "print(\"Regresión Lineal Normal:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"RMSE de Entrenamiento: {rmse_lr_train:.4f}\")\n",
    "print(f\"RMSE de Prueba:        {rmse_lr_test:.4f}\")\n",
    "print(f\"R² de Entrenamiento:   {r2_lr_train:.4f}\")\n",
    "print(f\"R² de Prueba:          {r2_lr_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena Ridge con el mejor alpha encontrado por validación cruzada\n",
    "\n",
    "best_alpha_ridge = 9.486832980892942\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge, random_state=42)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones y métricas\n",
    "y_pred_ridge_train = ridge_model.predict(X_train_scaled)\n",
    "y_pred_ridge_test = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "rmse_ridge_train = np.sqrt(mean_squared_error(y_train, y_pred_ridge_train))\n",
    "rmse_ridge_test = np.sqrt(mean_squared_error(y_test, y_pred_ridge_test))\n",
    "r2_ridge_train = r2_score(y_train, y_pred_ridge_train)\n",
    "r2_ridge_test = r2_score(y_test, y_pred_ridge_test)\n",
    "\n",
    "print(\"Ridge Regression con mejor alpha de CV:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Mejor Alpha utilizado: {best_alpha_ridge:.4f}\")\n",
    "print(f\"RMSE de Entrenamiento: {rmse_ridge_train:.4f}\")\n",
    "print(f\"RMSE de Prueba:        {rmse_ridge_test:.4f}\")\n",
    "print(f\"R² de Entrenamiento:   {r2_ridge_train:.4f}\")\n",
    "print(f\"R² de Prueba:          {r2_ridge_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02634e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa LassoCV para encontrar el mejor alpha automáticamente\n",
    "alphas_lasso = np.logspace(-3, 1, 100)\n",
    "lasso_cv = LassoCV(alphas=alphas_lasso, cv=5, random_state=42, n_jobs=-1)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones y métricas\n",
    "y_pred_lasso_train = lasso_cv.predict(X_train_scaled)\n",
    "y_pred_lasso_test = lasso_cv.predict(X_test_scaled)\n",
    "\n",
    "rmse_lasso_train = np.sqrt(mean_squared_error(y_train, y_pred_lasso_train))\n",
    "rmse_lasso_test = np.sqrt(mean_squared_error(y_test, y_pred_lasso_test))\n",
    "r2_lasso_train = r2_score(y_train, y_pred_lasso_train)\n",
    "r2_lasso_test = r2_score(y_test, y_pred_lasso_test)\n",
    "\n",
    "num_selected_features = np.sum(lasso_cv.coef_ != 0)\n",
    "\n",
    "print(\"Lasso Regression con Validación Cruzada:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Mejor alpha para Lasso: {lasso_cv.alpha_:.4f}\")\n",
    "print(f\"Número de características seleccionadas: {num_selected_features}\")\n",
    "print(f\"RMSE de Entrenamiento: {rmse_lasso_train:.4f}\")\n",
    "print(f\"RMSE de Prueba:        {rmse_lasso_test:.4f}\")\n",
    "print(f\"R² de Entrenamiento:   {r2_lasso_train:.4f}\")\n",
    "print(f\"R² de Prueba:          {r2_lasso_test:.4f}\")\n",
    "\n",
    "# TODO: Identifica qué características fueron eliminadas por Lasso\n",
    "eliminated_features = feature_names[lasso_cv.coef_ == 0]\n",
    "selected_features = feature_names[lasso_cv.coef_ != 0]\n",
    "\n",
    "print(\"Análisis de Coeficientes de Lasso:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Características eliminadas (coeficiente = 0):\")\n",
    "if len(eliminated_features) > 0:\n",
    "    for feature in eliminated_features:\n",
    "        print(f\"- {feature}\")\n",
    "else:\n",
    "    print(\"Ninguna característica fue eliminada por Lasso en este rango de alphas.\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Características seleccionadas (coeficiente ≠ 0):\")\n",
    "print(f\"{selected_features.tolist()}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Coeficientes de las características:\")\n",
    "lasso_coefficients = pd.DataFrame({'feature': feature_names, 'coefficient': lasso_cv.coef_})\n",
    "print(lasso_coefficients.sort_values(by='coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae175ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crea una tabla comparativa con todos los modelos\n",
    "# Incluye: RMSE Train, RMSE Test, R² Train, R² Test, MAE Test\n",
    "\n",
    "comparison_data = {\n",
    "    'Modelo': ['Regresión Lineal', 'Ridge', 'Lasso'],\n",
    "    'RMSE Train': [\n",
    "        np.sqrt(mean_squared_error(y_train, y_pred_lr_train)),\n",
    "        np.sqrt(mean_squared_error(y_train, y_pred_ridge_train)),\n",
    "        np.sqrt(mean_squared_error(y_train, y_pred_lasso_train))\n",
    "    ],\n",
    "    'RMSE Test': [\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_lr_test)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_ridge_test)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_lasso_test))\n",
    "    ],\n",
    "    'R² Train': [\n",
    "        r2_score(y_train, y_pred_lr_train),\n",
    "        r2_score(y_train, y_pred_ridge_train),\n",
    "        r2_score(y_train, y_pred_lasso_train)\n",
    "    ],\n",
    "    'R² Test': [\n",
    "        r2_score(y_test, y_pred_lr_test),\n",
    "        r2_score(y_test, y_pred_ridge_test),\n",
    "        r2_score(y_test, y_pred_lasso_test)\n",
    "    ],\n",
    "    'MAE Test': [\n",
    "        mean_absolute_error(y_test, y_pred_lr_test),\n",
    "        mean_absolute_error(y_test, y_pred_ridge_test),\n",
    "        mean_absolute_error(y_test, y_pred_lasso_test)\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crea visualizaciones para comparar los modelos\n",
    "# 1. Gráfico de barras comparando RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "rmse_plot = sns.barplot(x='Modelo', y='RMSE', data=performance_df, palette='viridis')\n",
    "plt.title('Comparación de RMSE de los Modelos en el Conjunto de Prueba', fontsize=14)\n",
    "plt.xlabel('Modelo', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.ylim(0.64, 0.66)\n",
    "\n",
    "for index, row in performance_df.iterrows():\n",
    "    rmse_plot.text(row.name, row.RMSE + 0.0005, f'{row.RMSE:.4f}', color='black', ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Gráfico de barras comparando R²\n",
    "plt.figure(figsize=(10, 6))\n",
    "r2_plot = sns.barplot(x='Modelo', y='R²', data=performance_df, palette='viridis')\n",
    "plt.title('Comparación de R² de los Modelos en el Conjunto de Prueba', fontsize=14)\n",
    "plt.xlabel('Modelo', fontsize=12)\n",
    "plt.ylabel('R²', fontsize=12)\n",
    "plt.ylim(0.35, 0.38) \n",
    "\n",
    "for index, row in performance_df.iterrows():\n",
    "    r2_plot.text(row.name, row.R2 + 0.0005, f'{row.R2:.4f}', color='black', ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3df136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Para el mejor modelo, crea:\n",
    "# 1. Gráfico de residuos vs predicciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_pred_lasso_test, y=residuals, alpha=0.6, color='steelblue')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicciones', fontsize=12)\n",
    "plt.ylabel('Residuos', fontsize=12)\n",
    "plt.title('Gráfico de Residuos vs. Predicciones', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2. Histograma de residuos\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, bins=30, kde=True, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Residuos', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.title('Histograma de Residuos', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 3. Q-Q plot de residuos\n",
    "fig = sm.qqplot(residuals, line='45', fit=True)\n",
    "fig.set_size_inches(10, 6)\n",
    "plt.title('Q-Q Plot de Residuos', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualiza los coeficientes de los tres modelos en un mismo gráfico\n",
    "# Esto te ayudará a entender qué características son más importantes\n",
    "coef_df_melted = coef_df.melt('Features', var_name='Modelo', value_name='Coeficiente')\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x='Features', y='Coeficiente', hue='Modelo', data=coef_df_melted, palette='tab10')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.axhline(y=0, color='black', linestyle='-', linewidth=1.5)\n",
    "plt.title('Comparación de Coeficientes de los Modelos de Regresión', fontsize=16)\n",
    "plt.xlabel('Características', fontsize=12)\n",
    "plt.ylabel('Valor del Coeficiente', fontsize=12)\n",
    "plt.legend(title='Modelo')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realiza validación cruzada con 10 folds del mejor modelo\n",
    "# Reporta la media y desviación estándar del RMSE\n",
    "final_lasso_model = Lasso(alpha=best_alpha_lasso, random_state=42)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    final_lasso_model,\n",
    "    X_scaled,\n",
    "    y,\n",
    "    cv=kf,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Convertir los scores negativos a RMSE\n",
    "rmse_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "# Reportar los resultados\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "\n",
    "print(\"Validación Cruzada Final del Modelo Lasso:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Alpha utilizado: {best_alpha_lasso:.4f}\")\n",
    "print(f\"Media del RMSE (10 pliegues):    {mean_rmse:.4f}\")\n",
    "print(f\"Desviación Estándar del RMSE: {std_rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineria_datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
