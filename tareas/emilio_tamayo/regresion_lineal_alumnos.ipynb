{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5013b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genera_datos_lineales(\n",
    "        n:int=100,\n",
    "        slope:float=0.5,\n",
    "        intercept:float=1,\n",
    "        noise_scale:float=1.5\n",
    "    ) -> pd.DataFrame:\n",
    "    X = np.linspace(0, 10, n)\n",
    "    y = slope * X + intercept + np.random.normal(scale=noise_scale, size=n)\n",
    "    df = pd.DataFrame({\"x\": X, \"y\": y})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ee5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente_historial(datos: pd.DataFrame, learning_rate: float, iteraciones: int) -> tuple[float, float, list, list, list]:\n",
    "    \"\"\"\n",
    "    Realiza el descenso de gradiente para una regresión lineal y guarda el historial\n",
    "    de los parámetros (m, b) y del Error Cuadrático Medio (MSE) en cada iteración.\n",
    "    \"\"\"\n",
    "    # 1. Inicializar parámetros y listas de historial\n",
    "    m = 0.0\n",
    "    b = 0.0\n",
    "    n = float(len(datos))\n",
    "\n",
    "    historial_m = []\n",
    "    historial_b = []\n",
    "    historial_error = []\n",
    "\n",
    "    # 2. Iterar para optimizar m y b\n",
    "    for i in range(iteraciones):\n",
    "        # Almacenar los valores de la iteración actual ANTES de actualizarlos\n",
    "        historial_m.append(m)\n",
    "        historial_b.append(b)\n",
    "\n",
    "        # Calcular las predicciones actuales\n",
    "        y_pred = ...\n",
    "\n",
    "        # Calcular y almacenar el Error Cuadrático Medio (MSE)\n",
    "        error = ...\n",
    "        historial_error.append(error)\n",
    "\n",
    "        # Calcular los gradientes\n",
    "        D_m = ...\n",
    "        D_b = ...\n",
    "\n",
    "        # 3. Actualizar los parámetros\n",
    "        m = ...\n",
    "        b = ...\n",
    "\n",
    "    return m, b, historial_m, historial_b, historial_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "learning_rate = 0.001\n",
    "iteraciones = 10000\n",
    "\n",
    "# Ejecutar el descenso de gradiente\n",
    "datos = genera_datos_lineales(n=1000, slope=2, intercept=5, noise_scale=5)\n",
    "m_final, b_final, h_m, h_b, h_error = descenso_gradiente_historial(datos, learning_rate, iteraciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame({\n",
    "    'Iteración': range(iteraciones),\n",
    "    'MSE': h_error\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=plot_data, x='Iteración', y='MSE', color='darkcyan', linewidth=2.5)\n",
    "\n",
    "# 4. Añadir títulos y etiquetas\n",
    "plt.title('Disminución del Error Cuadrático Medio (MSE) por Iteración', fontsize=16)\n",
    "plt.xlabel('Iteración', fontsize=12)\n",
    "plt.ylabel('Error Cuadrático Medio (MSE)', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd86bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparar los datos\n",
    "# Scikit-learn espera que X sea un array 2D\n",
    "X_sklearn = datos[['x']]\n",
    "y_sklearn = datos['y']\n",
    "\n",
    "# 2. Crear y entrenar el modelo\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_sklearn, y_sklearn)\n",
    "\n",
    "# Obtener los coeficientes\n",
    "m_sklearn = modelo.coef_[0]\n",
    "b_sklearn = modelo.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5241bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Implementación Manual ---\")\n",
    "print(f\"La pendiente (m) encontrada es: {m_final:.4f}\")\n",
    "print(f\"El intercepto (b) encontrado es: {b_final:.4f}\")\n",
    "print(\"\\n--- Resultado con Scikit-Learn ---\")\n",
    "print(f\"La pendiente (m) encontrada es: {m_sklearn:.4f}\")\n",
    "print(f\"El intercepto (b) encontrado es: {b_sklearn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08360e91",
   "metadata": {},
   "source": [
    "## Implementación multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c26f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_datos_lineales_multivariados(n_muestras: int, n_caracteristicas: int, ruido: float = 0.5) -> tuple[pd.DataFrame, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Genera un conjunto de datos sintético para regresión lineal multivariada.\n",
    "\n",
    "    Args:\n",
    "        n_muestras (int): El número de puntos de datos a generar (filas).\n",
    "        n_caracteristicas (int): El número de variables independientes (características).\n",
    "        ruido (float): La desviación estándar del ruido gaussiano a añadir.\n",
    "                       Controla la dispersión de los puntos.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, np.ndarray, float]:\n",
    "            - Un DataFrame de pandas con las características (x1, x2, ...) y la variable objetivo (y).\n",
    "            - El array de coeficientes (pesos) reales que se usaron para generar los datos.\n",
    "            - El intercepto (sesgo) real que se usó.\n",
    "    \"\"\"\n",
    "    # 1. Generar las características (X) con valores aleatorios entre 0 y 10\n",
    "    X = 10 * np.random.rand(n_muestras, n_caracteristicas)\n",
    "\n",
    "    # 2. Generar coeficientes e intercepto reales aleatorios\n",
    "    # Estos son los \"verdaderos\" parámetros que un modelo intentaría encontrar.\n",
    "    coeficientes_reales = np.random.randn(n_caracteristicas) * 2\n",
    "    intercepto_real = np.random.randn() * 5\n",
    "\n",
    "    # 3. Generar el ruido gaussiano\n",
    "    # El ruido simula la variabilidad aleatoria en los datos del mundo real.\n",
    "    ruido_gaussiano = np.random.randn(n_muestras) * ruido\n",
    "\n",
    "    # 4. Calcular la variable objetivo (y) usando la ecuación lineal\n",
    "    # y = (X • coeficientes) + intercepto + ruido\n",
    "    y = np.dot(X, coeficientes_reales) + intercepto_real + ruido_gaussiano\n",
    "\n",
    "    # 5. Formatear la salida en un DataFrame de pandas\n",
    "    nombres_columnas = [f'x{i+1}' for i in range(n_caracteristicas)]\n",
    "    datos = pd.DataFrame(X, columns=nombres_columnas)\n",
    "    datos['y'] = y\n",
    "\n",
    "    return datos, coeficientes_reales, intercepto_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66809139",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_muestras = 200\n",
    "num_caracteristicas = 10 \n",
    "nivel_ruido = 1.5\n",
    "\n",
    "# Generar los datos\n",
    "datos_generados, coeficientes, intercepto = generar_datos_lineales_multivariados(\n",
    "    n_muestras=num_muestras,\n",
    "    n_caracteristicas=num_caracteristicas,\n",
    "    ruido=nivel_ruido\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente_multivariado(datos: pd.DataFrame, learning_rate: float, iteraciones: int) -> tuple[np.ndarray, float, list]:\n",
    "    \"\"\"\n",
    "    Realiza el descenso de gradiente para una regresión lineal multivariada.\n",
    "\n",
    "    Args:\n",
    "        datos (pd.DataFrame): DataFrame que contiene las características y la variable objetivo 'y'.\n",
    "        learning_rate (float): La tasa de aprendizaje.\n",
    "        iteraciones (int): El número de iteraciones para ejecutar el algoritmo.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, float, list]:\n",
    "            - El array de coeficientes (pesos) optimizados.\n",
    "            - El intercepto (sesgo) optimizado.\n",
    "            - Una lista con el historial del Error Cuadrático Medio (MSE) en cada iteración.\n",
    "    \"\"\"\n",
    "    # 1. Preparar los datos\n",
    "    X = ...  # Matriz de características\n",
    "    y = datos['y'].values              # Vector de la variable objetivo\n",
    "    n_muestras, n_caracteristicas = ...\n",
    "\n",
    "    # 2. Inicializar parámetros\n",
    "    coeficientes = np.zeros(n_caracteristicas)\n",
    "    intercepto = 0.0\n",
    "    historial_error = []\n",
    "\n",
    "    # 3. Iterar para optimizar los parámetros\n",
    "    for i in range(iteraciones):\n",
    "        # Calcular las predicciones (producto punto de X y coeficientes)\n",
    "        # Ecuación: y_pred = (X • coeficientes) + intercepto\n",
    "        y_pred = ...\n",
    "\n",
    "        # Calcular el Error Cuadrático Medio (MSE) y guardarlo\n",
    "        error = ...\n",
    "        historial_error.append(error)\n",
    "\n",
    "        # Calcular los gradientes (derivadas parciales)\n",
    "        # El gradiente es la dirección de máximo ascenso del error.\n",
    "        # Lo calculamos de forma vectorizada para eficiencia.\n",
    "        D_coeficientes = ...\n",
    "        D_intercepto = ...\n",
    "\n",
    "        # 4. Actualizar los parámetros (moverse en dirección opuesta al gradiente)\n",
    "        coeficientes = ...\n",
    "        intercepto = ...\n",
    "\n",
    "    return coeficientes, intercepto, historial_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eea4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_muestras = 200\n",
    "num_caracteristicas = 3\n",
    "nivel_ruido = 1.5\n",
    "datos_generados, coef_reales, int_real = generar_datos_lineales_multivariados(\n",
    "    n_muestras=num_muestras,\n",
    "    n_caracteristicas=num_caracteristicas,\n",
    "    ruido=nivel_ruido\n",
    ")\n",
    "\n",
    "X_original = datos_generados.drop('y', axis=1)\n",
    "y = datos_generados['y']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_escalado = scaler.fit_transform(X_original)\n",
    "\n",
    "datos_escalados = pd.DataFrame(X_escalado, columns=X_original.columns)\n",
    "datos_escalados['y'] = y.values\n",
    "\n",
    "learning_rate = 0.01\n",
    "iteraciones = 1000\n",
    "coef_aprendidos, int_aprendido, error_hist = descenso_gradiente_multivariado(\n",
    "    datos=datos_escalados,\n",
    "    learning_rate=learning_rate,\n",
    "    iteraciones=iteraciones\n",
    ")\n",
    "\n",
    "modelo_sklearn = LinearRegression()\n",
    "modelo_sklearn.fit(X_escalado, y)\n",
    "coef_sklearn = modelo_sklearn.coef_\n",
    "int_sklearn = modelo_sklearn.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eca24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Comparación de Parámetros (con datos escalados) ---\")\n",
    "print(f\"Intercepto GD: {int_aprendido:.4f}  |  Intercepto Sklearn: {int_sklearn:.4f}\")\n",
    "for i in range(num_caracteristicas):\n",
    "    print(f\"Coef. x{i+1} GD: {coef_aprendidos[i]:.4f} |  Coef. x{i+1} Sklearn: {coef_sklearn[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8218720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineria_datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
